# Bloque 10: Optimizaci√≥n de Hiperpar√°metros

## üìã Descripci√≥n General

Este bloque es como **afinar un instrumento musical** para que suene perfecto. Los modelos tienen "perillas" (hiperpar√°metros) que controlan su comportamiento. Aqu√≠ buscamos la mejor combinaci√≥n de configuraciones para maximizar el rendimiento del modelo.

---

## üéØ Prop√≥sito y Objetivo

Los objetivos principales de este bloque son:

1. **Identificar el mejor modelo** de los candidatos anteriores
2. **Definir un espacio de b√∫squeda** de hiperpar√°metros
3. **Aplicar GridSearchCV o RandomizedSearchCV** para encontrar la mejor configuraci√≥n
4. **Evaluar el modelo optimizado** y comparar con el baseline
5. **Seleccionar el modelo final** para producci√≥n

### ¬øPor qu√© es importante?

**Analog√≠a del caf√©**: Hacer caf√© perfecto requiere ajustar:
- Temperatura del agua
- Tiempo de extracci√≥n
- Cantidad de caf√©
- Molienda

Cambiar cualquiera de estos par√°metros afecta el sabor final. Lo mismo pasa con los modelos de ML.

---

## üîë Conceptos Clave y T√©cnicas Utilizadas

### 1. **¬øQu√© son los Hiperpar√°metros?**

**Hiperpar√°metros** son configuraciones que se establecen ANTES del entrenamiento y controlan c√≥mo aprende el modelo.

**Diferencia con par√°metros**:
- **Par√°metros**: El modelo los aprende de los datos (ej: pesos en regresi√≥n)
- **Hiperpar√°metros**: Los definimos nosotros (ej: profundidad de un √°rbol)

**Analog√≠a del estudiante**:
- **Par√°metros**: El conocimiento que adquiere estudiando
- **Hiperpar√°metros**: Cu√°ntas horas estudia, qu√© t√©cnica usa, en qu√© ambiente

---

### 2. **Hiperpar√°metros Comunes por Modelo**

#### **Random Forest**

```python
param_grid = {
    'n_estimators': [100, 200, 300],      # N√∫mero de √°rboles
    'max_depth': [10, 20, 30, None],      # Profundidad m√°xima
    'min_samples_split': [2, 5, 10],      # M√≠nimo para dividir nodo
    'min_samples_leaf': [1, 2, 4],        # M√≠nimo en hoja
    'max_features': ['sqrt', 'log2']      # Features por split
}
```

**Explicaci√≥n**:

- **n_estimators**: M√°s √°rboles = m√°s robusto pero m√°s lento
  - **Analog√≠a**: M√°s jueces en un panel = decisi√≥n m√°s confiable
  
- **max_depth**: Controla cu√°n profundo puede crecer cada √°rbol
  - **Analog√≠a**: Cu√°ntos niveles de preguntas puede hacer
  - Muy profundo = overfitting, muy superficial = underfitting
  
- **min_samples_split**: M√≠nimo de ejemplos para dividir un nodo
  - **Analog√≠a**: No dividir un grupo si es muy peque√±o
  - Previene overfitting
  
- **min_samples_leaf**: M√≠nimo de ejemplos en cada hoja
  - **Analog√≠a**: Cada conclusi√≥n debe basarse en al menos X casos
  
- **max_features**: Cu√°ntas features considerar en cada split
  - **sqrt**: Ra√≠z cuadrada del total (m√°s diversidad)
  - **log2**: Logaritmo base 2 (m√°s conservador)

---

#### **XGBoost**

```python
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [3, 5, 7],
    'learning_rate': [0.01, 0.1, 0.3],
    'subsample': [0.8, 0.9, 1.0],
    'colsample_bytree': [0.8, 0.9, 1.0],
    'gamma': [0, 0.1, 0.2]
}
```

**Explicaci√≥n**:

- **learning_rate**: Qu√© tan r√°pido aprende el modelo
  - **Analog√≠a**: Tama√±o del paso al caminar
  - Bajo (0.01) = lento pero preciso
  - Alto (0.3) = r√°pido pero puede pasarse
  
- **subsample**: Fracci√≥n de datos usados en cada √°rbol
  - **Analog√≠a**: Usar una muestra aleatoria para cada decisi√≥n
  - Previene overfitting
  
- **colsample_bytree**: Fracci√≥n de features usadas por √°rbol
  - Similar a max_features en Random Forest
  
- **gamma**: Reducci√≥n m√≠nima de p√©rdida para hacer un split
  - **Analog√≠a**: Cu√°nto debe mejorar una pregunta para hacerla
  - Mayor gamma = modelo m√°s conservador

---

### 3. **GridSearchCV vs. RandomizedSearchCV**

#### **GridSearchCV (B√∫squeda Exhaustiva)**

**¬øC√≥mo funciona?**
- Prueba TODAS las combinaciones posibles de hiperpar√°metros

**Ejemplo**:
```python
n_estimators: [100, 200]
max_depth: [10, 20]
```
Combinaciones: 2 √ó 2 = 4 pruebas

**Ventajas**:
- ‚úÖ Garantiza encontrar la mejor combinaci√≥n en el espacio definido
- ‚úÖ Exhaustivo

**Desventajas**:
- ‚ùå Muy lento con muchos par√°metros
- ‚ùå Crece exponencialmente

**Analog√≠a**: Probar todas las combinaciones de ropa en tu armario.

---

#### **RandomizedSearchCV (B√∫squeda Aleatoria)**

**¬øC√≥mo funciona?**
- Prueba un n√∫mero fijo de combinaciones aleatorias

**Ejemplo**:
```python
n_estimators: [100, 200, 300, 400, 500]
max_depth: [5, 10, 15, 20, 25, 30]
learning_rate: [0.01, 0.05, 0.1, 0.15, 0.2]
```
Combinaciones posibles: 5 √ó 6 √ó 5 = 150
Pero solo prueba, por ejemplo, 30 aleatorias

**Ventajas**:
- ‚úÖ Mucho m√°s r√°pido
- ‚úÖ Puede explorar espacios grandes
- ‚úÖ Sorprendentemente efectivo

**Desventajas**:
- ‚ùå No garantiza encontrar el √≥ptimo absoluto
- ‚ùå Resultados pueden variar entre ejecuciones

**Analog√≠a**: Probar 20 combinaciones aleatorias de ropa en vez de todas.

---

### 4. **Validaci√≥n Cruzada (Cross-Validation)**

Tanto GridSearchCV como RandomizedSearchCV usan **validaci√≥n cruzada** para evaluar cada combinaci√≥n.

**¬øQu√© es CV=5?**

Divide los datos de entrenamiento en 5 partes (folds):

```
Fold 1: [Test] [Train] [Train] [Train] [Train]
Fold 2: [Train] [Test] [Train] [Train] [Train]
Fold 3: [Train] [Train] [Test] [Train] [Train]
Fold 4: [Train] [Train] [Train] [Test] [Train]
Fold 5: [Train] [Train] [Train] [Train] [Test]
```

**Proceso**:
1. Entrena con 4 folds, eval√∫a en 1
2. Repite 5 veces (cada fold es test una vez)
3. Promedia los resultados

**Ventajas**:
- ‚úÖ Usa todos los datos para entrenar y evaluar
- ‚úÖ Resultados m√°s robustos
- ‚úÖ Reduce varianza de la evaluaci√≥n

**Analog√≠a**: En vez de un solo examen, tomas 5 ex√°menes diferentes y promedias la nota.

---

### 5. **Proceso de Optimizaci√≥n**

```python
grid_search = GridSearchCV(
    estimator=RandomForestClassifier(random_state=42),
    param_grid=param_grid,
    cv=5,
    scoring='f1',
    n_jobs=-1,
    verbose=2
)

grid_search.fit(X_train_balanced, y_train_balanced)
best_model = grid_search.best_estimator_
```

**Par√°metros importantes**:

- **estimator**: El modelo a optimizar
- **param_grid**: Espacio de b√∫squeda
- **cv=5**: 5-fold cross-validation
- **scoring='f1'**: M√©trica a optimizar (F1-Score)
- **n_jobs=-1**: Usa todos los cores del CPU (paralelizaci√≥n)
- **verbose=2**: Muestra progreso detallado

**Resultado**:
- **best_estimator_**: Modelo con los mejores hiperpar√°metros
- **best_params_**: Diccionario con la mejor configuraci√≥n
- **best_score_**: Mejor score obtenido en CV

---

## üìä Resultados T√≠picos de la Optimizaci√≥n

### **Antes de Optimizaci√≥n (Baseline con SMOTE)**

| Modelo | F1-Score | Recall | Precision |
|--------|----------|--------|-----------|
| Random Forest | 0.71 | 0.78 | 0.65 |
| XGBoost | 0.73 | 0.80 | 0.67 |

### **Despu√©s de Optimizaci√≥n**

| Modelo | F1-Score | Recall | Precision |
|--------|----------|--------|-----------|
| Random Forest | 0.75 | 0.82 | 0.69 |
| XGBoost | 0.77 | 0.84 | 0.71 |

**Mejora**: ~4-5% en todas las m√©tricas

---

### **Mejores Hiperpar√°metros Encontrados (Ejemplo)**

**XGBoost**:
```python
{
    'n_estimators': 200,
    'max_depth': 5,
    'learning_rate': 0.1,
    'subsample': 0.9,
    'colsample_bytree': 0.9,
    'gamma': 0.1
}
```

**Interpretaci√≥n**:
- 200 √°rboles (balance entre rendimiento y velocidad)
- Profundidad moderada (5) para evitar overfitting
- Learning rate moderado (0.1) para convergencia estable
- Subsample y colsample altos (0.9) para usar la mayor√≠a de datos/features
- Gamma bajo (0.1) para permitir splits √∫tiles

---

## üîó Relaci√≥n con el An√°lisis General

Este bloque es el **refinamiento final**:

1. **Maximiza el rendimiento**: Exprime el √∫ltimo % de mejora
2. **Selecciona el modelo final**: El que ir√° a producci√≥n
3. **Documenta la configuraci√≥n**: Reproducibilidad
4. **Valida robustez**: CV asegura que no es suerte

---

## üí° Puntos Clave para Recordar

1. **Hiperpar√°metros** controlan c√≥mo aprende el modelo
2. **GridSearchCV**: Exhaustivo pero lento
3. **RandomizedSearchCV**: R√°pido y efectivo para espacios grandes
4. **Cross-Validation (CV=5)**: Evaluaci√≥n robusta
5. **Mejora t√≠pica**: 3-5% sobre baseline
6. **Scoring='f1'**: Optimizamos F1-Score (balance precision/recall)

---

## üéì Conclusi√≥n

La optimizaci√≥n de hiperpar√°metros es como ajustar la receta perfecta: peque√±os cambios en los ingredientes pueden hacer una gran diferencia. No siempre da mejoras dram√°ticas, pero ese 3-5% extra puede ser la diferencia entre un modelo bueno y uno excelente.

**Siguiente paso**: Evaluaci√≥n detallada del mejor modelo con an√°lisis de errores, curvas ROC, feature importance y recomendaciones de negocio.

