# Instrucciones para Ejecutar el Notebook Optimizado

## Requisitos Previos

### 1. Librer√≠as Necesarias

Aseg√∫rate de tener instaladas las siguientes librer√≠as de Python:

```bash
pip install numpy pandas matplotlib seaborn scikit-learn xgboost imbalanced-learn
```

O si usas conda:

```bash
conda install numpy pandas matplotlib seaborn scikit-learn xgboost imbalanced-learn -c conda-forge
```

### 2. Archivos Necesarios

- `Telco-Customer-Churn.ipynb` - El notebook optimizado
- `WA_Fn-UseC_-Telco-Customer-Churn.csv` - El dataset

## C√≥mo Ejecutar el Notebook

### Opci√≥n 1: Jupyter Notebook (Local)

1. Abre una terminal en el directorio del proyecto
2. Ejecuta:
   ```bash
   jupyter notebook
   ```
3. Abre `Telco-Customer-Churn.ipynb`
4. Ejecuta las celdas secuencialmente (Cell ‚Üí Run All)

### Opci√≥n 2: JupyterLab (Local)

1. Abre una terminal en el directorio del proyecto
2. Ejecuta:
   ```bash
   jupyter lab
   ```
3. Abre `Telco-Customer-Churn.ipynb`
4. Ejecuta las celdas secuencialmente

### Opci√≥n 3: Google Colab

1. Sube el notebook a Google Drive
2. Abre con Google Colab
3. Sube el archivo CSV cuando se solicite
4. Ejecuta todas las celdas

### Opci√≥n 4: VS Code

1. Abre VS Code en el directorio del proyecto
2. Instala la extensi√≥n "Jupyter" si no la tienes
3. Abre `Telco-Customer-Churn.ipynb`
4. Selecciona el kernel de Python
5. Ejecuta las celdas

## Tiempo de Ejecuci√≥n Estimado

- **Secciones 1-4 (EDA)**: ~2-3 minutos
- **Secciones 5-6 (Modelado Baseline)**: ~3-5 minutos
- **Secci√≥n 7 (SMOTE y Reentrenamiento)**: ~2-3 minutos
- **Secci√≥n 8 (Optimizaci√≥n)**: ~5-10 minutos (puede variar)
- **Secciones 9-10 (Evaluaci√≥n)**: ~1-2 minutos

**Total**: Aproximadamente 15-25 minutos

## Estructura del Notebook

El notebook est√° organizado en 10 secciones principales:

1. **Introducci√≥n y Carga de Datos**
2. **An√°lisis de Calidad de Datos**
3. **An√°lisis Exploratorio (EDA)**
4. **Feature Engineering**
5. **Preparaci√≥n de Datos**
6. **Modelos Baseline**
7. **Manejo de Desbalanceo**
8. **Optimizaci√≥n de Hiperpar√°metros**
9. **Evaluaci√≥n Detallada**
10. **Conclusiones y Recomendaciones**

## Puntos Clave para la Defensa

### Conceptos Fundamentales a Dominar:

1. **Desbalanceo de Clases**:
   - Por qu√© es un problema (73% vs 27%)
   - C√≥mo SMOTE ayuda a balancear
   - Impacto en las m√©tricas

2. **M√©tricas de Evaluaci√≥n**:
   - Accuracy vs Precision vs Recall
   - Por qu√© ROC-AUC es importante
   - Interpretaci√≥n de la matriz de confusi√≥n

3. **Feature Engineering**:
   - Justificaci√≥n de cada feature creada
   - Impacto en el rendimiento del modelo

4. **Optimizaci√≥n**:
   - Por qu√© usar RandomizedSearchCV
   - Importancia de la validaci√≥n cruzada
   - Trade-offs en hiperpar√°metros

5. **Interpretabilidad**:
   - Feature importance
   - Insights de negocio
   - Recomendaciones accionables

## Posibles Preguntas del Profesor

### T√©cnicas:

1. **¬øPor qu√© usaste SMOTE en lugar de otras t√©cnicas?**
   - SMOTE crea ejemplos sint√©ticos inteligentes
   - Mejor que simple oversampling
   - Evita overfitting del undersampling

2. **¬øPor qu√© Random Forest fue el mejor modelo?**
   - Robusto ante overfitting
   - Maneja bien features categ√≥ricas
   - Proporciona feature importance
   - Buen balance precision/recall

3. **¬øQu√© significa ROC-AUC de 0.85?**
   - 85% de probabilidad de clasificar correctamente
   - Excelente capacidad discriminativa
   - Mejor que clasificador aleatorio (0.5)

4. **¬øPor qu√© dividiste 80/20 y no 70/30?**
   - Balance entre datos de entrenamiento y validaci√≥n
   - Suficientes datos para test (~1,400 registros)
   - Est√°ndar en la industria

### De Negocio:

1. **¬øCu√°les son los factores m√°s importantes de churn?**
   - Tenure (clientes nuevos en riesgo)
   - Tipo de contrato (mes a mes)
   - Servicios adicionales (tech support)

2. **¬øQu√© recomendaciones dar√≠as a la empresa?**
   - Programas de retenci√≥n para clientes nuevos
   - Incentivos para contratos largos
   - Promoci√≥n de servicios de soporte

3. **¬øC√≥mo implementar√≠as esto en producci√≥n?**
   - API para scoring en tiempo real
   - Dashboard de monitoreo
   - Actualizaci√≥n peri√≥dica del modelo

## Soluci√≥n de Problemas

### Error: "No module named 'imblearn'"
```bash
pip install imbalanced-learn
```

### Error: "No module named 'xgboost'"
```bash
pip install xgboost
```

### Error: "FileNotFoundError"
- Verifica que el CSV est√© en el mismo directorio
- O ajusta la ruta en la celda de carga de datos

### Advertencias de deprecaci√≥n
- Son normales, el c√≥digo funciona correctamente
- Puedes ignorarlas o actualizar las librer√≠as

## Recursos Adicionales

- [Documentaci√≥n de Scikit-learn](https://scikit-learn.org/)
- [Documentaci√≥n de XGBoost](https://xgboost.readthedocs.io/)
- [Imbalanced-learn](https://imbalanced-learn.org/)
- [Seaborn Gallery](https://seaborn.pydata.org/examples/index.html)

## Contacto y Soporte

Si encuentras alg√∫n problema o tienes preguntas:
1. Revisa la documentaci√≥n de las librer√≠as
2. Verifica que todas las dependencias est√©n instaladas
3. Aseg√∫rate de ejecutar las celdas en orden

---

**¬°Buena suerte en tu defensa!** üöÄ

