## üéØ ¬øQu√© son los Modelos Baseline?

Los **modelos baseline** son modelos de Machine Learning entrenados con **configuraciones por defecto** (sin optimizaci√≥n) que sirven como **punto de referencia inicial** para evaluar el rendimiento y comparar diferentes algoritmos.

**Analog√≠a**: Es como una audici√≥n deportiva donde varios atletas compiten con su rendimiento natural (sin entrenamiento especializado) para ver qui√©nes tienen m√°s potencial.

---

## üîë Caracter√≠sticas Clave de los Modelos Baseline

1. **Configuraci√≥n por defecto**: Se usan los par√°metros predeterminados de cada algoritmo
2. **L√≠nea base de rendimiento**: Establecen un punto de partida antes de optimizar
3. **Comparaci√≥n justa**: Todos los modelos se eval√∫an bajo las mismas condiciones
4. **Identificaci√≥n de candidatos**: Ayudan a decidir en qu√© modelos invertir tiempo de optimizaci√≥n

---

## üìä Modelos Baseline en Tu Proyecto

Seg√∫n tu notebook `Telco_Customer_Churn.ipynb`, entrenas **7 modelos baseline**:

```python 
path=Telco_Customer_Churn.ipynb mode=EXCERPT
models = {
    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),
    'Decision Tree': DecisionTreeClassifier(random_state=42),
    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100),
    'Gradient Boosting': GradientBoostingClassifier(random_state=42, n_estimators=100),
    'XGBoost': xgb.XGBClassifier(random_state=42, n_estimators=100, eval_metric='logloss'),
    'SVM': SVC(random_state=42, probability=True),
    'KNN': KNeighborsClassifier()
}
```

---

## üéì C√≥mo Escoger los Mejores Modelos Baseline

### **Paso 1: Entrenar Todos los Modelos**
Entrenas los 7 modelos con los datos de entrenamiento y eval√∫as su rendimiento con m√∫ltiples m√©tricas.

### **Paso 2: Evaluar con M√©tricas Apropiadas**
En tu contexto de predicci√≥n de churn, las m√©tricas clave son:

- **Accuracy**: Porcentaje de predicciones correctas
- **Precision**: De los que predijiste como churn, ¬øcu√°ntos realmente lo hicieron?
- **Recall**: De todos los que hicieron churn, ¬øcu√°ntos detectaste? ‚≠ê **MUY IMPORTANTE para churn**
- **F1-Score**: Balance entre Precision y Recall
- **ROC-AUC**: Capacidad de discriminar entre clases (0.5 = aleatorio, 1.0 = perfecto)

### **Paso 3: Comparar Resultados**
Seg√∫n tu documentaci√≥n, los resultados t√≠picos son:

**üèÜ Mejores modelos (Ensemble Methods)**:

1. **XGBoost**: ~85% accuracy, ~0.85 ROC-AUC
2. **Random Forest**: ~84% accuracy, ~0.84 ROC-AUC
3. **Gradient Boosting**: ~83% accuracy, ~0.83 ROC-AUC

**üìä Rendimiento moderado**:

4. **Logistic Regression**: ~80% accuracy
5. **SVM**: ~79% accuracy

**üìâ Menor rendimiento**:

6. **Decision Tree**: ~75% accuracy (propenso a overfitting)
7. **KNN**: ~76% accuracy

### **Paso 4: Seleccionar los Mejores Candidatos**
En tu proyecto, seleccionaste **4 modelos** para continuar:

```python 
path=Telco_Customer_Churn.ipynb mode=EXCERPT
best_models = {
    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),
    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100),
    'Gradient Boosting': GradientBoostingClassifier(random_state=42, n_estimators=100),
    'XGBoost': xgb.XGBClassifier(random_state=42, n_estimators=100, eval_metric='logloss')
}
```

---

## üí° Criterios para Escoger Modelos Baseline

### **1. Rendimiento en M√©tricas Clave**
- Prioriza **Recall** en problemas de churn (no perder clientes en riesgo)
- Considera **F1-Score** para balance
- Revisa **ROC-AUC** para capacidad de discriminaci√≥n

### **2. Tipo de Problema**
- **Ensemble methods** (Random Forest, XGBoost, Gradient Boosting) suelen ganar en problemas tabulares
- **Logistic Regression** es buena para interpretabilidad

### **3. Recursos Computacionales**
- **Random Forest/XGBoost**: M√°s lentos pero m√°s precisos
- **Logistic Regression**: R√°pido y eficiente

### **4. Interpretabilidad**
- **Logistic Regression**: Muy interpretable
- **Decision Tree**: Interpretable
- **Random Forest/XGBoost**: Menos interpretables pero proporcionan feature importance

---

## üîÑ Flujo Completo en Tu Proyecto

```
1. Entrenar 7 modelos baseline
   ‚Üì
2. Evaluar con m√©tricas (Accuracy, Precision, Recall, F1, ROC-AUC)
   ‚Üì
3. Seleccionar los 4 mejores (Logistic Regression, Random Forest, Gradient Boosting, XGBoost)
   ‚Üì
4. Reentrenar con datos balanceados (SMOTE)
   ‚Üì
5. Optimizar hiperpar√°metros del mejor modelo (Random Forest)
   ‚Üì
6. Evaluar modelo final
```

---

## üìù Recomendaciones Pr√°cticas

1. **Siempre entrena m√∫ltiples modelos**: No sabes cu√°l funcionar√° mejor hasta probarlo
2. **Usa validaci√≥n cruzada**: Para evaluaci√≥n m√°s robusta
3. **Considera el contexto de negocio**: En churn, Recall es m√°s importante que Precision
4. **No te cases con un modelo**: Los ensemble methods suelen ganar, pero no siempre
5. **Establece una l√≠nea base simple**: A veces Logistic Regression es suficiente

---

## üéØ Resumen

- **Baseline** = Configuraci√≥n por defecto, sin optimizaci√≥n
- **Prop√≥sito** = Comparar algoritmos y establecer punto de referencia
- **En tu proyecto** = 7 modelos ‚Üí seleccionas 4 mejores ‚Üí optimizas el mejor
- **Criterio principal** = Rendimiento en m√©tricas clave (especialmente Recall para churn)
- **Ganadores t√≠picos** = XGBoost, Random Forest, Gradient Boosting

¬øTe gustar√≠a que profundice en alg√∫n aspecto espec√≠fico, como c√≥mo interpretar las m√©tricas o c√≥mo implementar la selecci√≥n de modelos en tu notebook?
