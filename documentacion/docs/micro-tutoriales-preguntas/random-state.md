---
title: "Â¿QuÃ© es lo que se Aleatoriza con random_state?"
author: "Bootcamp VirtIA - Tutorial Detallado"
date: "`r Sys.Date()`"
output:
  html_document: default
  pdf_document:
    latex_engine: xelatex
    keep_tex: false
    toc: true
    toc_depth: 3
---

# ğŸ² Â¿QuÃ© es lo que se Aleatoriza con `random_state`?

## ğŸ“š DefiniciÃ³n Simple

**`random_state`** es un parÃ¡metro que **controla la aleatoriedad** en algoritmos de machine learning. Funciona como una **semilla** que determina quÃ© nÃºmeros "aleatorios" se generarÃ¡n.

---

## ğŸ” Â¿QuÃ© se Aleatoriza Exactamente?

En el proyecto de churn, `random_state` controla la aleatoriedad en **mÃºltiples procesos**:

### 1. **DivisiÃ³n Train/Test** ğŸ¯

```python
# path=Telco_Customer_Churn.ipynb mode=EXCERPT
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y
)
```

**Â¿QuÃ© se aleatoriza?**

- **QuÃ© filas van a train y cuÃ¡les a test**
- Sin `random_state`: cada ejecuciÃ³n crearÃ­a divisiones diferentes
- Con `random_state=42`: siempre las mismas filas en train/test

**AnalogÃ­a:** Es como barajar un mazo de cartas. Con `random_state=42`, siempre barajas de la misma forma.

---

### 2. **Modelos de Machine Learning** ğŸ¤–

```python
# path=Telco_Customer_Churn.ipynb mode=EXCERPT
models = {
    'Random Forest': RandomForestClassifier(random_state=RANDOM_STATE, n_estimators=100),
    'Gradient Boosting': GradientBoostingClassifier(random_state=RANDOM_STATE),
    'XGBoost': xgb.XGBClassifier(random_state=RANDOM_STATE),
}
```

**Â¿QuÃ© se aleatoriza en cada modelo?**

#### **Random Forest:**

- **SelecciÃ³n aleatoria de features** en cada split
- **SelecciÃ³n aleatoria de muestras** (bootstrap) para cada Ã¡rbol
- **Orden de construcciÃ³n** de los Ã¡rboles

#### **Gradient Boosting:**

- **InicializaciÃ³n de pesos**
- **Muestreo de datos** en cada iteraciÃ³n
- **SelecciÃ³n de features** para cada Ã¡rbol

#### **Logistic Regression:**

- **InicializaciÃ³n de pesos** (cuando usa solver iterativo)
- **Orden de procesamiento** de datos en algunos solvers

---

### 3. **SMOTE (Balanceo de Datos)** âš–ï¸

```python
# path=Telco_Customer_Churn.ipynb mode=EXCERPT
smote = SMOTE(random_state=RANDOM_STATE)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train_processed, y_train)
```

**Â¿QuÃ© se aleatoriza?**

- **SelecciÃ³n de vecinos** para crear ejemplos sintÃ©ticos
- **PosiciÃ³n de los nuevos puntos** entre vecinos
- **Orden de generaciÃ³n** de ejemplos sintÃ©ticos

**Ejemplo:**

```
Cliente A: [tenure=10, MonthlyCharges=50]
Cliente B: [tenure=15, MonthlyCharges=60]

SMOTE crea un punto aleatorio entre A y B:
Cliente SintÃ©tico: [tenure=12.3, MonthlyCharges=54.7]
                                    â†‘ Aleatorio
```

---

### 4. **RandomizedSearchCV (OptimizaciÃ³n)** ğŸ”§

```python
# path=Telco_Customer_Churn.ipynb mode=EXCERPT
random_search = RandomizedSearchCV(
    estimator=rf_base,
    param_distributions=param_distributions,
    n_iter=20,
    cv=3,
    random_state=RANDOM_STATE,
)
```

**Â¿QuÃ© se aleatoriza?**

- **QuÃ© 20 combinaciones** de hiperparÃ¡metros se prueban (de 144 posibles)
- **Orden de evaluaciÃ³n** de las combinaciones

**Ejemplo:**

```
Posibles combinaciones: 144
Con random_state=42, siempre prueba las mismas 20:
  1. n_estimators=200, max_depth=10, ...
  2. n_estimators=100, max_depth=None, ...
  ...
  20. n_estimators=300, max_depth=20, ...
```

---

### 5. **ValidaciÃ³n Cruzada (StratifiedKFold)** ğŸ“Š

```python
# path=Telco_Customer_Churn.ipynb mode=EXCERPT
cv_scores = cross_val_score(best_rf, X_train_balanced, y_train_balanced,
                            cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE),
                            scoring='roc_auc', n_jobs=-1)
```

**Â¿QuÃ© se aleatoriza?**

- **CÃ³mo se dividen los datos** en los 5 folds
- **Orden de las filas** antes de dividir (cuando `shuffle=True`)

---

## ğŸ¯ En el Proyecto: Modo Reproducible vs Experimental

El notebook tiene una configuraciÃ³n especial:

```python
# path=Telco_Customer_Churn.ipynb mode=EXCERPT
REPRODUCIBLE_MODE = False  # True = resultados fijos, False = resultados variables

if REPRODUCIBLE_MODE:
    RANDOM_STATE = 42
    print("ğŸ”’ MODO REPRODUCIBLE ACTIVADO")
else:
    RANDOM_STATE = np.random.randint(0, 10000)
    print("ğŸ”¬ MODO EXPERIMENTAL ACTIVADO")
    print(f"   â†’ Semilla aleatoria: {RANDOM_STATE}")
```

### **Modo Reproducible (RANDOM_STATE = 42):**

âœ… **Ventajas:**

- Resultados idÃ©nticos en cada ejecuciÃ³n
- FÃ¡cil de depurar
- Permite comparar cambios en el cÃ³digo

âŒ **Desventajas:**

- Puede ocultar variabilidad del modelo
- No prueba robustez

### **Modo Experimental (RANDOM_STATE = aleatorio):**

âœ… **Ventajas:**

- Prueba robustez del modelo
- Detecta si resultados dependen de la semilla
- MÃ¡s realista

âŒ **Desventajas:**

- Resultados diferentes cada vez
- DifÃ­cil de reproducir bugs

---

## ğŸ”‘ Conceptos Clave

### 1. **Reproducibilidad**

```python
# EjecuciÃ³n 1 con random_state=42
ROC-AUC: 0.8274

# EjecuciÃ³n 2 con random_state=42
ROC-AUC: 0.8274  # âœ… IdÃ©ntico

# EjecuciÃ³n 3 sin random_state
ROC-AUC: 0.8301  # âŒ Diferente
```

### 2. **NÃºmeros Pseudoaleatorios**

Los nÃºmeros "aleatorios" en computadoras **no son realmente aleatorios**:

```
Semilla 42 â†’ Secuencia: [0.374, 0.950, 0.731, 0.598, ...]
Semilla 42 â†’ Secuencia: [0.374, 0.950, 0.731, 0.598, ...]  # Siempre igual
Semilla 99 â†’ Secuencia: [0.123, 0.456, 0.789, 0.012, ...]  # Diferente
```

### 3. **Â¿Por quÃ© 42?**

Es una **convenciÃ³n** en la comunidad de ML (referencia a "The Hitchhiker's Guide to the Galaxy"). Puedes usar cualquier nÃºmero:

```python
random_state=42   # âœ… ComÃºn
random_state=0    # âœ… TambiÃ©n comÃºn
random_state=123  # âœ… VÃ¡lido
random_state=999  # âœ… VÃ¡lido
```

---

## ğŸ“‹ Resumen Ejecutivo

### Â¿QuÃ© se aleatoriza con `random_state`?

1. **DivisiÃ³n de datos** (train/test, folds)
2. **ConstrucciÃ³n de modelos** (Ã¡rboles, pesos, muestras)
3. **GeneraciÃ³n de datos sintÃ©ticos** (SMOTE)
4. **SelecciÃ³n de hiperparÃ¡metros** (RandomizedSearchCV)
5. **Orden de procesamiento** (shuffle en validaciÃ³n cruzada)

### Â¿CuÃ¡ndo usar `random_state`?

- âœ… **Siempre** en producciÃ³n y experimentos cientÃ­ficos
- âœ… Para **depurar** y comparar modelos
- âœ… Para **reproducir** resultados en papers/reportes

### Â¿CuÃ¡ndo NO usar `random_state`?

- âš ï¸ Para **probar robustez** del modelo
- âš ï¸ Para **validar estabilidad** de resultados
- âš ï¸ En **anÃ¡lisis de sensibilidad**

---

## ğŸ’¡ AnalogÃ­a Final

**`random_state` es como el cÃ³digo de una caja fuerte:**

- **Sin cÃ³digo (sin random_state):** Cada vez que abres la caja, encuentras cosas diferentes
- **Con cÃ³digo 42 (random_state=42):** Siempre encuentras exactamente las mismas cosas en el mismo orden

Â¿Te quedÃ³ claro quÃ© se aleatoriza con `random_state`? ğŸ¤“

