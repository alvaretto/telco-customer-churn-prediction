## 1. Â¿QuÃ© representa este ratio en tÃ©rminos de distribuciÃ³n de clases?

El ratio **2.77:1** significa que por cada **cliente que abandona** (Churn = Yes), hay aproximadamente **2.77 clientes que permanecen** (Churn = No).

**DistribuciÃ³n exacta del dataset:**

- **Clientes que NO abandonaron**: 5,174 (73.46%)
- **Clientes que SÃ abandonaron**: 1,869 (26.54%)
- **Total de clientes**: 7,043

Esto indica un **desbalanceo moderado** donde la clase mayoritaria (No Churn) representa casi 3 veces mÃ¡s casos que la clase minoritaria (Churn).

---

## 2. Â¿CÃ³mo se calcula este ratio de 2.77:1?

El cÃ¡lculo es muy simple y se encuentra en el notebook principal:

```python
print(f"\nRatio de desbalanceo: {churn_counts['No']/churn_counts['Yes']:.2f}:1")
```

**CÃ¡lculo matemÃ¡tico:**
```
Ratio = Clientes No Churn / Clientes Churn
Ratio = 5,174 / 1,869
Ratio = 2.77:1
```

Este cÃ¡lculo se realiza despuÃ©s del anÃ¡lisis exploratorio inicial de datos (EDA) para cuantificar el nivel de desbalanceo.

---

## 3. Â¿QuÃ© implicaciones tiene este desbalanceo para el modelo de ML?

El desbalanceo de 2.77:1 tiene **implicaciones crÃ­ticas** para el entrenamiento del modelo:

### **Problemas que causa:**

1. **Sesgo hacia la clase mayoritaria**: Los modelos tienden a predecir "No Churn" con mÃ¡s frecuencia porque es la clase dominante (73%).

2. **Baja sensibilidad (Recall)**: El modelo puede tener dificultades para detectar clientes que realmente harÃ¡n churn (la clase minoritaria).

3. **MÃ©tricas engaÃ±osas**: Un modelo "ingenuo" que siempre prediga "No Churn" tendrÃ­a un 73% de accuracy, pero serÃ­a completamente inÃºtil para el negocio.

4. **Aprendizaje desigual**: Durante el entrenamiento, el modelo ve muchos mÃ¡s ejemplos de "No Churn", lo que dificulta aprender los patrones de "Churn".

### **AnalogÃ­a del proyecto:**

Como se explica en la documentaciÃ³n:

> **AnalogÃ­a de la enfermedad rara**: Imagina un test mÃ©dico para una enfermedad que solo afecta al 3% de la poblaciÃ³n:

> - Un modelo "tonto" que siempre dice "NO tienes la enfermedad" tendrÃ­a 97% de accuracy
> - Pero serÃ­a inÃºtil porque nunca detectarÃ­a a los enfermos

Lo mismo ocurre con el churn: necesitamos detectar especÃ­ficamente a los que **SÃ se van**, no solo tener alta accuracy general.

---

## 4. Â¿DÃ³nde en el cÃ³digo se identifica o calcula este ratio?

El ratio se calcula en **mÃºltiples puntos** del proyecto:

### **a) AnÃ¡lisis Exploratorio Inicial (EDA)**

En el notebook `Telco_Customer_Churn.ipynb`, despuÃ©s de cargar los datos:

```python
# EstadÃ­sticas
print("\nEstadÃ­sticas de Churn:")
print(f"Total de clientes: {len(df)}")
print(f"Clientes que NO abandonaron: {churn_counts['No']} ({100*churn_counts['No']/len(df):.2f}%)")
print(f"Clientes que SÃ abandonaron: {churn_counts['Yes']} ({100*churn_counts['Yes']/len(df):.2f}%)")
print(f"\nRatio de desbalanceo: {churn_counts['No']/churn_counts['Yes']:.2f}:1")
```

**Salida:**
```
EstadÃ­sticas de Churn:

Total de clientes: 7043
Clientes que NO abandonaron: 5174 (73.46%)
Clientes que SÃ abandonaron: 1869 (26.54%)

Ratio de desbalanceo: 2.77:1
```

### **b) Antes de aplicar SMOTE**

TambiÃ©n se calcula el ratio en el conjunto de entrenamiento antes de balancear:

```python
print("DistribuciÃ³n ANTES de SMOTE:")
print(y_train.value_counts())
print(f"\nRatio: {y_train.value_counts()[0]/y_train.value_counts()[1]:.2f}:1")
```

**Salida:**
```
DistribuciÃ³n ANTES de SMOTE:
Churn
0    4139
1    1495
dtype: int64

Ratio: 2.77:1
```

### **c) DocumentaciÃ³n**

El ratio tambiÃ©n estÃ¡ documentado en:

- `guia_completa_analisis_churn/09_manejo_desbalanceo_clases.md`
- `README.md`
- Visualizaciones (grÃ¡ficos de barras y pie charts)

---

## 5. Â¿QuÃ© tÃ©cnicas se estÃ¡n utilizando para manejar este desbalanceo?

El proyecto utiliza **SMOTE (Synthetic Minority Over-sampling Technique)** como tÃ©cnica principal para manejar el desbalanceo.

### **a) Â¿QuÃ© es SMOTE?**

SMOTE es una tÃ©cnica que **crea ejemplos sintÃ©ticos** de la clase minoritaria (Churn = Yes) para balancear el dataset.

**CÃ³mo funciona:**

1. Toma un ejemplo de la clase minoritaria
2. Encuentra sus K vecinos mÃ¡s cercanos (tambiÃ©n de la clase minoritaria)
3. Crea nuevos ejemplos **interpolando** entre el ejemplo original y sus vecinos

**AnalogÃ­a visual:**
```
Original:  A -------- B
                â†“
SintÃ©tico: A -- X -- B
```
Donde X es un nuevo ejemplo creado "entre" A y B.

### **b) ImplementaciÃ³n en el cÃ³digo**

```python
# Aplicar SMOTE
smote = SMOTE(random_state=42)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train_processed, y_train)
```

**Resultado del balanceo:**

```
DistribuciÃ³n ANTES de SMOTE:
0    4139
1    1495
Ratio: 2.77:1

DistribuciÃ³n DESPUÃ‰S de SMOTE:
0    4139
1    4139
Ratio: 1.00:1
```

SMOTE **duplica la clase minoritaria** creando ejemplos sintÃ©ticos hasta igualar la clase mayoritaria (balance 50/50).

### **c) Â¿Por quÃ© SMOTE y no otras tÃ©cnicas?**

El proyecto considera tres tÃ©cnicas principales:

| TÃ©cnica | DescripciÃ³n | Ventajas | Desventajas |
|---------|-------------|----------|-------------|
| **SMOTE** âœ… | Crea ejemplos sintÃ©ticos | Ejemplos realistas, no duplicados | Puede crear ejemplos en zonas de solapamiento |
| **RandomOverSampler** | Duplica ejemplos existentes | Simple | Puede causar overfitting |
| **RandomUnderSampler** | Elimina ejemplos de clase mayoritaria | Reduce tamaÃ±o del dataset | Pierde informaciÃ³n valiosa |

**SMOTE es la mejor opciÃ³n** porque:

- âœ… Crea ejemplos realistas (no duplicados)
- âœ… Aumenta la diversidad de la clase minoritaria
- âœ… No pierde informaciÃ³n de la clase mayoritaria
- âœ… Mejora el aprendizaje del modelo

### **d) Regla importante: SMOTE solo en entrenamiento**

**Importante**: SMOTE solo se aplica al conjunto de **entrenamiento**, NUNCA al de prueba.

**Â¿Por quÃ©?**

**AnalogÃ­a del examen**:

- Puedes estudiar con material adicional (SMOTE en train)
- Pero el examen debe ser con preguntas reales (test sin modificar)

### **e) Impacto de SMOTE en las mÃ©tricas**

**ComparaciÃ³n de resultados:**

| Modelo | MÃ©trica | Sin SMOTE | Con SMOTE | Mejora |
|--------|---------|-----------|-----------|--------|
| Random Forest | **Recall** | ~50% | ~78% | **+28%** |
| XGBoost | **Recall** | ~52% | ~80% | **+28%** |
| Logistic Regression | **Recall** | ~45% | ~81% | **+36%** |

**InterpretaciÃ³n:**

- **Recall aumenta significativamente** (~30% de mejora): El modelo detecta muchos mÃ¡s clientes que harÃ¡n churn
- **Accuracy baja ligeramente** (84% â†’ 82%): Trade-off aceptable
- **Precision baja un poco** (70% â†’ 65%): MÃ¡s falsos positivos, pero aceptable para el negocio

### **f) Otras tÃ©cnicas consideradas (pero no implementadas)**

El proyecto tambiÃ©n importa otras tÃ©cnicas de balanceo:

```python
# Manejo de desbalanceo
from imblearn.over_sampling import SMOTE, RandomOverSampler
from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import Pipeline as ImbPipeline
```

Aunque estÃ¡n disponibles, **SMOTE es la Ãºnica tÃ©cnica aplicada** porque ofrece el mejor balance entre rendimiento y realismo de los datos sintÃ©ticos.

---

## ğŸ“Š Resumen Visual

SegÃºn la imagen que compartiste:

```
DistribuciÃ³n de Churn:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ No:  5174 (73.5%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â”‚
â”‚ Yes: 1869 (26.5%) â–ˆâ–ˆâ–ˆ       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Ratio de desbalanceo: 2.77:1
```

**ConclusiÃ³n:** El ratio de 2.77:1 es un desbalanceo moderado que requiere atenciÃ³n especial. SMOTE resuelve este problema eficazmente, mejorando el Recall en ~30% y permitiendo que el modelo detecte mejor a los clientes en riesgo de churn, que es el objetivo principal del negocio.
