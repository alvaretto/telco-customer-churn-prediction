# üöÄ DEPLOYMENT PASO A PASO - RENDER + STREAMLIT CLOUD

## üìã PREREQUISITOS

- [x] Cuenta de GitHub (ya tienes)
- [x] Repositorio pushed a GitHub (ya tienes)
- [x] Git LFS configurado (ya tienes)
- [ ] Cuenta en Render.com (crear gratis)
- [ ] Cuenta en Streamlit Cloud (usar GitHub para login)

---

## PARTE 1: DEPLOY API EN RENDER (10-15 minutos)

### Paso 1: Crear cuenta en Render

1. Ir a **https://render.com**
2. Click en **"Get Started"**
3. **Sign up with GitHub** (recomendado)
4. Autorizar Render a acceder a tus repos

### Paso 2: Crear Web Service

1. En el dashboard de Render, click **"New +"** ‚Üí **"Web Service"**
2. Click **"Connect a repository"**
3. Si no ves tu repo:
   - Click **"Configure account"**
   - Seleccionar **"All repositories"** o solo tu repo
   - Click **"Save"**
4. Buscar y seleccionar: **`telco-customer-churn-prediction`**
5. Click **"Connect"**

### Paso 3: Configurar el servicio

**Configuraci√≥n b√°sica:**
```
Name: telco-churn-api
Region: Oregon (US West) o el m√°s cercano
Branch: main
Root Directory: api
Runtime: Python 3
```

**Build & Deploy:**
```
Build Command: pip install -r requirements.txt
Start Command: gunicorn --bind 0.0.0.0:$PORT --workers 2 --threads 2 --timeout 60 app:app
```

**Instance Type:**
```
Free
```

### Paso 4: Variables de entorno (IMPORTANTE)

Click en **"Advanced"** ‚Üí **"Add Environment Variable"**

Agregar:
```
Key: PYTHON_VERSION
Value: 3.10.0
```

### Paso 5: Deploy

1. Click **"Create Web Service"**
2. Render comenzar√° a:
   - Clonar tu repo
   - Descargar archivos de Git LFS (modelo de 65 MB)
   - Instalar dependencias
   - Iniciar la aplicaci√≥n
3. **Esperar 5-10 minutos** (primera vez es m√°s lento)
4. Ver logs en tiempo real en la p√°gina

### Paso 6: Verificar deployment

Una vez que veas **"Your service is live üéâ"**:

1. Copiar la URL (algo como: `https://telco-churn-api.onrender.com`)
2. Probar endpoints:

```bash
# Health check
curl https://telco-churn-api.onrender.com/health

# Model info
curl https://telco-churn-api.onrender.com/model_info

# Prediction (ejemplo)
curl -X POST https://telco-churn-api.onrender.com/predict \
  -H "Content-Type: application/json" \
  -d '{
    "gender": "Female",
    "SeniorCitizen": 0,
    "Partner": "Yes",
    "Dependents": "No",
    "tenure": 12,
    "PhoneService": "Yes",
    "MultipleLines": "No",
    "InternetService": "Fiber optic",
    "OnlineSecurity": "No",
    "OnlineBackup": "No",
    "DeviceProtection": "No",
    "TechSupport": "No",
    "StreamingTV": "No",
    "StreamingMovies": "No",
    "Contract": "Month-to-month",
    "PaperlessBilling": "Yes",
    "PaymentMethod": "Electronic check",
    "MonthlyCharges": 70.35,
    "TotalCharges": 844.2,
    "tenure_group": "6-12 months",
    "TotalServices": 1,
    "AvgChargePerService": 70.35,
    "ChargeToTenureRatio": 5.86,
    "HasMultipleServices": 0,
    "HasStreamingServices": 0
  }'
```

### Paso 7: Guardar URL

Guardar la URL de tu API para usarla en el Dashboard.

---

## PARTE 2: DEPLOY DASHBOARD EN STREAMLIT CLOUD (5-10 minutos)

### Paso 1: Ir a Streamlit Cloud

1. Ir a **https://share.streamlit.io**
2. Click **"Sign in"**
3. **Continue with GitHub**
4. Autorizar Streamlit

### Paso 2: Crear nueva app

1. Click **"New app"**
2. Configurar:

```
Repository: alvaretto/telco-customer-churn-prediction
Branch: main
Main file path: dashboard/app.py
App URL (custom): telco-churn-dashboard (o el que prefieras)
```

3. Click **"Advanced settings"** (opcional):

```
Python version: 3.10
```

### Paso 3: Deploy

1. Click **"Deploy!"**
2. Streamlit comenzar√° a:
   - Clonar tu repo
   - Descargar archivos de Git LFS
   - Instalar dependencias de `dashboard/requirements.txt`
   - Ejecutar `dashboard/app.py`
3. **Esperar 3-5 minutos**
4. Ver logs en tiempo real

### Paso 4: Verificar dashboard

Una vez que veas la app corriendo:

1. Explorar las p√°ginas:
   - üè† Home
   - üìä Overview
   - üéØ Risk Analysis (probar predicci√≥n)
   - üìà Model Metrics
   - üí∞ ROI Simulator
   - üîç Model Monitoring

2. Probar predicci√≥n en **Risk Analysis**:
   - Llenar formulario
   - Click "Predict Churn Risk"
   - Ver resultado

### Paso 5: Configurar API URL (si es necesario)

Si el dashboard necesita conectarse a la API:

1. En Streamlit Cloud, ir a **"Settings"** ‚Üí **"Secrets"**
2. Agregar:

```toml
[api]
url = "https://telco-churn-api.onrender.com"
```

3. Guardar y redeploy

---

## PARTE 3: VERIFICACI√ìN FINAL (5 minutos)

### Checklist de verificaci√≥n:

- [ ] API responde en `/health`
- [ ] API responde en `/model_info`
- [ ] API puede hacer predicciones en `/predict`
- [ ] Dashboard carga correctamente
- [ ] Dashboard puede hacer predicciones
- [ ] Todas las p√°ginas del dashboard funcionan
- [ ] M√©tricas del modelo se muestran correctamente

### URLs finales:

```
API: https://telco-churn-api.onrender.com
Dashboard: https://telco-churn-dashboard.streamlit.app
GitHub: https://github.com/alvaretto/telco-customer-churn-prediction
```

---

## üêõ TROUBLESHOOTING

### Problema: "Build failed" en Render

**Soluci√≥n**:
1. Ver logs completos
2. Verificar que `api/requirements.txt` existe
3. Verificar que `PYTHON_VERSION=3.10.0` est√° configurado
4. Verificar que Git LFS est√° funcionando (archivos .pkl deben descargarse)

### Problema: "Application error" en Render

**Soluci√≥n**:
1. Ver logs de runtime
2. Verificar que el modelo se carg√≥ correctamente
3. Verificar que el puerto est√° configurado correctamente (`$PORT`)

### Problema: "ModuleNotFoundError" en Streamlit

**Soluci√≥n**:
1. Verificar que `dashboard/requirements.txt` tiene todas las dependencias
2. Verificar que la ruta del archivo es `dashboard/app.py`
3. Redeploy

### Problema: "Model not found" en Dashboard

**Soluci√≥n**:
1. Verificar que Git LFS est√° configurado
2. Verificar que los archivos `.pkl` est√°n en `models/`
3. Verificar rutas relativas en el c√≥digo

---

## üìä MONITOREO

### Render:
- **Logs**: Dashboard ‚Üí Logs (tiempo real)
- **Metrics**: Dashboard ‚Üí Metrics (CPU, RAM, requests)
- **Restart**: Dashboard ‚Üí Manual Deploy ‚Üí "Clear build cache & deploy"

### Streamlit Cloud:
- **Logs**: App ‚Üí Manage app ‚Üí Logs
- **Reboot**: App ‚Üí Manage app ‚Üí Reboot app
- **Redeploy**: Push a GitHub ‚Üí auto-redeploy

---

## üîÑ ACTUALIZAR MODELO

Cuando reentrenar el modelo en Colab:

1. **En Colab**: Entrenar y serializar nuevo modelo
2. **Local**: Descargar y reemplazar archivos en `models/`
3. **Git**:
   ```bash
   git add models/
   git commit -m "feat: Actualizar modelo v2"
   git push origin main
   ```
4. **Render**: Auto-redeploy (o manual)
5. **Streamlit**: Auto-redeploy

---

## ‚úÖ ¬°LISTO!

Tu proyecto est√° deployado y accesible p√∫blicamente. Puedes:
- Compartir las URLs
- Demostrar el proyecto
- Presentar en el bootcamp
- Agregar al portfolio

**Pr√≥ximos pasos opcionales**:
- Configurar dominio custom
- Agregar autenticaci√≥n
- Implementar CI/CD con GitHub Actions
- Agregar monitoreo con Sentry
- Escalar a plan pago si es necesario

