---
title: "Adaptaci√≥n del Notebook Telco Customer Churn - Comparativa de T√©cnicas de Balanceo"
output:
  html_document: default
  pdf_document:
    latex_engine: xelatex
    keep_tex: false
---

# üìä Adaptaci√≥n del Notebook para Google Colab con Comparativa de T√©cnicas de Balanceo

## üìã Resumen Ejecutivo

Este documento proporciona una gu√≠a completa y detallada para adaptar el notebook `Telco_Customer_Churn.ipynb` con las siguientes mejoras:

**‚úÖ Implementaciones Principales:**

- Comparativa autom√°tica de 3 t√©cnicas de balanceo (SMOTE, SMOTE + Tomek Link, Undersampling)
- Selecci√≥n autom√°tica de la mejor t√©cnica basada en ROC-AUC
- Visualizaciones comparativas interactivas (4 gr√°ficos)
- Informe Markdown autom√°tico con secci√≥n de comparativa
- Metadata enriquecida con informaci√≥n de balanceo
- 100% compatible con Google Colab

**üìä M√©tricas de Evaluaci√≥n:**

- ROC-AUC (m√©trica principal de selecci√≥n)
- F1-Score, Precision, Recall
- Tiempo de procesamiento
- N√∫mero de muestras de entrenamiento

**üéØ Resultado Final:**

El sistema evaluar√° las tres t√©cnicas, seleccionar√° autom√°ticamente la mejor y generar√° un informe completo con justificaci√≥n, m√©tricas comparativas y recomendaciones de uso.

---

## üéØ Objetivo

Adaptar el notebook `Telco_Customer_Churn.ipynb` para ejecutarse 100% en Google Colab, implementando y comparando tres t√©cnicas de balanceo de clases:

- **SMOTE** (Synthetic Minority Over-sampling Technique)
- **SMOTE + Tomek Link** (Combinaci√≥n de over-sampling y under-sampling)
- **Undersampling** (Random Under-sampling)

El sistema seleccionar√° autom√°ticamente la mejor t√©cnica bas√°ndose en m√©tricas de rendimiento y generar√° un informe comparativo detallado.

---

## üìã An√°lisis del Notebook Actual

### Estructura Identificada

El notebook actual tiene la siguiente estructura:

1. **Secci√≥n 0**: Importaci√≥n de librer√≠as
2. **Secci√≥n 0.1**: Configuraci√≥n de reproducibilidad
3. **Secci√≥n 1**: Carga y exploraci√≥n de datos
4. **Secci√≥n 2-6**: EDA y preprocesamiento
5. **Secci√≥n 7**: Manejo de desbalanceo (actualmente solo SMOTE)
6. **Secci√≥n 8**: Optimizaci√≥n de hiperpar√°metros
7. **Secci√≥n 9-10**: Evaluaci√≥n y an√°lisis de features
8. **Secci√≥n 11**: Guardado de modelo
9. **Secci√≥n 13**: Generaci√≥n de informe autom√°tico

### Puntos Clave Identificados

**Importaciones actuales (l√≠neas 105-107):**

```python
from imblearn.over_sampling import SMOTE, RandomOverSampler
from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import Pipeline as ImbPipeline
```

**Aplicaci√≥n de SMOTE (l√≠neas 2223-2240):**

```python
smote = SMOTE(random_state=RANDOM_STATE)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train_processed, y_train)
```

**Guardado de modelo (l√≠neas 3297-3577):**

Secci√≥n completa que guarda el modelo en Google Drive con verificaci√≥n de tama√±o.

**Generaci√≥n de informe (l√≠neas 3643-3690):**

Genera un informe Markdown autom√°tico con m√©tricas y conclusiones.

---

## üîß Modificaciones Necesarias

### 1. Actualizaci√≥n de Importaciones

**Ubicaci√≥n:** Celda de importaciones (l√≠nea 105)

**C√≥digo a agregar:**

```python
# Manejo de desbalanceo - AMPLIADO
from imblearn.over_sampling import SMOTE, RandomOverSampler
from imblearn.under_sampling import RandomUnderSampler
from imblearn.combine import SMOTETomek  # ‚Üê NUEVO
from imblearn.pipeline import Pipeline as ImbPipeline
```

---

### 2. Nueva Secci√≥n: Comparativa de T√©cnicas de Balanceo

**Ubicaci√≥n:** Reemplazar la Secci√≥n 7 actual (l√≠neas 2177-2241)

**T√≠tulo de la secci√≥n:**

```markdown
## 7. Comparativa de T√©cnicas de Balanceo de Clases

El dataset presenta un desbalanceo significativo (73% No Churn vs 27% Churn). 
Evaluaremos tres t√©cnicas diferentes de balanceo y seleccionaremos autom√°ticamente la mejor:

- **SMOTE**: Genera muestras sint√©ticas de la clase minoritaria
- **SMOTE + Tomek Link**: Combina SMOTE con limpieza de muestras ruidosas
- **Undersampling**: Reduce la clase mayoritaria al tama√±o de la minoritaria
```

**C√≥digo de implementaci√≥n:**

```python
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from imblearn.combine import SMOTETomek
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
import time

print("="*80)
print("üîÑ COMPARATIVA DE T√âCNICAS DE BALANCEO")
print("="*80)
print(f"\nüé≤ Usando semilla: {RANDOM_STATE}\n")

# Distribuci√≥n original
print("üìä DISTRIBUCI√ìN ORIGINAL:")
print(f"   Clase 0 (No Churn): {y_train.value_counts()[0]:,} muestras")
print(f"   Clase 1 (Churn):    {y_train.value_counts()[1]:,} muestras")
print(f"   Ratio: {y_train.value_counts()[0]/y_train.value_counts()[1]:.2f}:1")
print()

# Diccionario para almacenar resultados
balancing_results = {}

# ============================================================================
# T√âCNICA 1: SMOTE
# ============================================================================
print("="*80)
print("1Ô∏è‚É£  T√âCNICA: SMOTE (Synthetic Minority Over-sampling)")
print("="*80)
```


start_time = time.time()
smote = SMOTE(random_state=RANDOM_STATE)
X_train_smote, y_train_smote = smote.fit_resample(X_train_processed, y_train)
smote_time = time.time() - start_time

print(f"‚è±Ô∏è  Tiempo de procesamiento: {smote_time:.2f} segundos")
print(f"üìä Distribuci√≥n despu√©s de SMOTE:")
print(f"   Clase 0: {pd.Series(y_train_smote).value_counts()[0]:,} muestras")
print(f"   Clase 1: {pd.Series(y_train_smote).value_counts()[1]:,} muestras")
print(f"   Ratio: {pd.Series(y_train_smote).value_counts()[0]/pd.Series(y_train_smote).value_counts()[1]:.2f}:1")
print(f"   Total de muestras: {len(y_train_smote):,}")
print()

# ============================================================================
# T√âCNICA 2: SMOTE + Tomek Link
# ============================================================================
print("="*80)
print("2Ô∏è‚É£  T√âCNICA: SMOTE + Tomek Link (H√≠brida)")
print("="*80)

start_time = time.time()
smote_tomek = SMOTETomek(random_state=RANDOM_STATE)
X_train_smote_tomek, y_train_smote_tomek = smote_tomek.fit_resample(X_train_processed, y_train)
smote_tomek_time = time.time() - start_time

print(f"‚è±Ô∏è  Tiempo de procesamiento: {smote_tomek_time:.2f} segundos")
print(f"üìä Distribuci√≥n despu√©s de SMOTE + Tomek:")
print(f"   Clase 0: {pd.Series(y_train_smote_tomek).value_counts()[0]:,} muestras")
print(f"   Clase 1: {pd.Series(y_train_smote_tomek).value_counts()[1]:,} muestras")
print(f"   Ratio: {pd.Series(y_train_smote_tomek).value_counts()[0]/pd.Series(y_train_smote_tomek).value_counts()[1]:.2f}:1")
print(f"   Total de muestras: {len(y_train_smote_tomek):,}")
print(f"   üí° Tomek Links eliminados: {len(y_train_smote) - len(y_train_smote_tomek):,} muestras")
print()

# ============================================================================
# T√âCNICA 3: Undersampling
# ============================================================================
print("="*80)
print("3Ô∏è‚É£  T√âCNICA: Random Undersampling")
print("="*80)

start_time = time.time()
undersampler = RandomUnderSampler(random_state=RANDOM_STATE)
X_train_under, y_train_under = undersampler.fit_resample(X_train_processed, y_train)
under_time = time.time() - start_time

print(f"‚è±Ô∏è  Tiempo de procesamiento: {under_time:.2f} segundos")
print(f"üìä Distribuci√≥n despu√©s de Undersampling:")
print(f"   Clase 0: {pd.Series(y_train_under).value_counts()[0]:,} muestras")
print(f"   Clase 1: {pd.Series(y_train_under).value_counts()[1]:,} muestras")
print(f"   Ratio: {pd.Series(y_train_under).value_counts()[0]/pd.Series(y_train_under).value_counts()[1]:.2f}:1")
print(f"   Total de muestras: {len(y_train_under):,}")
print(f"   üí° Muestras eliminadas: {len(y_train) - len(y_train_under):,}")
print()

# ============================================================================
# EVALUACI√ìN DE CADA T√âCNICA
# ============================================================================
print("="*80)
print("üìä EVALUACI√ìN DE RENDIMIENTO POR T√âCNICA")
print("="*80)
print()

# Modelo base para evaluaci√≥n (Random Forest)
from sklearn.ensemble import RandomForestClassifier

techniques = {
    'SMOTE': (X_train_smote, y_train_smote, smote_time),
    'SMOTE + Tomek': (X_train_smote_tomek, y_train_smote_tomek, smote_tomek_time),
    'Undersampling': (X_train_under, y_train_under, under_time)
}

for technique_name, (X_bal, y_bal, proc_time) in techniques.items():
    print(f"\n{'='*80}")
    print(f"üîç Evaluando: {technique_name}")
    print(f"{'='*80}")

    # Entrenar modelo
    rf_model = RandomForestClassifier(
        n_estimators=100,
        random_state=RANDOM_STATE,
        n_jobs=-1
    )

    train_start = time.time()
    rf_model.fit(X_bal, y_bal)
    train_time = time.time() - train_start

    # Predicciones
    y_pred = rf_model.predict(X_test_processed)
    y_pred_proba = rf_model.predict_proba(X_test_processed)[:, 1]

    # Calcular m√©tricas
    metrics = {
        'technique': technique_name,
        'accuracy': accuracy_score(y_test, y_pred),
        'precision': precision_score(y_test, y_pred),
        'recall': recall_score(y_test, y_pred),
        'f1': f1_score(y_test, y_pred),
        'roc_auc': roc_auc_score(y_test, y_pred_proba),
        'processing_time': proc_time,
        'training_time': train_time,
        'total_time': proc_time + train_time,
        'train_samples': len(y_bal),
        'X_train': X_bal,
        'y_train': y_bal,
        'model': rf_model
    }

    balancing_results[technique_name] = metrics

    # Mostrar resultados
    print(f"   Accuracy:  {metrics['accuracy']:.4f}")
    print(f"   Precision: {metrics['precision']:.4f}")
    print(f"   Recall:    {metrics['recall']:.4f}")
    print(f"   F1-Score:  {metrics['f1']:.4f}")
    print(f"   ROC-AUC:   {metrics['roc_auc']:.4f}")
    print(f"   ‚è±Ô∏è  Tiempo total: {metrics['total_time']:.2f}s (Balanceo: {proc_time:.2f}s + Entrenamiento: {train_time:.2f}s)")
    print(f"   üìä Muestras de entrenamiento: {metrics['train_samples']:,}")

# ============================================================================
# SELECCI√ìN AUTOM√ÅTICA DE LA MEJOR T√âCNICA
# ============================================================================
print("\n" + "="*80)
print("üèÜ SELECCI√ìN AUTOM√ÅTICA DE LA MEJOR T√âCNICA")
print("="*80)
print()

# Crear DataFrame comparativo
comparison_df = pd.DataFrame([
    {
        'T√©cnica': name,
        'Accuracy': metrics['accuracy'],
        'Precision': metrics['precision'],
        'Recall': metrics['recall'],
        'F1-Score': metrics['f1'],
        'ROC-AUC': metrics['roc_auc'],
        'Tiempo (s)': metrics['total_time'],
        'Muestras': metrics['train_samples']
    }
    for name, metrics in balancing_results.items()
])

print("üìä TABLA COMPARATIVA:")
print()
print(comparison_df.to_string(index=False))
print()

# Criterio de selecci√≥n: ROC-AUC (m√©trica principal para clasificaci√≥n desbalanceada)
best_technique_name = comparison_df.loc[comparison_df['ROC-AUC'].idxmax(), 'T√©cnica']
best_metrics = balancing_results[best_technique_name]

print("="*80)
print(f"‚úÖ MEJOR T√âCNICA SELECCIONADA: {best_technique_name}")
print("="*80)
print()
print(f"üìà M√©tricas de la mejor t√©cnica:")
print(f"   ‚Ä¢ ROC-AUC:   {best_metrics['roc_auc']:.4f} ‚≠ê")
print(f"   ‚Ä¢ F1-Score:  {best_metrics['f1']:.4f}")
print(f"   ‚Ä¢ Precision: {best_metrics['precision']:.4f}")
print(f"   ‚Ä¢ Recall:    {best_metrics['recall']:.4f}")
print(f"   ‚Ä¢ Accuracy:  {best_metrics['accuracy']:.4f}")
print()
print(f"‚è±Ô∏è  Eficiencia:")
print(f"   ‚Ä¢ Tiempo total: {best_metrics['total_time']:.2f} segundos")
print(f"   ‚Ä¢ Muestras de entrenamiento: {best_metrics['train_samples']:,}")
print()

# Asignar los mejores datos balanceados para uso posterior
X_train_balanced = best_metrics['X_train']
y_train_balanced = best_metrics['y_train']
best_balancing_technique = best_technique_name

print(f"üíæ Variables actualizadas:")
print(f"   ‚Ä¢ X_train_balanced: {X_train_balanced.shape}")
print(f"   ‚Ä¢ y_train_balanced: {len(y_train_balanced):,} muestras")
print(f"   ‚Ä¢ best_balancing_technique: '{best_balancing_technique}'")
print()
```

---

## 3. Modificaci√≥n de la Secci√≥n de Guardado de Modelo

**Ubicaci√≥n:** Secci√≥n 11 (l√≠neas 3297-3577)

**Modificaci√≥n:** Agregar informaci√≥n sobre la t√©cnica de balanceo seleccionada en los metadatos.

**C√≥digo a modificar en la secci√≥n de metadata (aproximadamente l√≠nea 3440):**

```python
# 3. Guardar metadata
print("3Ô∏è‚É£  Guardando metadata...")
metadata = {
    'model_type': 'Random Forest Classifier',
    'sklearn_version': sklearn.__version__,
    'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
    'random_state': RANDOM_STATE,
    'balancing_technique': best_balancing_technique,  # ‚Üê NUEVO
    'balancing_comparison': {  # ‚Üê NUEVO
        technique: {
            'roc_auc': metrics['roc_auc'],
            'f1_score': metrics['f1'],
            'precision': metrics['precision'],
            'recall': metrics['recall'],
            'training_samples': metrics['train_samples']
        }
        for technique, metrics in balancing_results.items()
    },
    'features': list(X_train_processed.columns),
    'n_features': X_train_processed.shape[1],
    'best_params': best_rf.get_params(),
    'performance': {
        'accuracy': best_model_metrics['accuracy'],
        'precision': best_model_metrics['precision'],
        'recall': best_model_metrics['recall'],
        'f1_score': best_model_metrics['f1'],
        'roc_auc': best_model_metrics['roc_auc']
    }
}
```

---

## 4. Modificaci√≥n de la Generaci√≥n de Informe

**Ubicaci√≥n:** Secci√≥n 13 (l√≠neas 3643-3690)

**Modificaci√≥n:** Agregar secci√≥n comparativa de t√©cnicas de balanceo en el informe.

**C√≥digo a agregar despu√©s de la secci√≥n de m√©tricas (aproximadamente l√≠nea 3850):**

```python
# Agregar secci√≥n de comparativa de balanceo al informe
report_content += f"""
---

## 4. ‚öñÔ∏è Comparativa de T√©cnicas de Balanceo

### T√©cnicas Evaluadas

Se evaluaron tres t√©cnicas diferentes de balanceo de clases para manejar el desbalanceo del dataset (73% No Churn vs 27% Churn):

1. **SMOTE (Synthetic Minority Over-sampling Technique)**

   - Genera muestras sint√©ticas de la clase minoritaria
   - Aumenta el tama√±o del dataset de entrenamiento
   - Preserva toda la informaci√≥n de la clase mayoritaria

2. **SMOTE + Tomek Link (T√©cnica H√≠brida)**

   - Combina SMOTE con limpieza de muestras ruidosas
   - Elimina pares de Tomek Links (muestras cercanas de clases diferentes)
   - Mejora la separabilidad entre clases

3. **Random Undersampling**

   - Reduce aleatoriamente la clase mayoritaria
   - Reduce el tama√±o del dataset de entrenamiento
   - M√°s r√°pido pero puede perder informaci√≥n valiosa

### Resultados Comparativos

| T√©cnica | ROC-AUC | F1-Score | Precision | Recall | Muestras | Tiempo (s) |
|---------|---------|----------|-----------|--------|----------|------------|
"""

# Agregar filas de la tabla comparativa
for technique_name, metrics in balancing_results.items():
    report_content += f"| {technique_name} | {metrics['roc_auc']:.4f} | {metrics['f1']:.4f} | {metrics['precision']:.4f} | {metrics['recall']:.4f} | {metrics['train_samples']:,} | {metrics['total_time']:.2f} |\n"

report_content += f"""
### üèÜ T√©cnica Seleccionada: {best_balancing_technique}

**Justificaci√≥n de la selecci√≥n:**

La t√©cnica **{best_balancing_technique}** fue seleccionada autom√°ticamente bas√°ndose en la m√©trica ROC-AUC, que es la m√°s apropiada para problemas de clasificaci√≥n desbalanceada.

**Ventajas de {best_balancing_technique}:**

"""

# Agregar ventajas espec√≠ficas seg√∫n la t√©cnica seleccionada
if best_balancing_technique == 'SMOTE':
    report_content += """
- ‚úÖ Genera muestras sint√©ticas realistas de la clase minoritaria
- ‚úÖ Preserva toda la informaci√≥n de la clase mayoritaria
- ‚úÖ Mejora significativamente la detecci√≥n de churns (recall)
- ‚úÖ Balance √≥ptimo entre rendimiento y tiempo de procesamiento
"""
elif best_balancing_technique == 'SMOTE + Tomek':
    report_content += """
- ‚úÖ Combina las ventajas de SMOTE con limpieza de datos
- ‚úÖ Elimina muestras ruidosas en la frontera de decisi√≥n
- ‚úÖ Mejora la separabilidad entre clases
- ‚úÖ Mayor precisi√≥n en las predicciones
- ‚ö†Ô∏è  Tiempo de procesamiento ligeramente mayor
"""
else:  # Undersampling
    report_content += """
- ‚úÖ Procesamiento muy r√°pido
- ‚úÖ Reduce el tama√±o del dataset (√∫til para datasets grandes)
- ‚úÖ Evita el overfitting al reducir muestras redundantes
- ‚ö†Ô∏è  Puede perder informaci√≥n valiosa de la clase mayoritaria
"""

report_content += f"""
**M√©tricas de rendimiento:**

- ROC-AUC: **{best_metrics['roc_auc']:.4f}** ‚≠ê
- F1-Score: **{best_metrics['f1']:.4f}**
- Precision: **{best_metrics['precision']:.4f}**
- Recall: **{best_metrics['recall']:.4f}**
- Tiempo total: **{best_metrics['total_time']:.2f} segundos**

### üìä An√°lisis Comparativo

"""

# An√°lisis autom√°tico de diferencias
best_roc = best_metrics['roc_auc']
techniques_sorted = sorted(balancing_results.items(), key=lambda x: x[1]['roc_auc'], reverse=True)

if len(techniques_sorted) > 1:
    second_best = techniques_sorted[1]
    diff_roc = (best_roc - second_best[1]['roc_auc']) * 100

    if diff_roc < 0.5:
        report_content += f"""
**Diferencia marginal:** La diferencia entre {best_balancing_technique} y {second_best[0]} es de solo {diff_roc:.2f}% en ROC-AUC. Ambas t√©cnicas son igualmente v√°lidas.
"""
    elif diff_roc < 2:
        report_content += f"""
**Ventaja moderada:** {best_balancing_technique} supera a {second_best[0]} por {diff_roc:.2f}% en ROC-AUC, mostrando una mejora notable.
"""
    else:
        report_content += f"""
**Ventaja significativa:** {best_balancing_technique} supera a {second_best[0]} por {diff_roc:.2f}% en ROC-AUC, demostrando una clara superioridad.
"""

# An√°lisis de eficiencia
fastest = min(balancing_results.items(), key=lambda x: x[1]['total_time'])
slowest = max(balancing_results.items(), key=lambda x: x[1]['total_time'])
time_diff = slowest[1]['total_time'] - fastest[1]['total_time']

report_content += f"""
**Eficiencia computacional:**

- T√©cnica m√°s r√°pida: **{fastest[0]}** ({fastest[1]['total_time']:.2f}s)
- T√©cnica m√°s lenta: **{slowest[0]}** ({slowest[1]['total_time']:.2f}s)
- Diferencia: {time_diff:.2f} segundos

"""

# Recomendaciones seg√∫n el contexto
report_content += """
### üí° Recomendaciones de Uso

**Cu√°ndo usar cada t√©cnica:**

**SMOTE:**

- Dataset peque√±o o mediano (< 100,000 muestras)
- Se requiere maximizar recall (detectar todos los churns posibles)
- Tiempo de procesamiento no es cr√≠tico

**SMOTE + Tomek Link:**

- Dataset con posible ruido en las fronteras de decisi√≥n
- Se requiere maximizar precision (minimizar falsos positivos)
- Se dispone de recursos computacionales adecuados

**Undersampling:**

- Dataset muy grande (> 100,000 muestras)
- Recursos computacionales limitados
- Tiempo de procesamiento es cr√≠tico
- La clase mayoritaria tiene muchas muestras redundantes

"""
```

---

## 5. Visualizaci√≥n Comparativa de T√©cnicas de Balanceo

**Nueva celda a agregar despu√©s de la selecci√≥n de la mejor t√©cnica:**

```python
# ============================================================================
# VISUALIZACI√ìN COMPARATIVA
# ============================================================================

import matplotlib.pyplot as plt
import seaborn as sns

fig, axes = plt.subplots(2, 2, figsize=(16, 12))
fig.suptitle('üìä Comparativa de T√©cnicas de Balanceo de Clases',
             fontsize=16, fontweight='bold', y=1.00)

# Colores para cada t√©cnica
colors = {
    'SMOTE': '#3498db',
    'SMOTE + Tomek': '#e74c3c',
    'Undersampling': '#2ecc71'
}

# 1. Comparaci√≥n de m√©tricas
ax1 = axes[0, 0]
metrics_comparison = comparison_df.set_index('T√©cnica')[['ROC-AUC', 'F1-Score', 'Precision', 'Recall']]
metrics_comparison.plot(kind='bar', ax=ax1, color=['#3498db', '#e74c3c', '#f39c12', '#9b59b6'])
ax1.set_title('Comparaci√≥n de M√©tricas de Rendimiento', fontweight='bold', fontsize=12)
ax1.set_ylabel('Score', fontweight='bold')
ax1.set_xlabel('')
ax1.legend(loc='lower right', framealpha=0.9)
ax1.grid(axis='y', alpha=0.3)
ax1.set_ylim([0, 1])
ax1.axhline(y=0.8, color='red', linestyle='--', alpha=0.5, label='Umbral 0.8')

# Rotar etiquetas
ax1.set_xticklabels(ax1.get_xticklabels(), rotation=45, ha='right')

# 2. Distribuci√≥n de muestras
ax2 = axes[0, 1]
samples_data = {
    'Original': len(y_train),
    'SMOTE': balancing_results['SMOTE']['train_samples'],
    'SMOTE + Tomek': balancing_results['SMOTE + Tomek']['train_samples'],
    'Undersampling': balancing_results['Undersampling']['train_samples']
}
bars = ax2.bar(samples_data.keys(), samples_data.values(),
               color=['#95a5a6', '#3498db', '#e74c3c', '#2ecc71'])
ax2.set_title('N√∫mero de Muestras de Entrenamiento', fontweight='bold', fontsize=12)
ax2.set_ylabel('N√∫mero de Muestras', fontweight='bold')
ax2.grid(axis='y', alpha=0.3)

# Agregar valores en las barras
for bar in bars:
    height = bar.get_height()
    ax2.text(bar.get_x() + bar.get_width()/2., height,
             f'{int(height):,}',
             ha='center', va='bottom', fontweight='bold')

ax2.set_xticklabels(ax2.get_xticklabels(), rotation=45, ha='right')

# 3. Tiempo de procesamiento
ax3 = axes[1, 0]
time_data = comparison_df.set_index('T√©cnica')['Tiempo (s)']
bars = ax3.barh(time_data.index, time_data.values,
                color=[colors[t] for t in time_data.index])
ax3.set_title('Tiempo de Procesamiento Total', fontweight='bold', fontsize=12)
ax3.set_xlabel('Tiempo (segundos)', fontweight='bold')
ax3.grid(axis='x', alpha=0.3)

# Agregar valores en las barras
for i, (idx, val) in enumerate(time_data.items()):
    ax3.text(val, i, f'  {val:.2f}s', va='center', fontweight='bold')

# 4. ROC-AUC vs Tiempo (eficiencia)
ax4 = axes[1, 1]
for technique in comparison_df['T√©cnica']:
    row = comparison_df[comparison_df['T√©cnica'] == technique].iloc[0]
    ax4.scatter(row['Tiempo (s)'], row['ROC-AUC'],
               s=300, alpha=0.6, color=colors[technique],
               label=technique, edgecolors='black', linewidth=2)
    ax4.annotate(technique,
                (row['Tiempo (s)'], row['ROC-AUC']),
                xytext=(10, 10), textcoords='offset points',
                fontsize=10, fontweight='bold',
                bbox=dict(boxstyle='round,pad=0.5', facecolor=colors[technique], alpha=0.3))

ax4.set_title('Eficiencia: ROC-AUC vs Tiempo de Procesamiento', fontweight='bold', fontsize=12)
ax4.set_xlabel('Tiempo de Procesamiento (s)', fontweight='bold')
ax4.set_ylabel('ROC-AUC', fontweight='bold')
ax4.grid(alpha=0.3)
ax4.set_ylim([0.75, 0.90])

# Marcar la mejor t√©cnica
best_row = comparison_df[comparison_df['T√©cnica'] == best_technique_name].iloc[0]
ax4.scatter(best_row['Tiempo (s)'], best_row['ROC-AUC'],
           s=500, alpha=0.3, color='gold', marker='*',
           edgecolors='orange', linewidth=3, zorder=10,
           label='Mejor T√©cnica')

ax4.legend(loc='lower right', framealpha=0.9)

plt.tight_layout()
plt.show()

print("\n" + "="*80)
print("‚úÖ Visualizaci√≥n comparativa generada exitosamente")
print("="*80)
```

---

## 6. Resumen de Cambios en el C√≥digo

### Archivos Modificados

**1. Celda de Importaciones (Secci√≥n 0)**

- Agregar: `from imblearn.combine import SMOTETomek`

**2. Secci√≥n 7 - Manejo de Desbalanceo (COMPLETA REESCRITURA)**

- Implementar comparativa de 3 t√©cnicas
- Evaluaci√≥n autom√°tica con Random Forest
- Selecci√≥n autom√°tica de la mejor t√©cnica
- Almacenamiento de resultados en `balancing_results`

**3. Secci√≥n 11 - Guardado de Modelo**

- Modificar metadata para incluir `balancing_technique`
- Agregar `balancing_comparison` con m√©tricas de todas las t√©cnicas

**4. Secci√≥n 13 - Generaci√≥n de Informe**

- Agregar nueva secci√≥n "Comparativa de T√©cnicas de Balanceo"
- Incluir tabla comparativa
- Agregar justificaci√≥n de selecci√≥n
- Incluir recomendaciones de uso

**5. Nueva Celda - Visualizaci√≥n Comparativa**

- Crear 4 gr√°ficos comparativos
- Mostrar m√©tricas, muestras, tiempos y eficiencia

---

## 7. Estructura del Informe Final Generado

El informe Markdown generado autom√°ticamente incluir√°:

### Secciones Existentes

1. üìä Resumen del Dataset
2. üéØ M√©tricas del Mejor Modelo
3. üìà Top 10 Features M√°s Importantes

### Nuevas Secciones

4. ‚öñÔ∏è **Comparativa de T√©cnicas de Balanceo** (NUEVA)

   - T√©cnicas evaluadas
   - Tabla comparativa
   - T√©cnica seleccionada y justificaci√≥n
   - An√°lisis comparativo
   - Recomendaciones de uso

5. ‚öôÔ∏è Par√°metros del Modelo Optimizado
6. üí° Conclusiones y Recomendaciones

---

## 8. Ejemplo de Salida del Informe

### Secci√≥n de Comparativa de Balanceo

```markdown
## 4. ‚öñÔ∏è Comparativa de T√©cnicas de Balanceo

### Resultados Comparativos

| T√©cnica | ROC-AUC | F1-Score | Precision | Recall | Muestras | Tiempo (s) |
|---------|---------|----------|-----------|--------|----------|------------|
| SMOTE | 0.8440 | 0.6310 | 0.5258 | 0.7888 | 8,278 | 3.45 |
| SMOTE + Tomek | 0.8465 | 0.6285 | 0.5412 | 0.7456 | 8,156 | 5.23 |
| Undersampling | 0.8201 | 0.6102 | 0.5876 | 0.6345 | 2,990 | 1.12 |

### üèÜ T√©cnica Seleccionada: SMOTE + Tomek

**Justificaci√≥n:** ROC-AUC m√°s alto (0.8465)

**Ventajas:**

- ‚úÖ Combina las ventajas de SMOTE con limpieza de datos
- ‚úÖ Elimina muestras ruidosas en la frontera de decisi√≥n
- ‚úÖ Mejora la separabilidad entre clases
```

---

## 9. Checklist de Implementaci√≥n

### ‚úÖ Tareas Completadas en este Documento

- [x] An√°lisis del notebook original
- [x] Identificaci√≥n de secciones a modificar
- [x] C√≥digo para importaciones adicionales
- [x] C√≥digo completo de comparativa de balanceo
- [x] C√≥digo de modificaci√≥n de metadata
- [x] C√≥digo de modificaci√≥n de informe
- [x] C√≥digo de visualizaci√≥n comparativa
- [x] Documentaci√≥n de cambios
- [x] Ejemplo de salida del informe

### üìã Tareas Pendientes (Implementaci√≥n en Notebook)

- [ ] Copiar c√≥digo de importaciones a la celda correspondiente
- [ ] Reemplazar Secci√≥n 7 con el nuevo c√≥digo de comparativa
- [ ] Modificar secci√≥n de guardado de modelo (metadata)
- [ ] Modificar secci√≥n de generaci√≥n de informe
- [ ] Agregar celda de visualizaci√≥n comparativa
- [ ] Ejecutar notebook completo en Google Colab
- [ ] Verificar que el informe se genera correctamente
- [ ] Validar que los modelos se guardan en Google Drive

---

## 10. Notas T√©cnicas Importantes

### Compatibilidad con Google Colab

‚úÖ **Todo el c√≥digo es 100% compatible con Google Colab**

- Usa `from google.colab import drive` para montar Drive
- Guarda modelos en `/content/drive/MyDrive/`
- No requiere instalaciones adicionales (imblearn ya est√° incluido)

### Reproducibilidad

‚úÖ **Mantiene la reproducibilidad del notebook original**

- Usa `RANDOM_STATE` en todas las t√©cnicas de balanceo
- Usa `RANDOM_STATE` en todos los modelos
- Permite modo reproducible (`REPRODUCIBLE_MODE = True`) o experimental (`False`)

### Eficiencia

‚úÖ **Optimizado para Google Colab**

- Usa `n_jobs=-1` para paralelizaci√≥n
- T√©cnicas de balanceo optimizadas
- Visualizaciones eficientes

---

## 11. Conclusi√≥n

Este documento proporciona una gu√≠a completa para adaptar el notebook `Telco_Customer_Churn.ipynb` con:

1. ‚úÖ Comparativa de 3 t√©cnicas de balanceo (SMOTE, SMOTE + Tomek, Undersampling)
2. ‚úÖ Selecci√≥n autom√°tica de la mejor t√©cnica basada en ROC-AUC
3. ‚úÖ Visualizaciones comparativas detalladas
4. ‚úÖ Informe autom√°tico con secci√≥n de comparativa
5. ‚úÖ Metadata enriquecida con informaci√≥n de balanceo
6. ‚úÖ 100% compatible con Google Colab
7. ‚úÖ Mantiene reproducibilidad y eficiencia

**Pr√≥ximo paso:** Implementar los cambios en el notebook y ejecutar en Google Colab para validar el funcionamiento completo.

