---
title: "GuÃ­a Completa de Cliente Insight"
subtitle: "AnÃ¡lisis de Customer Churn"
output:
  pdf_document:
    latex_engine: xelatex
    toc: true
    toc_depth: 3
  html_document:
    toc: true
header-includes:
  - \usepackage{fontspec}
  - \usepackage{unicode-math}
---
# ğŸ“Š GuÃ­a Completa de Cliente Insight - AnÃ¡lisis de Customer Churn

## IntroducciÃ³n

Este documento proporciona una guÃ­a detallada del notebook **Telco_Customer_Churn.ipynb**, un proyecto de Machine Learning diseÃ±ado para predecir la fuga de clientes (churn) en una empresa de telecomunicaciones.

### Objetivo del Proyecto
Desarrollar un modelo predictivo que identifique clientes con alta probabilidad de abandonar el servicio, permitiendo implementar estrategias de retenciÃ³n proactivas.

### Dataset Utilizado
- **Archivo**: `WA_Fn-UseC_-Telco-Customer-Churn.csv`
- **Registros**: 7,043 clientes
- **Variables**: 21 columnas (20 features + 1 target)
- **Target**: `Churn` (Yes/No)

### Estructura del Notebook
El notebook estÃ¡ organizado en **13 bloques** principales que cubren todo el ciclo de vida de un proyecto de Machine Learning.

---

## ğŸ“¦ Bloque 1: ConfiguraciÃ³n e Importaciones

### Â¿QuÃ© es?
Este bloque establece el entorno de trabajo importando todas las librerÃ­as necesarias para el anÃ¡lisis de datos, visualizaciÃ³n, preprocesamiento y modelado de Machine Learning.

### CÃ³digo Relevante

```python
# LibrerÃ­as de manipulaciÃ³n de datos
import pandas as pd
import numpy as np

# LibrerÃ­as de visualizaciÃ³n
import matplotlib.pyplot as plt
import seaborn as sns

# LibrerÃ­as de Machine Learning
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
import xgboost as xgb

# MÃ©tricas de evaluaciÃ³n
from sklearn.metrics import (accuracy_score, precision_score, recall_score, 
                             f1_score, roc_auc_score, confusion_matrix,
                             classification_report, roc_curve, precision_recall_curve)

# Manejo de desbalanceo
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler

# ConfiguraciÃ³n de semilla para reproducibilidad
RANDOM_STATE = 42
np.random.seed(RANDOM_STATE)

# ConfiguraciÃ³n de visualizaciÃ³n
plt.style.use('seaborn-v0_8-whitegrid')
sns.set_palette("husl")
```

### ExplicaciÃ³n Detallada

| LibrerÃ­a | PropÃ³sito |
|----------|-----------|
| **pandas** | ManipulaciÃ³n y anÃ¡lisis de datos tabulares |
| **numpy** | Operaciones numÃ©ricas y arrays |
| **matplotlib/seaborn** | VisualizaciÃ³n de datos |
| **sklearn** | Algoritmos de ML, preprocesamiento y mÃ©tricas |
| **xgboost** | Algoritmo de Gradient Boosting avanzado |
| **imblearn** | TÃ©cnicas para manejar datasets desbalanceados |

### Resultados Esperados

- Todas las librerÃ­as importadas sin errores
- Variable `RANDOM_STATE = 42` definida para reproducibilidad
- ConfiguraciÃ³n visual establecida para grÃ¡ficos consistentes

### Mejores PrÃ¡cticas Aplicadas

1. **Reproducibilidad**: Se define `RANDOM_STATE = 42` para garantizar resultados consistentes entre ejecuciones
2. **OrganizaciÃ³n**: Las importaciones estÃ¡n agrupadas por funcionalidad
3. **ConfiguraciÃ³n visual**: Se establece un estilo de grÃ¡ficos uniforme
4. **SupresiÃ³n de warnings**: Se pueden agregar filtros para warnings no crÃ­ticos

### Consideraciones Importantes

- La semilla aleatoria (`RANDOM_STATE`) es crucial para:

  - Reproducir experimentos
  - Comparar modelos de forma justa
  - Debugging y validaciÃ³n
  
- Las versiones de las librerÃ­as deben documentarse para evitar incompatibilidades

### Dependencias del Bloque
Este bloque no tiene dependencias previas y es el punto de partida del anÃ¡lisis.

### ConexiÃ³n con Bloques Siguientes
Las librerÃ­as importadas aquÃ­ se utilizan en todos los bloques posteriores:

- **Bloque 2**: pandas para carga de datos
- **Bloque 3**: matplotlib/seaborn para EDA
- **Bloque 6-10**: sklearn para modelado

---

## ğŸ“¥ Bloque 2: Carga de Datos

### Â¿QuÃ© es?
Este bloque carga el dataset de clientes de telecomunicaciones y realiza una inspecciÃ³n inicial para comprender la estructura y caracterÃ­sticas de los datos.

### CÃ³digo Relevante

```python
# Cargar el dataset
df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')

# InspecciÃ³n inicial
print(f"Dimensiones del dataset: {df.shape}")
print(f"\nPrimeras filas:")
df.head()

# InformaciÃ³n del dataset
df.info()

# EstadÃ­sticas descriptivas
df.describe()

# Verificar valores Ãºnicos por columna
for col in df.columns:
    print(f"{col}: {df[col].nunique()} valores Ãºnicos")
```

### ExplicaciÃ³n Detallada

**Estructura del Dataset (21 columnas):**

| Variable | Tipo | DescripciÃ³n |
|----------|------|-------------|
| `customerID` | String | Identificador Ãºnico del cliente |
| `gender` | CategÃ³rica | GÃ©nero (Male/Female) |
| `SeniorCitizen` | Binaria | Es adulto mayor (0/1) |
| `Partner` | CategÃ³rica | Tiene pareja (Yes/No) |
| `Dependents` | CategÃ³rica | Tiene dependientes (Yes/No) |
| `tenure` | NumÃ©rica | Meses como cliente |
| `PhoneService` | CategÃ³rica | Tiene servicio telefÃ³nico |
| `MultipleLines` | CategÃ³rica | MÃºltiples lÃ­neas |
| `InternetService` | CategÃ³rica | Tipo de servicio de internet |
| `OnlineSecurity` | CategÃ³rica | Seguridad en lÃ­nea |
| `OnlineBackup` | CategÃ³rica | Backup en lÃ­nea |
| `DeviceProtection` | CategÃ³rica | ProtecciÃ³n de dispositivo |
| `TechSupport` | CategÃ³rica | Soporte tÃ©cnico |
| `StreamingTV` | CategÃ³rica | Streaming de TV |
| `StreamingMovies` | CategÃ³rica | Streaming de pelÃ­culas |
| `Contract` | CategÃ³rica | Tipo de contrato |
| `PaperlessBilling` | CategÃ³rica | FacturaciÃ³n sin papel |
| `PaymentMethod` | CategÃ³rica | MÃ©todo de pago |
| `MonthlyCharges` | NumÃ©rica | Cargo mensual |
| `TotalCharges` | NumÃ©rica | Cargo total acumulado |
| `Churn` | Target | Abandono del cliente (Yes/No) |

### Resultados Esperados

- Dataset cargado: 7,043 filas Ã— 21 columnas
- Sin errores de lectura
- Vista previa de los datos disponible

### Mejores PrÃ¡cticas Aplicadas

1. **InspecciÃ³n inmediata**: Verificar dimensiones y tipos de datos
2. **ExploraciÃ³n de valores Ãºnicos**: Identificar variables categÃ³ricas vs numÃ©ricas
3. **DocumentaciÃ³n de variables**: Entender el significado de cada columna

---

## ğŸ“Š Bloque 3: AnÃ¡lisis Exploratorio de Datos (EDA)

### Â¿QuÃ© es?
AnÃ¡lisis visual y estadÃ­stico profundo del dataset para entender patrones, distribuciones y relaciones entre variables, especialmente aquellas relacionadas con el churn.

### CÃ³digo Relevante

```python
# DistribuciÃ³n del target (Churn)
fig, axes = plt.subplots(1, 2, figsize=(12, 5))

# GrÃ¡fico de barras
df['Churn'].value_counts().plot(kind='bar', ax=axes[0], color=['#2ecc71', '#e74c3c'])
axes[0].set_title('DistribuciÃ³n de Churn')
axes[0].set_xlabel('Churn')
axes[0].set_ylabel('Cantidad')

# GrÃ¡fico de pie
df['Churn'].value_counts().plot(kind='pie', ax=axes[1], autopct='%1.1f%%',
                                 colors=['#2ecc71', '#e74c3c'])
axes[1].set_title('ProporciÃ³n de Churn')
plt.tight_layout()
plt.show()

# AnÃ¡lisis de variables numÃ©ricas
numerical_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']
fig, axes = plt.subplots(1, 3, figsize=(15, 5))
for i, col in enumerate(numerical_cols):
    sns.histplot(data=df, x=col, hue='Churn', ax=axes[i], kde=True)
    axes[i].set_title(f'DistribuciÃ³n de {col} por Churn')
plt.tight_layout()
plt.show()

# Matriz de correlaciÃ³n
plt.figure(figsize=(10, 8))
correlation_matrix = df[numerical_cols].corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)
plt.title('Matriz de CorrelaciÃ³n')
plt.show()

# AnÃ¡lisis de variables categÃ³ricas vs Churn
categorical_cols = ['gender', 'Partner', 'Dependents', 'Contract',
                    'InternetService', 'PaymentMethod']
fig, axes = plt.subplots(2, 3, figsize=(15, 10))
axes = axes.flatten()
for i, col in enumerate(categorical_cols):
    sns.countplot(data=df, x=col, hue='Churn', ax=axes[i])
    axes[i].set_title(f'{col} vs Churn')
    axes[i].tick_params(axis='x', rotation=45)
plt.tight_layout()
plt.show()
```

### ExplicaciÃ³n Detallada

**Hallazgos Clave del EDA:**

| Insight | DescripciÃ³n |
|---------|-------------|
| **Desbalance de clases** | ~26.5% Churn vs ~73.5% No Churn |
| **Tenure** | Clientes nuevos (bajo tenure) tienen mayor churn |
| **MonthlyCharges** | Cargos mensuales altos correlacionan con mayor churn |
| **Contract** | Contratos mes a mes tienen mayor tasa de abandono |
| **InternetService** | Fiber optic muestra mayor churn que DSL |
| **PaymentMethod** | Electronic check asociado a mayor churn |

### Resultados Esperados

- Visualizaciones claras de distribuciones
- IdentificaciÃ³n de patrones de churn
- Correlaciones entre variables numÃ©ricas
- Insights para feature engineering

### Mejores PrÃ¡cticas Aplicadas

1. **VisualizaciÃ³n multidimensional**: Combinar grÃ¡ficos de barras, pie, histogramas
2. **SegmentaciÃ³n por target**: Analizar distribuciones separadas por Churn
3. **Correlaciones**: Identificar multicolinealidad potencial

---

## ğŸ§¹ Bloque 4: Limpieza de Datos

### Â¿QuÃ© es?
Proceso de identificaciÃ³n y tratamiento de valores faltantes, conversiÃ³n de tipos de datos incorrectos y preparaciÃ³n del dataset para el modelado.

### CÃ³digo Relevante

```python
# Verificar valores faltantes
print("Valores faltantes por columna:")
print(df.isnull().sum())

# Detectar espacios en blanco en TotalCharges
df['TotalCharges'] = df['TotalCharges'].replace(' ', np.nan)

# Convertir TotalCharges a numÃ©rico
df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')

# Verificar nuevamente valores faltantes
print(f"\nValores faltantes en TotalCharges: {df['TotalCharges'].isnull().sum()}")

# Estrategia de imputaciÃ³n: rellenar con MonthlyCharges
# Los clientes con TotalCharges vacÃ­o son nuevos (tenure=0),
# por lo que su TotalCharges deberÃ­a ser igual a su primer MonthlyCharges
df['TotalCharges'] = df['TotalCharges'].fillna(df['MonthlyCharges'])

# Eliminar customerID (no aporta al modelo)
df_clean = df.drop('customerID', axis=1)

# Convertir SeniorCitizen a categÃ³rico
df_clean['SeniorCitizen'] = df_clean['SeniorCitizen'].map({0: 'No', 1: 'Yes'})

# Verificar resultado final
print(f"\nDataset limpio: {df_clean.shape}")
print(f"Valores faltantes totales: {df_clean.isnull().sum().sum()}")
```

### ExplicaciÃ³n Detallada

**Problemas Identificados y Soluciones:**

| Problema | SoluciÃ³n |
|----------|----------|
| TotalCharges con espacios en blanco | Convertir a NaN y luego a numÃ©rico |
| 11 valores faltantes en TotalCharges | Rellenar con MonthlyCharges (clientes nuevos con tenure=0) |
| customerID no predictivo | EliminaciÃ³n de la columna |
| SeniorCitizen como 0/1 | ConversiÃ³n a Yes/No para consistencia |

### Resultados Esperados

- Dataset sin valores faltantes
- Tipos de datos correctos
- 20 columnas (sin customerID)
- Datos listos para preprocesamiento

### Mejores PrÃ¡cticas Aplicadas

1. **ImputaciÃ³n lÃ³gica**: Usar MonthlyCharges para clientes nuevos (tenure=0)
2. **PreservaciÃ³n de informaciÃ³n**: No eliminar filas innecesariamente
3. **Consistencia de tipos**: Uniformar formato de variables categÃ³ricas

---

## ğŸ”§ Bloque 5: Feature Engineering

### Â¿QuÃ© es?
CreaciÃ³n de nuevas caracterÃ­sticas derivadas de las existentes para capturar patrones mÃ¡s complejos y mejorar el poder predictivo del modelo.

### CÃ³digo Relevante

```python
# 1. FEATURE ENGINEERING: Charge_Ratio
# Ratio que indica si el cliente paga mÃ¡s ahora que su promedio histÃ³rico
df['Charge_Ratio'] = df['MonthlyCharges'] / (df['TotalCharges'] / (df['tenure'] + 1))
df['Charge_Ratio'] = df['Charge_Ratio'].replace([np.inf, -np.inf], 1.0)
print("   âœ“ Creada variable 'Charge_Ratio' (ratio de cargos mensuales)")

# 2. FEATURE ENGINEERING: Total_Services
# Contador de servicios contratados por el cliente
services = ['PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity',
            'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']

df['Total_Services'] = df[services].apply(
    lambda x: ((x != 'No') & (x != 'No internet service') & (x != 'No phone service')).sum(),
    axis=1
)
print("   âœ“ Creada variable 'Total_Services' (total de servicios contratados)")
```

### ExplicaciÃ³n Detallada

**Nuevas Features Creadas:**

| Feature | LÃ³gica | HipÃ³tesis |
|---------|--------|-----------|
| `Charge_Ratio` | MonthlyCharges / (TotalCharges / (tenure + 1)) | Ratio que indica si el cliente paga mÃ¡s ahora que su promedio histÃ³rico |
| `Total_Services` | Conteo de servicios activos (donde valor != 'No') | MÃ¡s servicios contratados = mayor retenciÃ³n |

### Resultados Esperados

- 2 nuevas features derivadas
- Mayor poder predictivo potencial
- Features interpretables para negocio

### Mejores PrÃ¡cticas Aplicadas

1. **Features basadas en dominio**: Usar conocimiento del negocio de telecomunicaciones
2. **Agregaciones significativas**: Combinar variables relacionadas
3. **Evitar data leakage**: No usar informaciÃ³n futura

---

## âš™ï¸ Bloque 6: Preprocesamiento

### Â¿QuÃ© es?
TransformaciÃ³n de variables para que sean compatibles con algoritmos de Machine Learning, incluyendo encoding de categÃ³ricas y escalado de numÃ©ricas.

### CÃ³digo Relevante

```python
from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

# Separar features y target
X = df_fe.drop('Churn', axis=1)
y = df_fe['Churn'].map({'No': 0, 'Yes': 1})

# Identificar tipos de columnas
numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()
categorical_cols = X.select_dtypes(include=['object']).columns.tolist()

print(f"Columnas numÃ©ricas ({len(numerical_cols)}): {numerical_cols}")
print(f"Columnas categÃ³ricas ({len(categorical_cols)}): {categorical_cols}")

# Crear pipeline de preprocesamiento
numerical_transformer = StandardScaler()
categorical_transformer = OneHotEncoder(drop='first', sparse_output=False,
                                         handle_unknown='ignore')

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer, numerical_cols),
        ('cat', categorical_transformer, categorical_cols)
    ]
)

# Aplicar preprocesamiento
X_processed = preprocessor.fit_transform(X)

# Obtener nombres de features despuÃ©s de encoding
cat_feature_names = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_cols)
feature_names = numerical_cols + list(cat_feature_names)

print(f"\nDimensiones despuÃ©s de preprocesamiento: {X_processed.shape}")
print(f"Total de features: {len(feature_names)}")
```

### ExplicaciÃ³n Detallada

**Transformaciones Aplicadas:**

| Tipo | TransformaciÃ³n | RazÃ³n |
|------|---------------|-------|
| **NumÃ©ricas** | StandardScaler | Normalizar a media=0, std=1 |
| **CategÃ³ricas** | OneHotEncoder | Crear variables dummy |
| **Target** | Label Encoding | Convertir Yes/No a 1/0 |

**ParÃ¡metros Importantes:**

- `drop='first'`: Evita multicolinealidad en One-Hot Encoding
- `handle_unknown='ignore'`: Maneja categorÃ­as nuevas en producciÃ³n
- `sparse_output=False`: Retorna array denso para compatibilidad

### Resultados Esperados

- X_processed: matriz numÃ©rica lista para ML
- ~45-50 features despuÃ©s de One-Hot Encoding
- Valores escalados (numÃ©ricas) o binarios (categÃ³ricas)

### Mejores PrÃ¡cticas Aplicadas

1. **Pipeline integrado**: ColumnTransformer para transformaciones consistentes
2. **Evitar data leakage**: fit_transform solo en datos de entrenamiento (despuÃ©s de split)
3. **Manejo de unknowns**: Preparado para datos de producciÃ³n

---

## âœ‚ï¸ Bloque 7: DivisiÃ³n de Datos y Balanceo

### Â¿QuÃ© es?
SeparaciÃ³n del dataset en conjuntos de entrenamiento y prueba, junto con tÃ©cnicas para manejar el desbalance de clases en la variable objetivo.

### CÃ³digo Relevante

```python
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from imblearn.combine import SMOTETomek

# DivisiÃ³n train/test (80/20)
X_train, X_test, y_train, y_test = train_test_split(
    X_processed, y,
    test_size=0.2,
    random_state=RANDOM_STATE,
    stratify=y
)

print(f"Conjunto de entrenamiento: {X_train.shape[0]} muestras")
print(f"Conjunto de prueba: {X_test.shape[0]} muestras")

# Verificar distribuciÃ³n del target
print(f"\nDistribuciÃ³n en train:")
print(f"  No Churn (0): {(y_train == 0).sum()} ({(y_train == 0).mean()*100:.1f}%)")
print(f"  Churn (1): {(y_train == 1).sum()} ({(y_train == 1).mean()*100:.1f}%)")

# Se evaluaron 3 tÃ©cnicas de balanceo: SMOTE, SMOTE+Tomek, Undersampling
# Undersampling fue seleccionada como la mejor tÃ©cnica

# Aplicar Undersampling (tÃ©cnica seleccionada)
rus = RandomUnderSampler(random_state=RANDOM_STATE)
X_train_balanced, y_train_balanced = rus.fit_resample(X_train, y_train)

print(f"\nDespuÃ©s de Undersampling:")
print(f"  No Churn (0): {(y_train_balanced == 0).sum()}")
print(f"  Churn (1): {(y_train_balanced == 1).sum()}")
print(f"  Ratio: {(y_train_balanced == 1).sum() / (y_train_balanced == 0).sum():.2f}")
```

### ExplicaciÃ³n Detallada

**Estrategia de DivisiÃ³n:**

| ParÃ¡metro | Valor | JustificaciÃ³n |
|-----------|-------|---------------|
| `test_size` | 0.2 | 20% para evaluaciÃ³n final |
| `stratify` | y | Mantener proporciÃ³n de clases |
| `random_state` | 42 | Reproducibilidad |

**TÃ©cnicas de Balanceo Evaluadas:**

| TÃ©cnica | ROC-AUC | Recall | Tiempo | Resultado |
|---------|---------|--------|--------|-----------|
| **SMOTE** | 0.8258 | 76.47% | 0.91s | - |
| **SMOTE+Tomek** | 0.8217 | 74.33% | 1.10s | - |
| **Undersampling** | 0.8277 | 77.01% | 0.57s | â­ Seleccionada |

### Resultados Esperados

- Train: ~5,634 muestras (80%)
- Test: ~1,409 muestras (20%)
- DespuÃ©s de Undersampling: 2,990 muestras balanceadas (1,495 por clase)

### Mejores PrÃ¡cticas Aplicadas

1. **Stratify**: Garantiza proporciones iguales en train/test
2. **Balanceo solo en train**: Nunca en test para evitar data leakage
3. **Undersampling seleccionado**: Mejor ROC-AUC y menor tiempo de entrenamiento

---

## ğŸ¤– Bloque 8: Entrenamiento de Modelos Baseline

### Â¿QuÃ© es?
Entrenamiento y evaluaciÃ³n de mÃºltiples algoritmos de clasificaciÃ³n para establecer una lÃ­nea base de rendimiento y seleccionar el modelo mÃ¡s prometedor.

### CÃ³digo Relevante

```python
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
import xgboost as xgb

# Definir modelos a evaluar
models = {
    'Logistic Regression': LogisticRegression(random_state=RANDOM_STATE, max_iter=1000),
    'Decision Tree': DecisionTreeClassifier(random_state=RANDOM_STATE),
    'Random Forest': RandomForestClassifier(random_state=RANDOM_STATE, n_estimators=100),
    'Gradient Boosting': GradientBoostingClassifier(random_state=RANDOM_STATE),
    'XGBoost': xgb.XGBClassifier(random_state=RANDOM_STATE, eval_metric='logloss'),
    'SVM': SVC(random_state=RANDOM_STATE, probability=True),
    'KNN': KNeighborsClassifier(n_neighbors=5)
}

# Entrenar y evaluar cada modelo
results = []
for name, model in models.items():
    print(f"\nEntrenando {name}...")

    # Entrenar modelo
    model.fit(X_train_balanced, y_train_balanced)

    # Predicciones
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None

    # Calcular mÃ©tricas
    metrics = {
        'Model': name,
        'Accuracy': accuracy_score(y_test, y_pred),
        'Precision': precision_score(y_test, y_pred),
        'Recall': recall_score(y_test, y_pred),
        'F1-Score': f1_score(y_test, y_pred),
        'ROC-AUC': roc_auc_score(y_test, y_pred_proba) if y_pred_proba is not None else None
    }
    results.append(metrics)

    print(f"  Accuracy: {metrics['Accuracy']:.4f}")
    print(f"  F1-Score: {metrics['F1-Score']:.4f}")
    print(f"  ROC-AUC: {metrics['ROC-AUC']:.4f}" if metrics['ROC-AUC'] else "")

# Crear DataFrame de resultados
results_df = pd.DataFrame(results)
results_df = results_df.sort_values('ROC-AUC', ascending=False)
print("\n" + "="*60)
print("RESUMEN DE RESULTADOS:")
print("="*60)
print(results_df.to_string(index=False))
```

### ExplicaciÃ³n Detallada

**Modelos Evaluados:**

| Modelo | Tipo | CaracterÃ­sticas |
|--------|------|-----------------|
| **Logistic Regression** | Lineal | Simple, interpretable, baseline sÃ³lido |
| **Decision Tree** | Ãrbol | Interpretable, propenso a overfitting |
| **Random Forest** | Ensemble | Robusto, reduce varianza |
| **Gradient Boosting** | Ensemble | Alta precisiÃ³n, secuencial |
| **XGBoost** | Ensemble | Optimizado, regularizaciÃ³n |
| **SVM** | Kernel | Efectivo en alta dimensiÃ³n |
| **KNN** | Instancias | No paramÃ©trico, sensible a escala |

**MÃ©tricas Utilizadas:**

| MÃ©trica | FÃ³rmula | InterpretaciÃ³n para Churn |
|---------|---------|---------------------------|
| **Accuracy** | (TP+TN)/(Total) | % predicciones correctas |
| **Precision** | TP/(TP+FP) | De los predichos churn, % correctos |
| **Recall** | TP/(TP+FN) | De los churn reales, % detectados |
| **F1-Score** | 2Ã—(PÃ—R)/(P+R) | Balance precision-recall |
| **ROC-AUC** | Ãrea bajo curva ROC | Capacidad de discriminaciÃ³n |

### Resultados Esperados (Baseline sin balanceo)

| Modelo | Accuracy | F1-Score | ROC-AUC |
|--------|----------|----------|---------|
| Logistic Regression | 0.8084 | 0.5994 | 0.8483 |
| Gradient Boosting | 0.7956 | 0.5701 | 0.8453 |
| Random Forest | 0.7906 | 0.5564 | 0.8244 |
| XGBoost | 0.7828 | 0.5714 | 0.8234 |

> **Nota:** Logistic Regression obtuvo el mejor ROC-AUC en baseline. Tras optimizaciÃ³n con Undersampling, se seleccionÃ³ **Logistic Regression Optimizado** como modelo final.

### Mejores PrÃ¡cticas Aplicadas

1. **MÃºltiples modelos**: Comparar antes de optimizar
2. **MÃ©tricas relevantes**: F1 y Recall importantes para churn
3. **EvaluaciÃ³n en test set**: MÃ©tricas finales en datos no vistos

---

## ğŸ“ˆ Bloque 9: EvaluaciÃ³n del Mejor Modelo

### Â¿QuÃ© es?
AnÃ¡lisis detallado del modelo con mejor rendimiento, incluyendo matriz de confusiÃ³n, curvas ROC y Precision-Recall, e interpretaciÃ³n de resultados.

### CÃ³digo Relevante

```python
# Seleccionar mejor modelo (Logistic Regression Optimizado)
best_model_name = results_df.iloc[0]['Model']
best_model = models[best_model_name]

print(f"Mejor modelo: {best_model_name}")

# Predicciones finales
y_pred = best_model.predict(X_test)
y_pred_proba = best_model.predict_proba(X_test)[:, 1]

# 1. Matriz de ConfusiÃ³n
fig, axes = plt.subplots(1, 3, figsize=(18, 5))

cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0])
axes[0].set_title(f'Matriz de ConfusiÃ³n - {best_model_name}')
axes[0].set_xlabel('PredicciÃ³n')
axes[0].set_ylabel('Real')

# 2. Curva ROC
fpr, tpr, thresholds_roc = roc_curve(y_test, y_pred_proba)
roc_auc = roc_auc_score(y_test, y_pred_proba)
axes[1].plot(fpr, tpr, 'b-', label=f'ROC (AUC = {roc_auc:.3f})')
axes[1].plot([0, 1], [0, 1], 'r--', label='Random')
axes[1].set_xlabel('False Positive Rate')
axes[1].set_ylabel('True Positive Rate')
axes[1].set_title('Curva ROC')
axes[1].legend()

# 3. Curva Precision-Recall
precision, recall, thresholds_pr = precision_recall_curve(y_test, y_pred_proba)
axes[2].plot(recall, precision, 'g-')
axes[2].set_xlabel('Recall')
axes[2].set_ylabel('Precision')
axes[2].set_title('Curva Precision-Recall')
axes[2].axhline(y=y_test.mean(), color='r', linestyle='--', label='Baseline')
axes[2].legend()

plt.tight_layout()
plt.show()

# Classification Report
print("\nClassification Report:")
print(classification_report(y_test, y_pred, target_names=['No Churn', 'Churn']))

# AnÃ¡lisis de umbral Ã³ptimo
optimal_idx = np.argmax(tpr - fpr)
optimal_threshold = thresholds_roc[optimal_idx]
print(f"\nUmbral Ã³ptimo (Youden's J): {optimal_threshold:.3f}")
```

### ExplicaciÃ³n Detallada

**InterpretaciÃ³n de la Matriz de ConfusiÃ³n:**

|  | Pred: No Churn | Pred: Churn |
|--|----------------|-------------|
| **Real: No Churn** | TN (Verdaderos Negativos) | FP (Falsos Positivos) |
| **Real: Churn** | FN (Falsos Negativos) âš ï¸ | TP (Verdaderos Positivos) âœ“ |

**Importancia para el Negocio:**

- **FN (Falsos Negativos)**: Clientes que se irÃ¡n pero no detectamos - CRÃTICO
- **FP (Falsos Positivos)**: Clientes estables que predecimos se irÃ¡n - Menor costo

### Resultados Esperados

- Matriz de confusiÃ³n visual
- ROC-AUC > 0.80 (buen discriminador)
- Curva PR sobre la baseline
- Classification report detallado

### Mejores PrÃ¡cticas Aplicadas

1. **MÃºltiples visualizaciones**: Perspectiva completa del rendimiento
2. **AnÃ¡lisis de umbral**: Optimizar segÃºn costo de negocio
3. **Baseline comparison**: Comparar con clasificador aleatorio

---

## ğŸ¯ Bloque 10: OptimizaciÃ³n de HiperparÃ¡metros

### Â¿QuÃ© es?
BÃºsqueda sistemÃ¡tica de los mejores hiperparÃ¡metros del modelo seleccionado para maximizar su rendimiento predictivo.

### CÃ³digo Relevante

```python
from sklearn.model_selection import RandomizedSearchCV, GridSearchCV

# Definir espacio de bÃºsqueda para Logistic Regression
param_distributions = {
    'C': [0.001, 0.01, 0.1, 1, 10, 100],
    'penalty': ['l1', 'l2'],
    'solver': ['liblinear', 'saga'],
    'max_iter': [500, 1000, 2000],
    'subsample': [0.6, 0.7, 0.8, 0.9],
    'colsample_bytree': [0.6, 0.7, 0.8, 0.9],
    'gamma': [0, 0.1, 0.2, 0.3],
    'reg_alpha': [0, 0.1, 0.5, 1],
    'reg_lambda': [0, 0.1, 0.5, 1]
}

# Modelo base para optimizaciÃ³n
xgb_model = xgb.XGBClassifier(
    random_state=RANDOM_STATE,
    eval_metric='logloss',
    use_label_encoder=False
)

# RandomizedSearchCV para bÃºsqueda eficiente
random_search = RandomizedSearchCV(
    estimator=xgb_model,
    param_distributions=param_distributions,
    n_iter=50,  # NÃºmero de combinaciones a probar
    cv=5,       # Cross-validation 5-fold
    scoring='roc_auc',
    random_state=RANDOM_STATE,
    n_jobs=-1,
    verbose=2
)

# Ejecutar bÃºsqueda
print("Iniciando bÃºsqueda de hiperparÃ¡metros...")
random_search.fit(X_train_balanced, y_train_balanced)

# Mejores parÃ¡metros encontrados
print("\nMejores hiperparÃ¡metros:")
for param, value in random_search.best_params_.items():
    print(f"  {param}: {value}")

print(f"\nMejor ROC-AUC en CV: {random_search.best_score_:.4f}")

# Modelo optimizado
best_model_optimized = random_search.best_estimator_

# Evaluar en test set
y_pred_optimized = best_model_optimized.predict(X_test)
y_pred_proba_optimized = best_model_optimized.predict_proba(X_test)[:, 1]

print("\nMÃ©tricas del modelo optimizado en test set:")
print(f"  Accuracy: {accuracy_score(y_test, y_pred_optimized):.4f}")
print(f"  F1-Score: {f1_score(y_test, y_pred_optimized):.4f}")
print(f"  ROC-AUC: {roc_auc_score(y_test, y_pred_proba_optimized):.4f}")
```

### ExplicaciÃ³n Detallada

**HiperparÃ¡metros de Logistic Regression:**

| ParÃ¡metro | Rango | Efecto |
|-----------|-------|--------|
| `C` | 0.001-100 | Fuerza de regularizaciÃ³n inversa |
| `penalty` | l1, l2 | Tipo de regularizaciÃ³n |
| `solver` | liblinear, saga | Algoritmo de optimizaciÃ³n |
| `max_iter` | 500-2000 | Iteraciones mÃ¡ximas |
| `learning_rate` | 0.01-0.2 | Tasa de aprendizaje |
| `min_child_weight` | 1-7 | Peso mÃ­nimo en hojas |
| `subsample` | 0.6-0.9 | % de muestras por Ã¡rbol |
| `colsample_bytree` | 0.6-0.9 | % de features por Ã¡rbol |
| `gamma` | 0-0.3 | RegularizaciÃ³n de poda |
| `reg_alpha/lambda` | 0-1 | RegularizaciÃ³n L1/L2 |

**RandomizedSearchCV vs GridSearchCV:**

| MÃ©todo | Ventajas | Desventajas |
|--------|----------|-------------|
| **Randomized** | RÃ¡pido, explora espacio amplio | Puede perder Ã³ptimo |
| **Grid** | Exhaustivo, encuentra Ã³ptimo | Muy lento en espacios grandes |

### Resultados Esperados

- Mejora de 1-3% en ROC-AUC
- HiperparÃ¡metros Ã³ptimos documentados
- Modelo listo para producciÃ³n

### Mejores PrÃ¡cticas Aplicadas

1. **Cross-validation**: EvaluaciÃ³n robusta durante bÃºsqueda
2. **Scoring relevante**: Optimizar ROC-AUC para clasificaciÃ³n desbalanceada
3. **n_iter suficiente**: Balance entre exploraciÃ³n y tiempo

---

## ğŸ’¾ Bloque 11: Guardado del Modelo

### Â¿QuÃ© es?
ExportaciÃ³n del modelo entrenado y sus componentes asociados para su uso posterior en producciÃ³n o inferencia.

### CÃ³digo Relevante

```python
import joblib
import json
from datetime import datetime

# Crear directorio para modelos
import os
model_dir = 'models'
os.makedirs(model_dir, exist_ok=True)

# Timestamp para versionado
timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

# 1. Guardar modelo principal
model_path = f'{model_dir}/churn_model_{timestamp}.joblib'
joblib.dump(best_model_optimized, model_path)
print(f"Modelo guardado en: {model_path}")

# 2. Guardar preprocesador
preprocessor_path = f'{model_dir}/preprocessor_{timestamp}.joblib'
joblib.dump(preprocessor, preprocessor_path)
print(f"Preprocesador guardado en: {preprocessor_path}")

# 3. Guardar metadata del modelo
metadata = {
    'model_name': 'Logistic Regression Optimizado',
    'version': timestamp,
    'training_date': datetime.now().isoformat(),
    'metrics': {
        'accuracy': float(accuracy_score(y_test, y_pred_optimized)),
        'precision': float(precision_score(y_test, y_pred_optimized)),
        'recall': float(recall_score(y_test, y_pred_optimized)),
        'f1_score': float(f1_score(y_test, y_pred_optimized)),
        'roc_auc': float(roc_auc_score(y_test, y_pred_proba_optimized))
    },
    'best_params': random_search.best_params_,
    'features': feature_names,
    'target': 'Churn',
    'threshold': float(optimal_threshold)
}

metadata_path = f'{model_dir}/model_metadata_{timestamp}.json'
with open(metadata_path, 'w') as f:
    json.dump(metadata, f, indent=2)
print(f"Metadata guardada en: {metadata_path}")

# 4. Guardar nombres de features
features_path = f'{model_dir}/feature_names_{timestamp}.json'
with open(features_path, 'w') as f:
    json.dump(feature_names, f)
print(f"Features guardadas en: {features_path}")

print(f"\nâœ… Modelo exportado exitosamente - VersiÃ³n: {timestamp}")
```

### ExplicaciÃ³n Detallada

**Archivos Generados:**

| Archivo | Formato | Contenido |
|---------|---------|-----------|
| `churn_model_*.joblib` | Binario | Modelo entrenado serializado |
| `preprocessor_*.joblib` | Binario | Pipeline de preprocesamiento |
| `model_metadata_*.json` | JSON | MÃ©tricas, parÃ¡metros, versiÃ³n |
| `feature_names_*.json` | JSON | Lista de features esperadas |

**Estructura del Metadata:**

```json
{
  "model_name": "Logistic Regression Optimizado",
  "version": "20251128_170912",
  "training_date": "2025-11-28T17:09:12",
  "metrics": {
    "accuracy": 0.7424,
    "roc_auc": 0.8503
  },
  "best_params": {...},
  "threshold": 0.45
}
```

### Resultados Esperados

- 4 archivos en directorio `models/`
- Modelo reproducible y versionado
- Metadata completa para auditorÃ­a

### Mejores PrÃ¡cticas Aplicadas

1. **Versionado con timestamp**: Trazabilidad de versiones
2. **Metadata completa**: Reproducibilidad y documentaciÃ³n
3. **Preprocesador incluido**: Pipeline completo para producciÃ³n

---

## ğŸ“‹ Bloque 12: Resumen TÃ©cnico

### Â¿QuÃ© es?
DocumentaciÃ³n estructurada de la metodologÃ­a utilizada, decisiones tomadas, resultados obtenidos y recomendaciones para uso del modelo.

### CÃ³digo Relevante

```python
# Generar resumen tÃ©cnico
print("="*70)
print("RESUMEN TÃ‰CNICO DEL PROYECTO")
print("="*70)

print("\nğŸ“Š DATASET:")
print(f"  â€¢ Registros totales: 7,043")
print(f"  â€¢ Features originales: 21")
print(f"  â€¢ Features finales: {len(feature_names)}")
print(f"  â€¢ Target: Churn (26.5% positivos)")

print("\nğŸ”§ PREPROCESAMIENTO:")
print(f"  â€¢ Valores faltantes: ImputaciÃ³n con MonthlyCharges para clientes nuevos")
print(f"  â€¢ Encoding: OneHotEncoder (drop='first')")
print(f"  â€¢ Scaling: StandardScaler para numÃ©ricas")
print(f"  â€¢ Balanceo: Undersampling (seleccionado tras evaluar SMOTE, SMOTE+Tomek)")

print("\nğŸ¤– MODELO SELECCIONADO:")
print(f"  â€¢ Algoritmo: Logistic Regression Optimizado")
print(f"  â€¢ OptimizaciÃ³n: RandomizedSearchCV (50 iter, 5-fold CV)")
print(f"  â€¢ TÃ©cnica de Balanceo: Undersampling")

print("\nğŸ“ˆ MÃ‰TRICAS FINALES:")
print(f"  â€¢ Accuracy: {accuracy_score(y_test, y_pred_optimized):.4f}")
print(f"  â€¢ Precision: {precision_score(y_test, y_pred_optimized):.4f}")
print(f"  â€¢ Recall: {recall_score(y_test, y_pred_optimized):.4f}")
print(f"  â€¢ F1-Score: {f1_score(y_test, y_pred_optimized):.4f}")
print(f"  â€¢ ROC-AUC: {roc_auc_score(y_test, y_pred_proba_optimized):.4f}")

print("\nğŸ¯ UMBRAL DE DECISIÃ“N:")
print(f"  â€¢ Umbral Ã³ptimo: {optimal_threshold:.3f}")
print(f"  â€¢ Criterio: Youden's J (maximizar TPR - FPR)")

print("\nğŸ’¡ FEATURES MÃS IMPORTANTES:")
if hasattr(best_model_optimized, 'feature_importances_'):
    importances = pd.DataFrame({
        'feature': feature_names,
        'importance': best_model_optimized.feature_importances_
    }).sort_values('importance', ascending=False)

    for i, row in importances.head(10).iterrows():
        print(f"  {i+1}. {row['feature']}: {row['importance']:.4f}")

print("\n" + "="*70)
```

### ExplicaciÃ³n Detallada

**Componentes del Resumen:**

| SecciÃ³n | Contenido |
|---------|-----------|
| **Dataset** | Dimensiones, distribuciÃ³n del target |
| **Preprocesamiento** | TÃ©cnicas aplicadas, parÃ¡metros |
| **Modelo** | Algoritmo, mÃ©todo de optimizaciÃ³n |
| **MÃ©tricas** | Rendimiento en test set |
| **Umbral** | Punto de corte para clasificaciÃ³n |
| **Feature Importance** | Variables mÃ¡s predictivas |

### Resultados Esperados

- DocumentaciÃ³n completa del pipeline
- MÃ©tricas finales claras
- Top 10 features mÃ¡s importantes

### Mejores PrÃ¡cticas Aplicadas

1. **DocumentaciÃ³n inline**: Resumen ejecutivo en el notebook
2. **MÃ©tricas completas**: Todas las mÃ©tricas relevantes
3. **Feature importance**: Interpretabilidad del modelo

---

## ğŸ“„ Bloque 13: GeneraciÃ³n de Informe AutomÃ¡tico

### Â¿QuÃ© es?
CreaciÃ³n automatizada de un informe en formato Markdown que resume todo el proyecto y puede compartirse fÃ¡cilmente con stakeholders.

### CÃ³digo Relevante

```python
# Generar informe en Markdown
report_content = f"""# Informe de Modelo de PredicciÃ³n de Churn

## InformaciÃ³n General
- **Fecha de generaciÃ³n**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **VersiÃ³n del modelo**: {timestamp}
- **Autor**: Data Science Team

## Resumen Ejecutivo
Este modelo predice la probabilidad de que un cliente abandone el servicio de telecomunicaciones,
permitiendo implementar estrategias de retenciÃ³n proactivas.

## Dataset
| CaracterÃ­stica | Valor |
|----------------|-------|
| Registros totales | 7,043 |
| Features | {len(feature_names)} |
| Tasa de Churn | 26.5% |
| DivisiÃ³n Train/Test | 80/20 |

## Rendimiento del Modelo
| MÃ©trica | Valor |
|---------|-------|
| Accuracy | {accuracy_score(y_test, y_pred_optimized):.2%} |
| Precision | {precision_score(y_test, y_pred_optimized):.2%} |
| Recall | {recall_score(y_test, y_pred_optimized):.2%} |
| F1-Score | {f1_score(y_test, y_pred_optimized):.2%} |
| ROC-AUC | {roc_auc_score(y_test, y_pred_proba_optimized):.4f} |

## InterpretaciÃ³n de Negocio
- **Recall {recall_score(y_test, y_pred_optimized):.0%}**: De cada 100 clientes que realmente se van,
  el modelo detecta {int(recall_score(y_test, y_pred_optimized)*100)}.
- **Precision {precision_score(y_test, y_pred_optimized):.0%}**: De cada 100 clientes que el modelo
  predice como churn, {int(precision_score(y_test, y_pred_optimized)*100)} realmente se van.

## Recomendaciones

1. Implementar campaÃ±a de retenciÃ³n para clientes con score > {optimal_threshold:.2f}
2. Priorizar clientes con contratos mes a mes y tenure bajo
3. Ofrecer beneficios en servicios de seguridad y soporte tÃ©cnico
4. Revisar precios para clientes con MonthlyCharges alto

## Archivos Generados
- `{model_path}` - Modelo serializado
- `{preprocessor_path}` - Preprocesador
- `{metadata_path}` - Metadata

---
*Generado automÃ¡ticamente por el pipeline de ML*
"""

# Guardar informe
report_path = f'{model_dir}/churn_model_report_{timestamp}.md'
with open(report_path, 'w') as f:
    f.write(report_content)

print(f"ğŸ“„ Informe generado: {report_path}")
print("\n" + "="*70)
print("âœ… PIPELINE COMPLETADO EXITOSAMENTE")
print("="*70)
```

### ExplicaciÃ³n Detallada

**Estructura del Informe:**

| SecciÃ³n | Audiencia | Contenido |
|---------|-----------|-----------|
| Resumen Ejecutivo | Directivos | PropÃ³sito del modelo |
| Dataset | TÃ©cnicos | CaracterÃ­sticas de los datos |
| Rendimiento | Ambos | MÃ©tricas de evaluaciÃ³n |
| InterpretaciÃ³n | Negocio | TraducciÃ³n a impacto |
| Recomendaciones | Negocio | Acciones sugeridas |
| Archivos | TÃ©cnicos | Artefactos generados |

### Resultados Esperados

- Archivo Markdown legible
- MÃ©tricas formateadas como porcentajes
- Recomendaciones accionables
- Referencias a archivos generados

### Mejores PrÃ¡cticas Aplicadas

1. **Formato Markdown**: Universal y portable
2. **InterpretaciÃ³n de negocio**: Traducir mÃ©tricas a impacto
3. **AutomatizaciÃ³n**: Informe generado sin intervenciÃ³n manual
4. **Versionado**: Timestamp en nombre del archivo

---

## ğŸ“ Conclusiones Generales

### Flujo Completo del Proyecto

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Config  â”‚â”€â”€â”€â–¶â”‚  2. Carga   â”‚â”€â”€â”€â–¶â”‚   3. EDA    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
â”‚  6. Prepro  â”‚â—€â”€â”€â”€â”‚  5. FeatEng â”‚â—€â”€â”€â”€â”‚ 4. Limpieza â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  7. Split   â”‚â”€â”€â”€â–¶â”‚ 8. Baseline â”‚â”€â”€â”€â–¶â”‚  9. Eval    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 12. Resumen â”‚â—€â”€â”€â”€â”‚ 11. Guardar â”‚â—€â”€â”€â”€â”‚ 10. Optim   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 13. Informe â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### MÃ©tricas Clave del Proyecto

| Aspecto | Valor |
|---------|-------|
| Modelo Final | Logistic Regression Optimizado |
| ROC-AUC | 0.8503 |
| Recall | 79.41% |
| Precision | 50.94% |
| Accuracy | 74.24% |
| TÃ©cnica de Balanceo | Undersampling |
| Archivos generados | 5 |

### PrÃ³ximos Pasos Recomendados

1. **Monitoreo**: Implementar seguimiento de drift del modelo
2. **A/B Testing**: Validar efectividad de campaÃ±as de retenciÃ³n
3. **Reentrenamiento**: Programar actualizaciÃ³n trimestral
4. **API**: Desarrollar endpoint para predicciones en tiempo real

---

*Documento generado como parte del anÃ¡lisis del notebook Telco_Customer_Churn.ipynb*

