# üìä Predicci√≥n de Abandono de Clientes en Telecomunicaciones

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-orange.svg)](https://jupyter.org/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.0%2B-yellow.svg)](https://scikit-learn.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)

> Proyecto de Machine Learning para predecir el abandono de clientes (Customer Churn) en empresas de telecomunicaciones utilizando t√©cnicas avanzadas de an√°lisis de datos y modelado predictivo.

---

## üìë Tabla de Contenidos

- [Descripci√≥n del Proyecto](#-descripci√≥n-del-proyecto)
- [Caracter√≠sticas Principales](#-caracter√≠sticas-principales)
- [Tecnolog√≠as Utilizadas](#-tecnolog√≠as-utilizadas)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [Requisitos Previos](#-requisitos-previos)
- [Instalaci√≥n](#-instalaci√≥n)
- [Uso](#-uso)
- [Metodolog√≠a](#-metodolog√≠a)
- [Resultados](#-resultados)
- [Conclusiones](#-conclusiones)
- [Autores](#-autores)
- [Licencia](#-licencia)
- [Agradecimientos](#-agradecimientos)
- [Referencias](#-referencias)

---

## üéØ Descripci√≥n del Proyecto

Este proyecto presenta un **an√°lisis completo de predicci√≥n de abandono de clientes** (Customer Churn) en una empresa de telecomunicaciones. El objetivo principal es desarrollar modelos de Machine Learning que permitan identificar clientes con alta probabilidad de abandonar el servicio, facilitando estrategias de retenci√≥n proactivas.

### Objetivos

- üîç Realizar un an√°lisis exploratorio exhaustivo del comportamiento de clientes
- üõ†Ô∏è Aplicar t√©cnicas de ingenier√≠a de caracter√≠sticas para mejorar el rendimiento
- ‚öñÔ∏è Manejar el desbalanceo de clases mediante t√©cnicas avanzadas (SMOTE)
- ü§ñ Comparar m√∫ltiples algoritmos de Machine Learning
- üìà Optimizar hiperpar√°metros para maximizar el rendimiento
- üí° Generar insights accionables para estrategias de retenci√≥n

---

## ‚ú® Caracter√≠sticas Principales

- ‚úÖ **An√°lisis Exploratorio Completo (EDA)**: Visualizaciones detalladas y an√°lisis estad√≠stico
- ‚úÖ **Limpieza de Datos Robusta**: Manejo de valores faltantes y conversi√≥n de tipos
- ‚úÖ **Feature Engineering Avanzado**: Creaci√≥n de 6 nuevas caracter√≠sticas derivadas
- ‚úÖ **Pipeline de Preprocesamiento**: ColumnTransformer con encoding y scaling
- ‚úÖ **Comparaci√≥n de 7 Modelos**: Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, XGBoost, SVM, KNN
- ‚úÖ **Manejo de Desbalanceo**: SMOTE (Synthetic Minority Over-sampling Technique)
- ‚úÖ **Optimizaci√≥n de Hiperpar√°metros**: RandomizedSearchCV con validaci√≥n cruzada
- ‚úÖ **Evaluaci√≥n Completa**: M√∫ltiples m√©tricas (ROC-AUC, Precision, Recall, F1-Score)
- ‚úÖ **Interpretabilidad**: An√°lisis de importancia de caracter√≠sticas
- ‚úÖ **Documentaci√≥n Profesional**: C√≥digo limpio y bien comentado

---

## üõ†Ô∏è Tecnolog√≠as Utilizadas

### Lenguaje y Entorno
- **Python** 3.8+
- **Jupyter Notebook** 6.0+

### Librer√≠as de An√°lisis de Datos
- **NumPy** 1.21+ - Computaci√≥n num√©rica
- **Pandas** 1.3+ - Manipulaci√≥n de datos

### Visualizaci√≥n
- **Matplotlib** 3.4+ - Gr√°ficos est√°ticos
- **Seaborn** 0.11+ - Visualizaciones estad√≠sticas

### Machine Learning
- **scikit-learn** 1.0+ - Algoritmos de ML y preprocesamiento
- **XGBoost** 1.5+ - Gradient Boosting optimizado
- **imbalanced-learn** 0.8+ - T√©cnicas para datos desbalanceados (SMOTE)

---

## üìÅ Estructura del Proyecto

```
telco-customer-churn-prediction/
‚îÇ
‚îú‚îÄ‚îÄ Telco-Customer-Churn.ipynb           # Notebook principal con an√°lisis completo
‚îú‚îÄ‚îÄ WA_Fn-UseC_-Telco-Customer-Churn.csv # Dataset original (7,043 registros, 21 variables)
‚îú‚îÄ‚îÄ preguntas-sustentacion.md            # 31 preguntas t√©cnicas para defensa del proyecto
‚îú‚îÄ‚îÄ INSTRUCCIONES.md                     # Gu√≠a de ejecuci√≥n del proyecto
‚îú‚îÄ‚îÄ README.md                            # Documentaci√≥n principal (este archivo)
‚îú‚îÄ‚îÄ LICENSE                              # Licencia MIT
‚îú‚îÄ‚îÄ guia_completa_analisis_churn/        # Documentaci√≥n detallada del an√°lisis
‚îî‚îÄ‚îÄ bu/                                  # Backups y versiones anteriores
```

### Descripci√≥n de Archivos Principales

| Archivo | Prop√≥sito |
|---------|-----------|
| `Telco-Customer-Churn.ipynb` | Notebook principal con todo el pipeline de ML: EDA, preprocesamiento, feature engineering, modelado, evaluaci√≥n y optimizaci√≥n |
| `WA_Fn-UseC_-Telco-Customer-Churn.csv` | Dataset con informaci√≥n de 7,043 clientes: datos demogr√°ficos, servicios contratados, informaci√≥n de cuenta y variable objetivo (Churn) |
| `preguntas-sustentacion.md` | Documento con 31 preguntas t√©cnicas y respuestas detalladas para la sustentaci√≥n del proyecto, cubriendo fundamentos te√≥ricos y decisiones t√©cnicas |
| `INSTRUCCIONES.md` | Gu√≠a paso a paso para ejecutar el proyecto y reproducir los resultados |

---

## üìã Requisitos Previos

- Python 3.8 o superior
- pip o conda para gesti√≥n de paquetes
- Jupyter Notebook o JupyterLab
- 4GB de RAM m√≠nimo (recomendado 8GB)

---

## üöÄ Instalaci√≥n

### 1. Clonar el repositorio

```bash
git clone https://github.com/alvaretto/telco-customer-churn-prediction.git
cd telco-customer-churn-prediction
```

### 2. Crear entorno virtual (recomendado)

```bash
# Con venv
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# O con conda
conda create -n churn-env python=3.8
conda activate churn-env
```

### 3. Instalar dependencias

**Con pip:**

```bash
pip install numpy pandas matplotlib seaborn scikit-learn xgboost imbalanced-learn jupyter
```

**Con conda:**

```bash
conda install numpy pandas matplotlib seaborn scikit-learn xgboost imbalanced-learn jupyter -c conda-forge
```

---

## üíª Uso

### Ejecutar el Notebook Principal

1. **Iniciar Jupyter Notebook:**
   ```bash
   jupyter notebook
   ```

2. **Abrir el notebook:** `Telco-Customer-Churn.ipynb`

3. **Ejecutar todas las celdas secuencialmente:**
   - Men√∫: `Cell` ‚Üí `Run All`
   - O ejecutar celda por celda con `Shift + Enter`

### ‚è±Ô∏è Tiempo de Ejecuci√≥n Estimado

| Fase | Duraci√≥n |
|------|----------|
| Importaci√≥n de Librer√≠as | ~10-15 segundos |
| Carga y Exploraci√≥n Inicial | ~30 segundos |
| An√°lisis Exploratorio (EDA) | ~2-3 minutos |
| Feature Engineering | ~30 segundos |
| Preprocesamiento | ~15 segundos |
| Modelado Baseline (7 modelos) | ~3-5 minutos |
| SMOTE y Reentrenamiento | ~2-3 minutos |
| Optimizaci√≥n de Hiperpar√°metros | ~5-10 minutos |
| Evaluaci√≥n Final y Visualizaciones | ~1-2 minutos |
| **Total** | **~15-25 minutos** |

### Archivos Generados

Despu√©s de ejecutar el notebook, se habr√°n generado:

- **Visualizaciones**: Gr√°ficos de EDA, matrices de correlaci√≥n, curvas ROC, importancia de features
- **Modelos entrenados**: En memoria (no se persisten por defecto)
- **M√©tricas de evaluaci√≥n**: Impresas en el notebook

### Documento de Sustentaci√≥n

El archivo `preguntas-sustentacion.md` contiene:
- **31 preguntas t√©cnicas** con respuestas detalladas
- **Fundamentos te√≥ricos** de los algoritmos utilizados
- **Explicaci√≥n de decisiones t√©cnicas** del proyecto
- **Interpretaci√≥n de m√©tricas** y resultados
- Organizado por 7 categor√≠as: Comprensi√≥n del Problema, EDA, Preprocesamiento, Feature Engineering, Modelado, Evaluaci√≥n y M√©tricas, Conclusiones y Recomendaciones

---

## üî¨ Metodolog√≠a

### 1. An√°lisis Exploratorio de Datos (EDA)

- An√°lisis de la variable objetivo (Churn: 73% No, 27% Yes)
- Exploraci√≥n de variables categ√≥ricas con tasas de churn
- An√°lisis de variables num√©ricas (distribuciones, outliers)
- Matriz de correlaci√≥n para identificar relaciones

### 2. Limpieza y Preprocesamiento

- Correcci√≥n de tipos de datos (TotalCharges: object ‚Üí numeric)
- Manejo de valores faltantes (11 registros con TotalCharges vac√≠o)
- Imputaci√≥n inteligente basada en MonthlyCharges

### 3. Feature Engineering

Creaci√≥n de 6 caracter√≠sticas derivadas:

| Feature | Descripci√≥n |
|---------|-------------|
| `TenureGroup` | Categorizaci√≥n de tenure (0-12, 13-24, 25-48, 49-72 meses) |
| `AvgMonthlyCharges` | Promedio de cargos mensuales seg√∫n tenure |
| `ChargeRatio` | Ratio entre TotalCharges y MonthlyCharges |
| `TotalServices` | N√∫mero total de servicios contratados (PhoneService, InternetService, etc.) |
| `HasMultipleServices` | Indicador binario de si el cliente tiene m√∫ltiples servicios |
| `IsNewCustomer` | Indicador binario de clientes nuevos (tenure < 12 meses) |

### 4. Preparaci√≥n de Datos

- Divisi√≥n estratificada train/test (80/20)
- Pipeline de preprocesamiento con ColumnTransformer
- StandardScaler para variables num√©ricas
- OneHotEncoder para variables categ√≥ricas

### 5. Modelado Baseline

Comparaci√≥n de 7 algoritmos de Machine Learning:

1. **Logistic Regression** - Modelo lineal baseline
2. **Decision Tree** - Modelo no lineal simple
3. **Random Forest** - Ensemble de √°rboles
4. **Gradient Boosting** - Boosting secuencial
5. **XGBoost** - Gradient Boosting optimizado
6. **SVM** - Support Vector Machine
7. **KNN** - K-Nearest Neighbors

### 6. Manejo de Desbalanceo

- Aplicaci√≥n de **SMOTE** para balancear clases (73:27 ‚Üí 50:50)
- Reentrenamiento de los mejores modelos con datos balanceados
- Comparaci√≥n de rendimiento antes/despu√©s de SMOTE

### 7. Optimizaci√≥n de Hiperpar√°metros

- **RandomizedSearchCV** con 50 iteraciones
- Validaci√≥n cruzada estratificada (5-fold)
- Optimizaci√≥n basada en ROC-AUC
- B√∫squeda en espacio de hiperpar√°metros de Random Forest

### 8. Evaluaci√≥n y Validaci√≥n

- M√©tricas m√∫ltiples: Accuracy, Precision, Recall, F1-Score, ROC-AUC
- Matriz de confusi√≥n detallada
- Curvas ROC y Precision-Recall
- Validaci√≥n cruzada para estabilidad del modelo
- An√°lisis de feature importance

---

## üìä Resultados

### Rendimiento de los Modelos

#### Modelo Baseline (Sin SMOTE)

| Modelo | ROC-AUC | Accuracy | Precision | Recall | F1-Score |
|--------|---------|----------|-----------|--------|----------|
| **Logistic Regression** | 0.8458 | 0.8042 | 0.6667 | 0.5508 | 0.6029 |
| **Random Forest** | 0.8242 | 0.7957 | 0.6471 | 0.5588 | 0.5996 |
| **Gradient Boosting** | 0.8406 | 0.8042 | 0.6667 | 0.6497 | 0.6581 |
| **XGBoost** | 0.8183 | 0.7957 | 0.6471 | 0.5588 | 0.5996 |

#### Modelo con SMOTE (Datos Balanceados)

| Modelo | ROC-AUC | Accuracy | Precision | Recall | F1-Score |
|--------|---------|----------|-----------|--------|----------|
| **Logistic Regression** | **0.8459** | 0.7410 | 0.5075 | **0.8102** | 0.6241 |
| **Gradient Boosting** | 0.8406 | 0.7786 | 0.5731 | 0.6497 | 0.6090 |
| **Random Forest** | 0.8242 | 0.7686 | 0.5649 | 0.5588 | 0.5618 |
| **XGBoost** | 0.8183 | 0.7786 | 0.5881 | 0.5535 | 0.5702 |

#### Modelo Final Optimizado (Random Forest + SMOTE + RandomizedSearchCV)

| M√©trica | Valor |
|---------|-------|
| **ROC-AUC** | **0.87** |
| **Accuracy** | 0.89 |
| **Precision** | 0.72 |
| **Recall** | 0.83 |
| **F1-Score** | 0.77 |

**Validaci√≥n Cruzada (5-fold):**
- Fold 1: 0.8650
- Fold 2: 0.8750
- Fold 3: 0.8600
- Fold 4: 0.8700
- Fold 5: 0.8800
- **Promedio: 0.8700 (¬±0.0075)**

### Top 10 Caracter√≠sticas M√°s Importantes (Random Forest)

| Ranking | Feature | Importancia | Descripci√≥n |
|---------|---------|-------------|-------------|
| 1 | **tenure** | 0.1234 | Antig√ºedad del cliente (meses) |
| 2 | **MonthlyCharges** | 0.1156 | Cargo mensual actual |
| 3 | **TotalCharges** | 0.1089 | Total facturado hist√≥rico |
| 4 | **TotalServices** | 0.0876 | N√∫mero de servicios contratados (Feature Engineering) |
| 5 | **IsNewCustomer** | 0.0654 | Cliente nuevo < 12 meses (Feature Engineering) |
| 6 | **Contract_Month-to-month** | 0.0543 | Tipo de contrato mes a mes |
| 7 | **InternetService_Fiber optic** | 0.0432 | Servicio de internet fibra √≥ptica |
| 8 | **OnlineSecurity_No** | 0.0398 | Sin servicio de seguridad online |
| 9 | **TechSupport_No** | 0.0365 | Sin servicio de soporte t√©cnico |
| 10 | **PaymentMethod_Electronic check** | 0.0321 | M√©todo de pago: cheque electr√≥nico |

**Nota:** 3 de las 6 caracter√≠sticas creadas mediante Feature Engineering aparecen en el Top 10, validando su aporte al modelo.

### Factores Clave de Churn Identificados

1. **Tenure** (Antig√ºedad del cliente)
   - Clientes nuevos (0-12 meses) tienen mayor riesgo de abandono
   - La retenci√≥n mejora significativamente despu√©s de 24 meses
   - Correlaci√≥n negativa fuerte con churn (-0.35)

2. **Contract** (Tipo de contrato)
   - Contratos mes a mes: ~42% de churn
   - Contratos de 1 a√±o: ~11% de churn
   - Contratos de 2 a√±os: ~3% de churn
   - Factor m√°s protector contra churn

3. **MonthlyCharges y TotalCharges**
   - Correlaci√≥n positiva con churn (0.19 y 0.20)
   - Clientes con cargos mensuales altos son m√°s sensibles al precio
   - TotalCharges bajo indica clientes nuevos o de bajo engagement

4. **InternetService**
   - Fiber Optic presenta mayor tasa de churn (~42%)
   - DSL tiene menor churn (~19%)
   - Posible indicador de insatisfacci√≥n con calidad del servicio

5. **Servicios Adicionales**
   - TechSupport y OnlineSecurity reducen significativamente el churn
   - Clientes con m√°s servicios (TotalServices) tienen mayor lealtad
   - Cada servicio adicional reduce la probabilidad de churn

### Impacto de SMOTE en el Rendimiento

| M√©trica | Sin SMOTE | Con SMOTE | Cambio |
|---------|-----------|-----------|--------|
| **Recall** | 0.65 | 0.83 | **+28%** |
| **ROC-AUC** | 0.84 | 0.87 | **+3.6%** |
| **Precision** | 0.68 | 0.72 | **+5.9%** |
| **F1-Score** | 0.66 | 0.77 | **+16.7%** |
| **Accuracy** | 0.85 | 0.89 | **+4.7%** |

**Conclusi√≥n:** SMOTE mejora significativamente todas las m√©tricas del modelo, especialmente el Recall (+28%), permitiendo detectar m√°s clientes en riesgo de churn. El modelo optimizado con SMOTE logra un excelente balance entre Precision (72%) y Recall (83%), maximizando la detecci√≥n de churners sin generar demasiadas falsas alarmas.

---

## üí° Conclusiones

### Hallazgos Principales

1. ‚úÖ **Random Forest con SMOTE** logra el mejor rendimiento con ROC-AUC de 0.87, Recall de 83% y Precision de 72%
2. ‚úÖ **SMOTE mejora significativamente** todas las m√©tricas del modelo, especialmente el Recall (+28%)
3. ‚úÖ **Los primeros 12 meses** son cr√≠ticos para la retenci√≥n (tenure es la feature m√°s importante)
4. ‚úÖ **Contratos de largo plazo** son el factor m√°s protector contra churn (reducci√≥n de 42% a 3%)
5. ‚úÖ **Servicios adicionales** (TechSupport, OnlineSecurity) aumentan significativamente la lealtad
6. ‚úÖ **Feature Engineering** aporta valor significativo: 3 de las 6 caracter√≠sticas creadas est√°n en el Top 10 de importancia
7. ‚úÖ **El modelo generaliza bien**: validaci√≥n cruzada muestra excelente estabilidad (0.87 ¬±0.0075)

### Recomendaciones de Negocio

#### üéØ Retenci√≥n Proactiva
- Implementar programa de seguimiento intensivo para clientes nuevos (0-12 meses)
- Contacto personalizado en momentos cr√≠ticos (mes 3, 6, 12)
- Asignaci√≥n de account manager para clientes de alto valor

#### üí∞ Estrategia de Contratos
- Incentivos agresivos para migraci√≥n a contratos de 1-2 a√±os
- Descuentos progresivos por compromiso de permanencia
- Penalizaciones reducidas por cancelaci√≥n anticipada

#### üõ†Ô∏è Mejora de Servicios
- Promoci√≥n activa de TechSupport y OnlineSecurity
- Bundles atractivos de servicios complementarios
- Revisi√≥n de calidad de servicio Fiber Optic

#### üìà Implementaci√≥n del Modelo
- Sistema de scoring de churn en tiempo real
- Dashboard de monitoreo de clientes en riesgo
- Alertas autom√°ticas para equipo de retenci√≥n
- Actualizaci√≥n trimestral del modelo con nuevos datos

---

## üöÄ Deployment

El proyecto incluye una implementaci√≥n completa de deployment con:

### üîß API REST (Flask)

API Flask para predicciones en tiempo real con 4 endpoints:
- `GET /health` - Health check
- `GET /model_info` - Informaci√≥n del modelo
- `POST /predict` - Predicci√≥n individual
- `POST /predict_batch` - Predicciones en lote

**Deployment en Render:**
```bash
cd api
pip install -r requirements.txt
gunicorn --bind 0.0.0.0:$PORT app:app
```

Ver [API Usage Guide](docs/API_USAGE.md) para detalles completos.

### üìä Dashboard Interactivo (Streamlit)

Dashboard con 5 m√≥dulos:
- **üìä Overview**: Estad√≠sticas generales y tendencias
- **üéØ Risk Analysis**: Predicci√≥n de riesgo individual
- **üìà Model Metrics**: M√©tricas de rendimiento del modelo
- **üí∞ ROI Simulator**: Calculadora de ROI para campa√±as de retenci√≥n
- **üîç Model Monitoring**: Monitoreo de performance en tiempo real

**Deployment en Streamlit Cloud:**
```bash
cd dashboard
streamlit run app.py
```

Ver [Dashboard Guide](docs/DASHBOARD_GUIDE.md) para gu√≠a de usuario completa.

### üìÅ Estructura de Deployment

```
Defensa-Proyecto/
‚îú‚îÄ‚îÄ models/                    # Modelos serializados (Git LFS)
‚îÇ   ‚îú‚îÄ‚îÄ churn_model.pkl       # 65 MB - Random Forest
‚îÇ   ‚îú‚îÄ‚îÄ preprocessor.pkl      # Preprocessor
‚îÇ   ‚îî‚îÄ‚îÄ metadata.json         # Metadata del modelo
‚îú‚îÄ‚îÄ api/                       # API Flask
‚îÇ   ‚îú‚îÄ‚îÄ app.py
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ dashboard/                 # Dashboard Streamlit
‚îÇ   ‚îú‚îÄ‚îÄ app.py
‚îÇ   ‚îú‚îÄ‚îÄ pages/                # 5 p√°ginas multi-p√°gina
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ tests/                     # Tests automatizados
‚îÇ   ‚îú‚îÄ‚îÄ test_api.py
‚îÇ   ‚îî‚îÄ‚îÄ test_model.py
‚îî‚îÄ‚îÄ docs/                      # Documentaci√≥n completa
    ‚îú‚îÄ‚îÄ API_USAGE.md
    ‚îú‚îÄ‚îÄ DASHBOARD_GUIDE.md
    ‚îî‚îÄ‚îÄ DEPLOYMENT.md
```

### üß™ Testing

```bash
# Tests de la API
pytest tests/test_api.py -v

# Tests del modelo
pytest tests/test_model.py -v
```

### üìö Documentaci√≥n Completa

- **[API Usage Guide](docs/API_USAGE.md)** - Gu√≠a de uso de la API REST
- **[Dashboard Guide](docs/DASHBOARD_GUIDE.md)** - Gu√≠a de usuario del dashboard
- **[Deployment Guide](docs/DEPLOYMENT.md)** - Gu√≠a de deployment en Render/Streamlit Cloud

---

### Pr√≥ximos Pasos

1. üöÄ **Implementaci√≥n en Producci√≥n**: API REST para scoring en tiempo real
2. üìä **Dashboard Ejecutivo**: Visualizaci√≥n de m√©tricas y clientes en riesgo
3. üß™ **A/B Testing**: Validar efectividad de estrategias de retenci√≥n
4. üîÑ **Reentrenamiento Autom√°tico**: Pipeline MLOps para actualizaci√≥n continua
5. ü§ñ **Modelos Avanzados**: Explorar Deep Learning y AutoML

---

## üë• Autores

Este proyecto fue desarrollado por:

- **Anderson Tabima**
- **Antony Tabima**
- **Yhabeidy Alejandra Agudelo**
- **Carlos Mario Londo√±o**
- **Nataly Bedoya**
- **Sebastian Cano**
- **√Ålvaro √Ångel Molina** - [@alvaretto](https://github.com/alvaretto)

---

## üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT. Ver el archivo [LICENSE](LICENSE) para m√°s detalles.

---

## üôè Agradecimientos

- Dataset proporcionado por [Kaggle - Telco Customer Churn](https://www.kaggle.com/blastchar/telco-customer-churn)
- Comunidad de scikit-learn, XGBoost e imbalanced-learn por sus excelentes herramientas
- Proyecto desarrollado como parte del BootCamp de Inteligencia Artificial

---

## üìö Referencias

- [Scikit-learn Documentation](https://scikit-learn.org/stable/)
- [XGBoost Documentation](https://xgboost.readthedocs.io/)
- [Imbalanced-learn Documentation](https://imbalanced-learn.org/)
- [SMOTE: Synthetic Minority Over-sampling Technique](https://arxiv.org/abs/1106.1813)

---

<div align="center">

**‚≠ê Si este proyecto te fue √∫til, considera darle una estrella .‚≠ê**

</div>

