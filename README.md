# üìä Predicci√≥n de Abandono de Clientes en Telecomunicaciones

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-orange.svg)](https://jupyter.org/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.0%2B-yellow.svg)](https://scikit-learn.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)

> Proyecto de Machine Learning para predecir el abandono de clientes (Customer Churn) en empresas de telecomunicaciones utilizando t√©cnicas avanzadas de an√°lisis de datos y modelado predictivo.

---

## üìë Tabla de Contenidos

- [Descripci√≥n del Proyecto](#-descripci√≥n-del-proyecto)
- [Caracter√≠sticas Principales](#-caracter√≠sticas-principales)
- [Tecnolog√≠as Utilizadas](#-tecnolog√≠as-utilizadas)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [Requisitos Previos](#-requisitos-previos)
- [Instalaci√≥n](#-instalaci√≥n)
- [Uso](#-uso)
- [Metodolog√≠a](#-metodolog√≠a)
- [Resultados](#-resultados)
- [Conclusiones](#-conclusiones)
- [Autores](#-autores)
- [Licencia](#-licencia)
- [Agradecimientos](#-agradecimientos)
- [Referencias](#-referencias)

---

## üéØ Descripci√≥n del Proyecto

Este proyecto presenta un **an√°lisis completo de predicci√≥n de abandono de clientes** (Customer Churn) en una empresa de telecomunicaciones. El objetivo principal es desarrollar modelos de Machine Learning que permitan identificar clientes con alta probabilidad de abandonar el servicio, facilitando estrategias de retenci√≥n proactivas.

### Objetivos

- üîç Realizar un an√°lisis exploratorio exhaustivo del comportamiento de clientes
- üõ†Ô∏è Aplicar t√©cnicas de ingenier√≠a de caracter√≠sticas para mejorar el rendimiento
- ‚öñÔ∏è Manejar el desbalanceo de clases mediante t√©cnicas avanzadas (SMOTE)
- ü§ñ Comparar m√∫ltiples algoritmos de Machine Learning
- üìà Optimizar hiperpar√°metros para maximizar el rendimiento
- üí° Generar insights accionables para estrategias de retenci√≥n

---

## ‚ú® Caracter√≠sticas Principales

- ‚úÖ **An√°lisis Exploratorio Completo (EDA)**: Visualizaciones detalladas y an√°lisis estad√≠stico
- ‚úÖ **Limpieza de Datos Robusta**: Manejo de valores faltantes y conversi√≥n de tipos
- ‚úÖ **Feature Engineering Avanzado**: Creaci√≥n de 6 nuevas caracter√≠sticas derivadas
- ‚úÖ **Pipeline de Preprocesamiento**: ColumnTransformer con encoding y scaling
- ‚úÖ **Comparaci√≥n de 7 Modelos**: Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, XGBoost, SVM, KNN
- ‚úÖ **Manejo de Desbalanceo**: SMOTE (Synthetic Minority Over-sampling Technique)
- ‚úÖ **Optimizaci√≥n de Hiperpar√°metros**: RandomizedSearchCV con validaci√≥n cruzada
- ‚úÖ **Evaluaci√≥n Completa**: M√∫ltiples m√©tricas (ROC-AUC, Precision, Recall, F1-Score)
- ‚úÖ **Interpretabilidad**: An√°lisis de importancia de caracter√≠sticas
- ‚úÖ **Documentaci√≥n Profesional**: C√≥digo limpio y bien comentado

---

## üõ†Ô∏è Tecnolog√≠as Utilizadas

### Lenguaje y Entorno
- **Python** 3.8+
- **Jupyter Notebook** 6.0+

### Librer√≠as de An√°lisis de Datos
- **NumPy** 1.21+ - Computaci√≥n num√©rica
- **Pandas** 1.3+ - Manipulaci√≥n de datos

### Visualizaci√≥n
- **Matplotlib** 3.4+ - Gr√°ficos est√°ticos
- **Seaborn** 0.11+ - Visualizaciones estad√≠sticas

### Machine Learning
- **scikit-learn** 1.0+ - Algoritmos de ML y preprocesamiento
- **XGBoost** 1.5+ - Gradient Boosting optimizado
- **imbalanced-learn** 0.8+ - T√©cnicas para datos desbalanceados (SMOTE)

---

## üìÅ Estructura del Proyecto

```
telco-customer-churn-prediction/
‚îÇ
‚îú‚îÄ‚îÄ Telco-Customer-Churn.ipynb           # Notebook principal optimizado
‚îú‚îÄ‚îÄ WA_Fn-UseC_-Telco-Customer-Churn.csv # Dataset (7,043 registros)
‚îú‚îÄ‚îÄ MEJORAS_REALIZADAS.md                # Documentaci√≥n de mejoras
‚îú‚îÄ‚îÄ INSTRUCCIONES.md                     # Gu√≠a de ejecuci√≥n y defensa
‚îú‚îÄ‚îÄ CONFIGURACION_GITHUB.md              # Gu√≠a de configuraci√≥n y seguridad
‚îú‚îÄ‚îÄ README.md                            # Este archivo
‚îú‚îÄ‚îÄ LICENSE                              # Licencia MIT
‚îî‚îÄ‚îÄ .gitignore                           # Archivos excluidos de Git
```

---

## üìã Requisitos Previos

- Python 3.8 o superior
- pip o conda para gesti√≥n de paquetes
- Jupyter Notebook o JupyterLab
- 4GB de RAM m√≠nimo (recomendado 8GB)

---

## üöÄ Instalaci√≥n

### 1. Clonar el repositorio

```bash
git clone https://github.com/alvaretto/telco-customer-churn-prediction.git
cd telco-customer-churn-prediction
```

### 2. Crear entorno virtual (recomendado)

```bash
# Con venv
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# O con conda
conda create -n churn-env python=3.8
conda activate churn-env
```

### 3. Instalar dependencias

**Con pip:**

```bash
pip install numpy pandas matplotlib seaborn scikit-learn xgboost imbalanced-learn jupyter
```

**Con conda:**

```bash
conda install numpy pandas matplotlib seaborn scikit-learn xgboost imbalanced-learn jupyter -c conda-forge
```

---

## üíª Uso

### Ejecutar el Notebook

1. **Iniciar Jupyter Notebook:**
   ```bash
   jupyter notebook
   ```

2. **Abrir el notebook:** `Telco-Customer-Churn.ipynb`

3. **Ejecutar todas las celdas secuencialmente:**
   - Men√∫: `Cell` ‚Üí `Run All`
   - O ejecutar celda por celda con `Shift + Enter`

### ‚è±Ô∏è Tiempo de Ejecuci√≥n Estimado

| Fase | Duraci√≥n |
|------|----------|
| An√°lisis Exploratorio | ~2-3 minutos |
| Modelado Baseline | ~3-5 minutos |
| SMOTE y Reentrenamiento | ~2-3 minutos |
| Optimizaci√≥n de Hiperpar√°metros | ~5-10 minutos |
| Evaluaci√≥n Final | ~1-2 minutos |
| **Total** | **~15-25 minutos** |

---

## üî¨ Metodolog√≠a

### 1. An√°lisis Exploratorio de Datos (EDA)

- An√°lisis de la variable objetivo (Churn: 73% No, 27% Yes)
- Exploraci√≥n de variables categ√≥ricas con tasas de churn
- An√°lisis de variables num√©ricas (distribuciones, outliers)
- Matriz de correlaci√≥n para identificar relaciones

### 2. Limpieza y Preprocesamiento

- Correcci√≥n de tipos de datos (TotalCharges: object ‚Üí numeric)
- Manejo de valores faltantes (11 registros con TotalCharges vac√≠o)
- Imputaci√≥n inteligente basada en MonthlyCharges

### 3. Feature Engineering

Creaci√≥n de 6 nuevas caracter√≠sticas derivadas:

| Feature | Descripci√≥n |
|---------|-------------|
| `ChargeRatio` | Ratio entre MonthlyCharges y TotalCharges |
| `AvgMonthlyCharges` | Promedio de cargos mensuales seg√∫n tenure |
| `TenureGroup` | Categorizaci√≥n de tenure (0-12, 13-24, 25-48, 49-72 meses) |
| `TotalServices` | N√∫mero total de servicios contratados |
| `SeniorWithDependents` | Combinaci√≥n de SeniorCitizen y Dependents |
| `HighValueContract` | Identificaci√≥n de contratos de alto valor |

### 4. Preparaci√≥n de Datos

- Divisi√≥n estratificada train/test (80/20)
- Pipeline de preprocesamiento con ColumnTransformer
- StandardScaler para variables num√©ricas
- OneHotEncoder para variables categ√≥ricas

### 5. Modelado Baseline

Comparaci√≥n de 7 algoritmos de Machine Learning:

1. **Logistic Regression** - Modelo lineal baseline
2. **Decision Tree** - Modelo no lineal simple
3. **Random Forest** - Ensemble de √°rboles
4. **Gradient Boosting** - Boosting secuencial
5. **XGBoost** - Gradient Boosting optimizado
6. **SVM** - Support Vector Machine
7. **KNN** - K-Nearest Neighbors

### 6. Manejo de Desbalanceo

- Aplicaci√≥n de **SMOTE** para balancear clases (73:27 ‚Üí 50:50)
- Reentrenamiento de los mejores modelos con datos balanceados
- Comparaci√≥n de rendimiento antes/despu√©s de SMOTE

### 7. Optimizaci√≥n de Hiperpar√°metros

- **RandomizedSearchCV** con 50 iteraciones
- Validaci√≥n cruzada estratificada (5-fold)
- Optimizaci√≥n basada en ROC-AUC
- B√∫squeda en espacio de hiperpar√°metros de Random Forest

### 8. Evaluaci√≥n y Validaci√≥n

- M√©tricas m√∫ltiples: Accuracy, Precision, Recall, F1-Score, ROC-AUC
- Matriz de confusi√≥n detallada
- Curvas ROC y Precision-Recall
- Validaci√≥n cruzada para estabilidad del modelo
- An√°lisis de feature importance

---

## üìä Resultados

### Rendimiento del Mejor Modelo (Random Forest Optimizado)

| M√©trica | Valor |
|---------|-------|
| **ROC-AUC** | ~0.85-0.90 |
| **Accuracy** | ~0.80-0.85 |
| **Precision** | ~0.65-0.75 |
| **Recall** | ~0.75-0.85 |
| **F1-Score** | ~0.70-0.80 |

### Factores Clave de Churn Identificados

1. **Tenure** (Antig√ºedad del cliente)
   - Clientes nuevos (0-12 meses) tienen mayor riesgo de abandono
   - La retenci√≥n mejora significativamente despu√©s de 24 meses

2. **Contract** (Tipo de contrato)
   - Contratos mes a mes: ~42% de churn
   - Contratos de 1 a√±o: ~11% de churn
   - Contratos de 2 a√±os: ~3% de churn

3. **TotalCharges/MonthlyCharges**
   - Relaci√≥n directa con probabilidad de churn
   - Clientes con cargos muy altos o muy bajos tienen mayor riesgo

4. **InternetService**
   - Fiber Optic presenta mayor tasa de churn
   - Posible indicador de insatisfacci√≥n con el servicio

5. **Servicios Adicionales**
   - TechSupport, OnlineSecurity reducen significativamente el churn
   - Clientes con m√°s servicios tienden a permanecer

### Impacto de SMOTE

- **Mejora en Recall**: +15-20% (mejor detecci√≥n de clientes en riesgo)
- **Balance Precision-Recall**: Optimizado para el caso de uso
- **Reducci√≥n de Falsos Negativos**: Cr√≠tico para retenci√≥n proactiva

---

## üí° Conclusiones

### Hallazgos Principales

1. ‚úÖ **El modelo Random Forest optimizado** logra excelente capacidad discriminativa (ROC-AUC ~0.85-0.90)
2. ‚úÖ **SMOTE mejora significativamente** la detecci√≥n de clientes en riesgo
3. ‚úÖ **Los primeros 12 meses** son cr√≠ticos para la retenci√≥n
4. ‚úÖ **Contratos de largo plazo** son el factor m√°s protector contra churn
5. ‚úÖ **Servicios adicionales** (soporte t√©cnico, seguridad) aumentan la lealtad

### Recomendaciones de Negocio

#### üéØ Retenci√≥n Proactiva
- Implementar programa de seguimiento intensivo para clientes nuevos (0-12 meses)
- Contacto personalizado en momentos cr√≠ticos (mes 3, 6, 12)
- Asignaci√≥n de account manager para clientes de alto valor

#### üí∞ Estrategia de Contratos
- Incentivos agresivos para migraci√≥n a contratos de 1-2 a√±os
- Descuentos progresivos por compromiso de permanencia
- Penalizaciones reducidas por cancelaci√≥n anticipada

#### üõ†Ô∏è Mejora de Servicios
- Promoci√≥n activa de TechSupport y OnlineSecurity
- Bundles atractivos de servicios complementarios
- Revisi√≥n de calidad de servicio Fiber Optic

#### üìà Implementaci√≥n del Modelo
- Sistema de scoring de churn en tiempo real
- Dashboard de monitoreo de clientes en riesgo
- Alertas autom√°ticas para equipo de retenci√≥n
- Actualizaci√≥n trimestral del modelo con nuevos datos

### Pr√≥ximos Pasos

1. üöÄ **Implementaci√≥n en Producci√≥n**: API REST para scoring en tiempo real
2. üìä **Dashboard Ejecutivo**: Visualizaci√≥n de m√©tricas y clientes en riesgo
3. üß™ **A/B Testing**: Validar efectividad de estrategias de retenci√≥n
4. üîÑ **Reentrenamiento Autom√°tico**: Pipeline MLOps para actualizaci√≥n continua
5. ü§ñ **Modelos Avanzados**: Explorar Deep Learning y AutoML

---

## üë• Autores

Este proyecto fue desarrollado por:

- **Anderson Tabima**
- **Antony Tabima**
- **Yhabeidy Alejandra Agudelo**
- **Carlos Mario Londo√±o**
- **Nataly Bedoya**
- **Sebastian Cano**
- **√Ålvaro √Ångel Molina** - [@alvaretto](https://github.com/alvaretto)

---

## üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT. Ver el archivo [LICENSE](LICENSE) para m√°s detalles.

---

## üôè Agradecimientos

- Dataset proporcionado por [Kaggle - Telco Customer Churn](https://www.kaggle.com/blastchar/telco-customer-churn)
- Comunidad de scikit-learn, XGBoost e imbalanced-learn por sus excelentes herramientas
- Proyecto desarrollado como parte del BootCamp de Inteligencia Artificial

---

## üìö Referencias

- [Scikit-learn Documentation](https://scikit-learn.org/stable/)
- [XGBoost Documentation](https://xgboost.readthedocs.io/)
- [Imbalanced-learn Documentation](https://imbalanced-learn.org/)
- [SMOTE: Synthetic Minority Over-sampling Technique](https://arxiv.org/abs/1106.1813)

---

<div align="center">

**‚≠ê Si este proyecto te fue √∫til, considera darle una estrella ‚≠ê**

</div>

