# ğŸ“Š PredicciÃ³n de Abandono de Clientes en Telecomunicaciones

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-orange.svg)](https://jupyter.org/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.0%2B-yellow.svg)](https://scikit-learn.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)

> Proyecto de Machine Learning para predecir el abandono de clientes (Customer Churn) en empresas de telecomunicaciones utilizando tÃ©cnicas avanzadas de anÃ¡lisis de datos y modelado predictivo.

---

## ğŸ“‘ Tabla de Contenidos

- [DescripciÃ³n del Proyecto](#-descripciÃ³n-del-proyecto)
- [CaracterÃ­sticas Principales](#-caracterÃ­sticas-principales)
- [TecnologÃ­as Utilizadas](#-tecnologÃ­as-utilizadas)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [Requisitos Previos](#-requisitos-previos)
- [InstalaciÃ³n](#-instalaciÃ³n)
- [Uso](#-uso)
- [MetodologÃ­a](#-metodologÃ­a)
- [Resultados](#-resultados)
- [Conclusiones](#-conclusiones)
- [Autor](#-autor)
- [Licencia](#-licencia)

---

## ğŸ¯ DescripciÃ³n del Proyecto

Este proyecto presenta un **anÃ¡lisis completo de predicciÃ³n de abandono de clientes** (Customer Churn) en una empresa de telecomunicaciones. El objetivo principal es desarrollar modelos de Machine Learning que permitan identificar clientes con alta probabilidad de abandonar el servicio, facilitando estrategias de retenciÃ³n proactivas.

### Objetivos

- ğŸ” Realizar un anÃ¡lisis exploratorio exhaustivo del comportamiento de clientes
- ğŸ› ï¸ Aplicar tÃ©cnicas de ingenierÃ­a de caracterÃ­sticas para mejorar el rendimiento
- âš–ï¸ Manejar el desbalanceo de clases mediante tÃ©cnicas avanzadas (SMOTE)
- ğŸ¤– Comparar mÃºltiples algoritmos de Machine Learning
- ğŸ“ˆ Optimizar hiperparÃ¡metros para maximizar el rendimiento
- ğŸ’¡ Generar insights accionables para estrategias de retenciÃ³n

---

## âœ¨ CaracterÃ­sticas Principales

- âœ… **AnÃ¡lisis Exploratorio Completo (EDA)**: Visualizaciones detalladas y anÃ¡lisis estadÃ­stico
- âœ… **Limpieza de Datos Robusta**: Manejo de valores faltantes y conversiÃ³n de tipos
- âœ… **Feature Engineering Avanzado**: CreaciÃ³n de 6 nuevas caracterÃ­sticas derivadas
- âœ… **Pipeline de Preprocesamiento**: ColumnTransformer con encoding y scaling
- âœ… **ComparaciÃ³n de 7 Modelos**: Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, XGBoost, SVM, KNN
- âœ… **Manejo de Desbalanceo**: SMOTE (Synthetic Minority Over-sampling Technique)
- âœ… **OptimizaciÃ³n de HiperparÃ¡metros**: RandomizedSearchCV con validaciÃ³n cruzada
- âœ… **EvaluaciÃ³n Completa**: MÃºltiples mÃ©tricas (ROC-AUC, Precision, Recall, F1-Score)
- âœ… **Interpretabilidad**: AnÃ¡lisis de importancia de caracterÃ­sticas
- âœ… **DocumentaciÃ³n Profesional**: CÃ³digo limpio y bien comentado

---

## ğŸ› ï¸ TecnologÃ­as Utilizadas

### Lenguaje y Entorno
- **Python** 3.8+
- **Jupyter Notebook** 6.0+

### LibrerÃ­as de AnÃ¡lisis de Datos
- **NumPy** 1.21+ - ComputaciÃ³n numÃ©rica
- **Pandas** 1.3+ - ManipulaciÃ³n de datos

### VisualizaciÃ³n
- **Matplotlib** 3.4+ - GrÃ¡ficos estÃ¡ticos
- **Seaborn** 0.11+ - Visualizaciones estadÃ­sticas

### Machine Learning
- **scikit-learn** 1.0+ - Algoritmos de ML y preprocesamiento
- **XGBoost** 1.5+ - Gradient Boosting optimizado
- **imbalanced-learn** 0.8+ - TÃ©cnicas para datos desbalanceados (SMOTE)

---

## ğŸ“ Estructura del Proyecto

```
telco-customer-churn-prediction/
â”‚
â”œâ”€â”€ Telco-Customer-Churn.ipynb          # Notebook principal optimizado
â”œâ”€â”€ WA_Fn-UseC_-Telco-Customer-Churn.csv # Dataset (7,043 registros)
â”œâ”€â”€ MEJORAS_REALIZADAS.md                # DocumentaciÃ³n de mejoras
â”œâ”€â”€ INSTRUCCIONES.md                     # GuÃ­a de ejecuciÃ³n y defensa
â”œâ”€â”€ README.md                            # Este archivo
â”œâ”€â”€ LICENSE                              # Licencia MIT
â””â”€â”€ .gitignore                           # Archivos excluidos de Git
```

---

## ğŸ“‹ Requisitos Previos

- Python 3.8 o superior
- pip o conda para gestiÃ³n de paquetes
- Jupyter Notebook o JupyterLab
- 4GB de RAM mÃ­nimo (recomendado 8GB)

---

## ğŸš€ InstalaciÃ³n

### 1. Clonar el repositorio

```bash
git clone https://github.com/alvaretto/telco-customer-churn-prediction.git
cd telco-customer-churn-prediction
```

### 2. Crear entorno virtual (recomendado)

```bash
# Con venv
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# O con conda
conda create -n churn-env python=3.8
conda activate churn-env
```

### 3. Instalar dependencias

```bash
pip install numpy pandas matplotlib seaborn scikit-learn xgboost imbalanced-learn jupyter
```

O con conda:

```bash
conda install numpy pandas matplotlib seaborn scikit-learn xgboost imbalanced-learn jupyter -c conda-forge
```

---

## ğŸ’» Uso

### Ejecutar el Notebook

1. Iniciar Jupyter Notebook:
   ```bash
   jupyter notebook
   ```

2. Abrir `Telco-Customer-Churn.ipynb`

3. Ejecutar todas las celdas secuencialmente:
   - MenÃº: `Cell` â†’ `Run All`
   - O ejecutar celda por celda con `Shift + Enter`

### Tiempo de EjecuciÃ³n

- **AnÃ¡lisis Exploratorio**: ~2-3 minutos
- **Modelado Baseline**: ~3-5 minutos
- **SMOTE y Reentrenamiento**: ~2-3 minutos
- **OptimizaciÃ³n de HiperparÃ¡metros**: ~5-10 minutos
- **EvaluaciÃ³n Final**: ~1-2 minutos

**Total**: Aproximadamente 15-25 minutos

---

## ğŸ”¬ MetodologÃ­a

### 1. AnÃ¡lisis Exploratorio de Datos (EDA)

- AnÃ¡lisis de la variable objetivo (Churn: 73% No, 27% Yes)
- ExploraciÃ³n de variables categÃ³ricas con tasas de churn
- AnÃ¡lisis de variables numÃ©ricas (distribuciones, outliers)
- Matriz de correlaciÃ³n para identificar relaciones

### 2. Limpieza y Preprocesamiento

- CorrecciÃ³n de tipos de datos (TotalCharges: object â†’ numeric)
- Manejo de valores faltantes (11 registros con TotalCharges vacÃ­o)
- ImputaciÃ³n inteligente basada en MonthlyCharges

### 3. Feature Engineering

CreaciÃ³n de 6 nuevas caracterÃ­sticas derivadas:

| Feature | DescripciÃ³n |
|---------|-------------|
| `ChargeRatio` | Ratio entre MonthlyCharges y TotalCharges |
| `AvgMonthlyCharges` | Promedio de cargos mensuales segÃºn tenure |
| `TenureGroup` | CategorizaciÃ³n de tenure (0-12, 13-24, 25-48, 49-72) |
| `TotalServices` | NÃºmero total de servicios contratados |
| `SeniorWithDependents` | CombinaciÃ³n de SeniorCitizen y Dependents |
| `HighValueContract` | IdentificaciÃ³n de contratos de alto valor |

### 4. PreparaciÃ³n de Datos

- DivisiÃ³n estratificada train/test (80/20)
- Pipeline de preprocesamiento con ColumnTransformer
- StandardScaler para variables numÃ©ricas
- OneHotEncoder para variables categÃ³ricas

### 5. Modelado Baseline

ComparaciÃ³n de 7 algoritmos de Machine Learning:

1. **Logistic Regression** - Modelo lineal baseline
2. **Decision Tree** - Modelo no lineal simple
3. **Random Forest** - Ensemble de Ã¡rboles
4. **Gradient Boosting** - Boosting secuencial
5. **XGBoost** - Gradient Boosting optimizado
6. **SVM** - Support Vector Machine
7. **KNN** - K-Nearest Neighbors

### 6. Manejo de Desbalanceo

- AplicaciÃ³n de **SMOTE** para balancear clases (73:27 â†’ 50:50)
- Reentrenamiento de los mejores modelos con datos balanceados
- ComparaciÃ³n de rendimiento antes/despuÃ©s de SMOTE

### 7. OptimizaciÃ³n de HiperparÃ¡metros

- **RandomizedSearchCV** con 50 iteraciones
- ValidaciÃ³n cruzada estratificada (5-fold)
- OptimizaciÃ³n basada en ROC-AUC
- BÃºsqueda en espacio de hiperparÃ¡metros de Random Forest

### 8. EvaluaciÃ³n y ValidaciÃ³n

- MÃ©tricas mÃºltiples: Accuracy, Precision, Recall, F1-Score, ROC-AUC
- Matriz de confusiÃ³n detallada
- Curvas ROC y Precision-Recall
- ValidaciÃ³n cruzada para estabilidad del modelo
- AnÃ¡lisis de feature importance

---

## ğŸ“Š Resultados

### Rendimiento del Mejor Modelo (Random Forest Optimizado)

| MÃ©trica | Valor |
|---------|-------|
| **ROC-AUC** | ~0.85-0.90 |
| **Accuracy** | ~0.80-0.85 |
| **Precision** | ~0.65-0.75 |
| **Recall** | ~0.75-0.85 |
| **F1-Score** | ~0.70-0.80 |

### Factores Clave de Churn Identificados

1. **Tenure** (AntigÃ¼edad del cliente)
   - Clientes nuevos (0-12 meses) tienen mayor riesgo de abandono
   - La retenciÃ³n mejora significativamente despuÃ©s de 24 meses

2. **Contract** (Tipo de contrato)
   - Contratos mes a mes: ~42% de churn
   - Contratos de 1 aÃ±o: ~11% de churn
   - Contratos de 2 aÃ±os: ~3% de churn

3. **TotalCharges/MonthlyCharges**
   - RelaciÃ³n directa con probabilidad de churn
   - Clientes con cargos muy altos o muy bajos tienen mayor riesgo

4. **InternetService**
   - Fiber Optic presenta mayor tasa de churn
   - Posible indicador de insatisfacciÃ³n con el servicio

5. **Servicios Adicionales**
   - TechSupport, OnlineSecurity reducen significativamente el churn
   - Clientes con mÃ¡s servicios tienden a permanecer

### Impacto de SMOTE

- **Mejora en Recall**: +15-20% (mejor detecciÃ³n de clientes en riesgo)
- **Balance Precision-Recall**: Optimizado para el caso de uso
- **ReducciÃ³n de Falsos Negativos**: CrÃ­tico para retenciÃ³n proactiva

---

## ğŸ’¡ Conclusiones

### Hallazgos Principales

1. âœ… **El modelo Random Forest optimizado** logra excelente capacidad discriminativa (ROC-AUC ~0.85-0.90)
2. âœ… **SMOTE mejora significativamente** la detecciÃ³n de clientes en riesgo
3. âœ… **Los primeros 12 meses** son crÃ­ticos para la retenciÃ³n
4. âœ… **Contratos de largo plazo** son el factor mÃ¡s protector contra churn
5. âœ… **Servicios adicionales** (soporte tÃ©cnico, seguridad) aumentan la lealtad

### Recomendaciones de Negocio

#### ğŸ¯ RetenciÃ³n Proactiva
- Implementar programa de seguimiento intensivo para clientes nuevos (0-12 meses)
- Contacto personalizado en momentos crÃ­ticos (mes 3, 6, 12)
- AsignaciÃ³n de account manager para clientes de alto valor

#### ğŸ’° Estrategia de Contratos
- Incentivos agresivos para migraciÃ³n a contratos de 1-2 aÃ±os
- Descuentos progresivos por compromiso de permanencia
- Penalizaciones reducidas por cancelaciÃ³n anticipada

#### ğŸ› ï¸ Mejora de Servicios
- PromociÃ³n activa de TechSupport y OnlineSecurity
- Bundles atractivos de servicios complementarios
- RevisiÃ³n de calidad de servicio Fiber Optic

#### ğŸ“ˆ ImplementaciÃ³n del Modelo
- Sistema de scoring de churn en tiempo real
- Dashboard de monitoreo de clientes en riesgo
- Alertas automÃ¡ticas para equipo de retenciÃ³n
- ActualizaciÃ³n trimestral del modelo con nuevos datos

### PrÃ³ximos Pasos

1. ğŸš€ **ImplementaciÃ³n en ProducciÃ³n**: API REST para scoring en tiempo real
2. ğŸ“Š **Dashboard Ejecutivo**: VisualizaciÃ³n de mÃ©tricas y clientes en riesgo
3. ğŸ§ª **A/B Testing**: Validar efectividad de estrategias de retenciÃ³n
4. ğŸ”„ **Reentrenamiento AutomÃ¡tico**: Pipeline MLOps para actualizaciÃ³n continua
5. ğŸ¤– **Modelos Avanzados**: Explorar Deep Learning y AutoML

---

## ğŸ‘¨â€ğŸ’» Autor

**Ãlvaro Ãngel Molina**

- GitHub: [@alvaretto](https://github.com/alvaretto)
- Email: alvaretto@users.noreply.github.com

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

---

## ğŸ™ Agradecimientos

- Dataset proporcionado por [Kaggle - Telco Customer Churn](https://www.kaggle.com/blastchar/telco-customer-churn)
- Comunidad de scikit-learn y XGBoost por sus excelentes herramientas
- Proyecto desarrollado como parte de formaciÃ³n en Inteligencia Artificial

---

## ğŸ“š Referencias

- [Scikit-learn Documentation](https://scikit-learn.org/stable/)
- [XGBoost Documentation](https://xgboost.readthedocs.io/)
- [Imbalanced-learn Documentation](https://imbalanced-learn.org/)
- [SMOTE: Synthetic Minority Over-sampling Technique](https://arxiv.org/abs/1106.1813)

---

<div align="center">

**â­ Si este proyecto te fue Ãºtil, considera darle una estrella â­**

</div>

