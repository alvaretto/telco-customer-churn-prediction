# Bloque 9: Manejo del Desbalanceo de Clases

## üìã Descripci√≥n General

Este bloque es como **equilibrar una balanza desnivelada**. Recordemos que tenemos 73% de clientes que NO hacen churn y solo 27% que S√ç lo hacen. Este desbalanceo puede hacer que los modelos sean "perezosos" y simplemente predigan siempre la clase mayoritaria. Aqu√≠ aplicamos t√©cnicas para balancear las clases y mejorar la detecci√≥n de churn.

---

## üéØ Prop√≥sito y Objetivo

Los objetivos principales de este bloque son:

1. **Aplicar SMOTE** para balancear las clases en el conjunto de entrenamiento
2. **Reentrenar los mejores modelos** con datos balanceados
3. **Comparar resultados** antes y despu√©s del balanceo
4. **Mejorar el Recall** (detecci√≥n de clientes que har√°n churn)

### ¬øPor qu√© es importante?

**Analog√≠a de la enfermedad rara**: Imagina un test m√©dico para una enfermedad que solo afecta al 3% de la poblaci√≥n:
- Un modelo "tonto" que siempre dice "NO tienes la enfermedad" tendr√≠a 97% de accuracy
- Pero ser√≠a in√∫til porque nunca detectar√≠a a los enfermos

Lo mismo pasa con el churn: necesitamos detectar espec√≠ficamente a los que S√ç se van, no solo tener alta accuracy general.

---

## üîë Conceptos Clave y T√©cnicas Utilizadas

### 1. **El Problema del Desbalanceo**

**Distribuci√≥n original**:
- **No Churn**: ~5,163 clientes (73%)
- **Churn**: ~1,869 clientes (27%)

**Ratio**: ~2.76:1 (casi 3 veces m√°s "No" que "Yes")

**Consecuencias**:
- Los modelos aprenden mejor la clase mayoritaria
- Baja sensibilidad para detectar churn
- M√©tricas enga√±osas (alta accuracy pero bajo recall)

**Analog√≠a del profesor**: Si en una clase hay 73 estudiantes callados y 27 habladores, el profesor prestar√° m√°s atenci√≥n a los callados (mayor√≠a) y puede ignorar a los habladores (minor√≠a).

---

### 2. **SMOTE (Synthetic Minority Over-sampling Technique)**

**¬øQu√© es SMOTE?**

Una t√©cnica que crea **ejemplos sint√©ticos** de la clase minoritaria (Churn=Yes) para balancear el dataset.

**¬øC√≥mo funciona?**

1. Toma un ejemplo de la clase minoritaria
2. Encuentra sus K vecinos m√°s cercanos (tambi√©n de la clase minoritaria)
3. Crea nuevos ejemplos interpolando entre el ejemplo original y sus vecinos

**Analog√≠a visual**:
```
Original:  A -------- B
                ‚Üì
Sint√©tico: A -- X -- B
```

Donde X es un nuevo ejemplo creado "entre" A y B.

**Ventajas de SMOTE**:
- ‚úÖ Crea ejemplos realistas (no duplicados)
- ‚úÖ Aumenta la diversidad de la clase minoritaria
- ‚úÖ Mejora el aprendizaje del modelo

**Diferencia con otras t√©cnicas**:
- **RandomOverSampler**: Simplemente duplica ejemplos existentes (puede causar overfitting)
- **RandomUnderSampler**: Elimina ejemplos de la clase mayoritaria (pierde informaci√≥n)
- **SMOTE**: Crea nuevos ejemplos sint√©ticos (balance sin p√©rdida de informaci√≥n)

---

### 3. **Aplicaci√≥n de SMOTE**

```python
smote = SMOTE(random_state=42)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)
```

**Resultado**:
- **Antes**: 5,163 No Churn, 1,869 Churn
- **Despu√©s**: 5,163 No Churn, 5,163 Churn (balanceado 50/50)

**Importante**: SMOTE solo se aplica al conjunto de **entrenamiento**, NUNCA al de prueba.

**¬øPor qu√©?**

**Analog√≠a del examen**: 
- Puedes estudiar con material adicional (SMOTE en train)
- Pero el examen debe ser con preguntas reales (test sin modificar)

---

### 4. **Reentrenamiento de Modelos**

El bloque reentrena los mejores modelos (identificados en el bloque anterior) con los datos balanceados:

1. **Logistic Regression**
2. **Random Forest**
3. **Gradient Boosting**
4. **XGBoost**

**Configuraci√≥n**: Se mantienen los par√°metros por defecto (baseline) para comparaci√≥n justa.

---

## üìä Comparaci√≥n de Resultados: Antes vs. Despu√©s de SMOTE

### **M√©tricas T√≠picas - Antes de SMOTE**

| Modelo | Accuracy | Precision | Recall | F1-Score |
|--------|----------|-----------|--------|----------|
| Random Forest | 84% | 70% | 50% | 58% |
| XGBoost | 85% | 72% | 52% | 60% |

**Problema**: Recall bajo (solo detecta ~50% de los churns)

### **M√©tricas T√≠picas - Despu√©s de SMOTE**

| Modelo | Accuracy | Precision | Recall | F1-Score |
|--------|----------|-----------|--------|----------|
| Random Forest | 82% | 65% | 78% | 71% |
| XGBoost | 83% | 67% | 80% | 73% |

**Mejora**: Recall aumenta significativamente (~30% de mejora)

---

### **Interpretaci√≥n de los Cambios**

#### **Accuracy baja ligeramente** (84% ‚Üí 82%)
- **¬øPor qu√©?** Ahora el modelo comete m√°s "falsos positivos" (predice churn cuando no lo hay)
- **¬øEs malo?** No necesariamente - depende del objetivo de negocio

#### **Recall aumenta significativamente** (50% ‚Üí 78%)
- **¬øPor qu√©?** El modelo ahora detecta mejor la clase minoritaria
- **¬øEs bueno?** ¬°S√≠! Detectamos m√°s clientes en riesgo

#### **Precision baja un poco** (70% ‚Üí 65%)
- **¬øPor qu√©?** M√°s falsos positivos
- **Trade-off**: Sacrificamos un poco de precisi√≥n por mucho m√°s recall

---

### **Trade-off: Precision vs. Recall**

**Analog√≠a del detector de metales**:

**Antes de SMOTE** (Alta Precision, Bajo Recall):
- Cuando pita, casi siempre hay metal (pocas falsas alarmas)
- Pero se pierde mucho metal (no detecta todo)

**Despu√©s de SMOTE** (Precision moderada, Alto Recall):
- Pita m√°s veces, algunas falsas alarmas
- Pero encuentra casi todo el metal

**Para el negocio de Telco**:
- **Falso Positivo**: Ofrecemos descuento a alguien que no se iba a ir (costo: descuento innecesario)
- **Falso Negativo**: No detectamos a alguien que se va (costo: perder el cliente completo)

**Conclusi√≥n**: Es mejor tener algunos falsos positivos que perder clientes reales.

---

## üîó Relaci√≥n con el An√°lisis General

Este bloque es **cr√≠tico** porque:

1. **Corrige un problema fundamental**: El desbalanceo de clases
2. **Mejora la m√©trica clave**: Recall (detecci√≥n de churn)
3. **Alinea con objetivos de negocio**: Preferimos detectar m√°s churns aunque tengamos algunas falsas alarmas
4. **Prepara para optimizaci√≥n**: Datos balanceados permiten mejor ajuste de hiperpar√°metros

---

## üí° Puntos Clave para Recordar

1. **Desbalanceo original**: 73% No Churn, 27% Churn
2. **SMOTE** crea ejemplos sint√©ticos de la clase minoritaria
3. **Solo se aplica a train**, nunca a test
4. **Recall mejora ~30%** (de ~50% a ~78%)
5. **Trade-off**: Accuracy baja un poco, pero Recall aumenta mucho
6. **Para el negocio**: Mejor detectar m√°s churns con algunas falsas alarmas

---

## üéì Conclusi√≥n

El manejo del desbalanceo de clases transforma un modelo "perezoso" que ignora la clase minoritaria en uno que realmente detecta clientes en riesgo. SMOTE es como darle al modelo "gafas especiales" para ver mejor la clase minoritaria.

**Lecci√≥n importante**: En problemas de negocio, la m√©trica m√°s importante no siempre es accuracy. Para churn, Recall es cr√≠tico porque el costo de perder un cliente es mucho mayor que el costo de una falsa alarma.

**Siguiente paso**: Optimizar hiperpar√°metros de los mejores modelos para exprimir el m√°ximo rendimiento.

