# Bloque 8: Entrenamiento de Modelos Baseline

## ğŸ“‹ DescripciÃ³n General

Este bloque es como **una competencia deportiva donde varios atletas compiten** para ver quiÃ©n es el mejor. Entrenamos mÃºltiples algoritmos de Machine Learning diferentes y comparamos su rendimiento para identificar cuÃ¡les funcionan mejor para predecir el churn.

---

## ğŸ¯ PropÃ³sito y Objetivo

Los objetivos principales de este bloque son:

1. **Entrenar mÃºltiples modelos** con configuraciones por defecto (baseline)
2. **Evaluar el rendimiento** de cada modelo con mÃ©tricas apropiadas
3. **Comparar resultados** para identificar los mejores candidatos
4. **Establecer una lÃ­nea base** de rendimiento antes de optimizar

### Â¿Por quÃ© probar mÃºltiples modelos?

**AnalogÃ­a del transporte**: Si necesitas ir de A a B, podrÃ­as usar:
- Bicicleta (rÃ¡pida para distancias cortas)
- Auto (versÃ¡til)
- Tren (eficiente para largas distancias)
- AviÃ³n (rÃ¡pido pero costoso)

Cada uno tiene ventajas y desventajas. Lo mismo pasa con los algoritmos: cada uno tiene fortalezas en diferentes tipos de problemas.

---

## ğŸ”‘ Modelos Entrenados y Sus CaracterÃ­sticas

### 1. **Logistic Regression (RegresiÃ³n LogÃ­stica)**

**Â¿CÃ³mo funciona?**
- Encuentra una lÃ­nea (o hiperplano) que separa las dos clases
- Calcula la probabilidad de que un cliente haga churn

**Ventajas**:
- âœ… Simple y rÃ¡pido
- âœ… FÃ¡cil de interpretar
- âœ… Funciona bien con relaciones lineales

**Desventajas**:
- âŒ Asume relaciones lineales
- âŒ No captura patrones complejos

**AnalogÃ­a**: Es como trazar una lÃ­nea recta en un mapa para separar dos regiones.

---

### 2. **Decision Tree (Ãrbol de DecisiÃ³n)**

**Â¿CÃ³mo funciona?**
- Hace una serie de preguntas (if-then-else)
- Cada pregunta divide los datos en grupos mÃ¡s puros

**Ejemplo de decisiones**:
```
Â¿Contrato mes a mes?
â”œâ”€ SÃ­ â†’ Â¿Tenure < 12 meses?
â”‚  â”œâ”€ SÃ­ â†’ CHURN (alta probabilidad)
â”‚  â””â”€ No â†’ NO CHURN
â””â”€ No â†’ NO CHURN
```

**Ventajas**:
- âœ… Muy interpretable
- âœ… Captura relaciones no lineales
- âœ… No requiere normalizaciÃ³n

**Desventajas**:
- âŒ Propenso a overfitting (memorizar en vez de aprender)
- âŒ Inestable (pequeÃ±os cambios en datos â†’ Ã¡rbol muy diferente)

**AnalogÃ­a**: Como un diagrama de flujo de decisiones que sigues paso a paso.

---

### 3. **Random Forest (Bosque Aleatorio)**

**Â¿CÃ³mo funciona?**
- Crea muchos Ã¡rboles de decisiÃ³n (100-1000)
- Cada Ã¡rbol vota
- La decisiÃ³n final es por mayorÃ­a

**Ventajas**:
- âœ… Muy robusto y preciso
- âœ… Reduce overfitting vs. un solo Ã¡rbol
- âœ… Maneja bien datos complejos
- âœ… Proporciona importancia de features

**Desventajas**:
- âŒ Menos interpretable que un solo Ã¡rbol
- âŒ MÃ¡s lento de entrenar

**AnalogÃ­a**: Como pedir opiniÃ³n a 100 expertos y tomar la decisiÃ³n por votaciÃ³n mayoritaria.

---

### 4. **Gradient Boosting**

**Â¿CÃ³mo funciona?**
- Construye Ã¡rboles secuencialmente
- Cada Ã¡rbol nuevo corrige los errores del anterior
- Es como aprender de tus errores iterativamente

**Ventajas**:
- âœ… Muy preciso
- âœ… Captura patrones complejos
- âœ… Funciona bien en competencias de ML

**Desventajas**:
- âŒ MÃ¡s lento de entrenar
- âŒ Requiere ajuste cuidadoso de parÃ¡metros
- âŒ Propenso a overfitting si no se configura bien

**AnalogÃ­a**: Como un estudiante que hace un examen de prÃ¡ctica, revisa sus errores, estudia esas Ã¡reas y mejora en el siguiente intento.

---

### 5. **XGBoost (Extreme Gradient Boosting)**

**Â¿CÃ³mo funciona?**
- VersiÃ³n optimizada y mejorada de Gradient Boosting
- Incluye regularizaciÃ³n para prevenir overfitting
- Muy eficiente computacionalmente

**Ventajas**:
- âœ… Estado del arte en muchos problemas
- âœ… Muy preciso
- âœ… Maneja bien datos desbalanceados
- âœ… RÃ¡pido (comparado con Gradient Boosting tradicional)

**Desventajas**:
- âŒ Muchos hiperparÃ¡metros para ajustar
- âŒ Menos interpretable

**AnalogÃ­a**: Como Gradient Boosting pero con turbo y mejor motor.

---

### 6. **Support Vector Machine (SVM)**

**Â¿CÃ³mo funciona?**
- Encuentra el mejor hiperplano que separa las clases
- Maximiza el margen entre las clases

**Ventajas**:
- âœ… Efectivo en espacios de alta dimensiÃ³n
- âœ… Funciona bien con datos no lineales (usando kernels)

**Desventajas**:
- âŒ Lento con datasets grandes
- âŒ Sensible a la escala de datos
- âŒ DifÃ­cil de interpretar

**AnalogÃ­a**: Como encontrar la mejor valla para separar dos rebaÃ±os de ovejas, maximizando el espacio entre ellas.

---

### 7. **K-Nearest Neighbors (KNN)**

**Â¿CÃ³mo funciona?**
- Para clasificar un punto, mira sus K vecinos mÃ¡s cercanos
- Asigna la clase mÃ¡s comÃºn entre esos vecinos

**Ventajas**:
- âœ… Simple de entender
- âœ… No requiere entrenamiento (lazy learning)

**Desventajas**:
- âŒ Lento en predicciÃ³n con datasets grandes
- âŒ Sensible a la escala y ruido
- âŒ Requiere elegir K apropiado

**AnalogÃ­a**: "Dime con quiÃ©n andas y te dirÃ© quiÃ©n eres" - si tus 5 vecinos mÃ¡s cercanos hicieron churn, probablemente tÃº tambiÃ©n.

---

## ğŸ“Š MÃ©tricas de EvaluaciÃ³n

El bloque evalÃºa cada modelo con mÃºltiples mÃ©tricas:

### **1. Accuracy (Exactitud)**
- **Â¿QuÃ© mide?** Porcentaje de predicciones correctas
- **FÃ³rmula**: (Aciertos totales) / (Total de predicciones)
- **Problema**: Puede ser engaÃ±osa con datos desbalanceados

**Ejemplo**: Si 73% de clientes NO hacen churn, un modelo que siempre predice "NO" tendrÃ­a 73% de accuracy pero serÃ­a inÃºtil.

### **2. Precision (PrecisiÃ³n)**
- **Â¿QuÃ© mide?** De los que predijimos como churn, Â¿cuÃ¡ntos realmente lo hicieron?
- **FÃ³rmula**: Verdaderos Positivos / (Verdaderos Positivos + Falsos Positivos)
- **Importancia**: Evita falsas alarmas

**AnalogÃ­a**: De todas las veces que el detector de humo sonÃ³, Â¿cuÃ¡ntas veces realmente habÃ­a fuego?

### **3. Recall (Sensibilidad)**
- **Â¿QuÃ© mide?** De todos los que realmente hicieron churn, Â¿cuÃ¡ntos detectamos?
- **FÃ³rmula**: Verdaderos Positivos / (Verdaderos Positivos + Falsos Negativos)
- **Importancia**: No perder clientes en riesgo

**AnalogÃ­a**: De todos los incendios que hubo, Â¿cuÃ¡ntos detectÃ³ el detector de humo?

### **4. F1-Score**
- **Â¿QuÃ© mide?** Balance entre Precision y Recall
- **FÃ³rmula**: 2 Ã— (Precision Ã— Recall) / (Precision + Recall)
- **Importancia**: MÃ©trica equilibrada

### **5. ROC-AUC**
- **Â¿QuÃ© mide?** Capacidad del modelo para discriminar entre clases
- **Rango**: 0.5 (aleatorio) a 1.0 (perfecto)
- **Importancia**: Independiente del umbral de decisiÃ³n

---

## ğŸ† Resultados TÃ­picos (Baseline)

**Modelos de mejor rendimiento** (generalmente):
1. **XGBoost**: ~85% accuracy, ~0.85 ROC-AUC
2. **Random Forest**: ~84% accuracy, ~0.84 ROC-AUC
3. **Gradient Boosting**: ~83% accuracy, ~0.83 ROC-AUC

**Modelos de rendimiento moderado**:
4. **Logistic Regression**: ~80% accuracy
5. **SVM**: ~79% accuracy

**Modelos de menor rendimiento**:
6. **Decision Tree**: ~75% accuracy (overfitting)
7. **KNN**: ~76% accuracy

---

## ğŸ”— RelaciÃ³n con el AnÃ¡lisis General

Este bloque es **crucial** porque:

1. **Identifica candidatos**: Descubrimos quÃ© modelos funcionan mejor
2. **Establece baseline**: Punto de referencia para mejoras futuras
3. **Informa optimizaciÃ³n**: Sabemos en quÃ© modelos invertir tiempo
4. **Valida el enfoque**: Confirma que el problema es predecible

---

## ğŸ’¡ Puntos Clave para Recordar

1. **7 modelos diferentes** entrenados y comparados
2. **Ensemble methods** (Random Forest, Gradient Boosting, XGBoost) suelen ganar
3. **Accuracy no es suficiente** - necesitamos mÃºltiples mÃ©tricas
4. **Baseline = configuraciÃ³n por defecto** - aÃºn no optimizado
5. **Desbalanceo de clases** afecta el rendimiento (se abordarÃ¡ en el siguiente bloque)

---

## ğŸ“ ConclusiÃ³n

El entrenamiento de modelos baseline es como una audiciÃ³n: probamos varios candidatos para ver quiÃ©nes tienen potencial. Los modelos ensemble (Random Forest, XGBoost) generalmente destacan, pero todos aportan informaciÃ³n valiosa.

**Siguiente paso**: Manejar el desbalanceo de clases con tÃ©cnicas como SMOTE para mejorar la detecciÃ³n de churn.

