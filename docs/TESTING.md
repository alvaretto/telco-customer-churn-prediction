# üß™ Gu√≠a de Testing - Telco Customer Churn Prediction

## üìã Tabla de Contenidos

- [Introducci√≥n](#introducci√≥n)
- [Tests Unitarios](#tests-unitarios)
- [Tests de Integraci√≥n](#tests-de-integraci√≥n)
- [Ejecuci√≥n de Tests](#ejecuci√≥n-de-tests)
- [CI/CD](#cicd)
- [Monitoreo de Producci√≥n](#monitoreo-de-producci√≥n)

---

## üéØ Introducci√≥n

Este proyecto incluye una suite completa de tests para garantizar la calidad y confiabilidad del c√≥digo:

- **Tests Unitarios**: Validan componentes individuales (API, modelo)
- **Tests de Integraci√≥n**: Validan el funcionamiento end-to-end
- **Monitoreo de Producci√≥n**: Valida que los servicios deployados funcionen correctamente
- **CI/CD**: Automatizaci√≥n de tests en cada push

---

## üî¨ Tests Unitarios

### Ubicaci√≥n

```
tests/
‚îú‚îÄ‚îÄ test_api.py      # Tests de la API Flask
‚îî‚îÄ‚îÄ test_model.py    # Tests del modelo ML
```

### Tests de la API (`test_api.py`)

**Cobertura:**
- ‚úÖ Endpoint `/` (home)
- ‚úÖ Endpoint `/health` (health check)
- ‚úÖ Endpoint `/model_info` (informaci√≥n del modelo)
- ‚úÖ Endpoint `/predict` (predicci√≥n individual)
- ‚úÖ Endpoint `/predict_batch` (predicciones en lote)
- ‚úÖ Validaci√≥n de datos de entrada
- ‚úÖ Manejo de errores

**Total de tests:** 7

### Tests del Modelo (`test_model.py`)

**Cobertura:**
- ‚úÖ Existencia de archivos del modelo
- ‚úÖ Carga correcta del modelo
- ‚úÖ Carga correcta del preprocessor
- ‚úÖ Estructura de metadata
- ‚úÖ M√©todos del modelo (predict, predict_proba)
- ‚úÖ Formato de predicciones
- ‚úÖ Validaci√≥n de m√©tricas

**Total de tests:** 10

---

## üîó Tests de Integraci√≥n

### Script de Validaci√≥n de Deployment

**Ubicaci√≥n:** `scripts/validate_deployment.py`

**Funcionalidad:**
- Valida todos los endpoints de la API
- Prueba predicciones con casos de alto y bajo riesgo
- Verifica accesibilidad del dashboard
- Genera reporte detallado

**Uso:**
```bash
python scripts/validate_deployment.py
```

**Salida esperada:**
```
‚úÖ Todos los checks pasaron! Deployment validado exitosamente.
```

---

## üöÄ Ejecuci√≥n de Tests

### Opci√≥n 1: Ejecuci√≥n Local (Requiere Infraestructura)

‚ö†Ô∏è **Nota:** La ejecuci√≥n local requiere instalar todas las dependencias pesadas (scikit-learn, pandas, flask, etc.)

```bash
# Instalar dependencias
pip install -r api/requirements.txt
pip install pytest pytest-cov

# Ejecutar todos los tests
pytest tests/ -v

# Ejecutar con cobertura
pytest tests/ -v --cov=api --cov=models --cov-report=html

# Ver reporte de cobertura
open htmlcov/index.html
```

### Opci√≥n 2: Ejecuci√≥n en Google Colab (Recomendado)

Si no tienes infraestructura local, puedes ejecutar los tests en Google Colab:

```python
# En Google Colab
!git clone https://github.com/alvaretto/telco-customer-churn-prediction.git
%cd telco-customer-churn-prediction

# Instalar dependencias
!pip install -r api/requirements.txt
!pip install pytest pytest-cov

# Ejecutar tests
!pytest tests/ -v --cov=api --cov=models
```

### Opci√≥n 3: CI/CD con GitHub Actions (Autom√°tico)

Los tests se ejecutan autom√°ticamente en cada push a trav√©s de GitHub Actions.

Ver: `.github/workflows/ci.yml`

---

## ü§ñ CI/CD

### GitHub Actions Workflows

#### 1. CI Pipeline (`.github/workflows/ci.yml`)

**Triggers:**
- Push a `main` o `develop`
- Pull requests a `main`

**Jobs:**
- **test**: Ejecuta tests unitarios con pytest
- **lint**: Verifica calidad de c√≥digo (flake8, black, isort)
- **monitor**: Monitorea producci√≥n (solo en main)
- **security**: Escaneo de vulnerabilidades con Trivy

#### 2. Deploy Pipeline (`.github/workflows/deploy.yml`)

**Triggers:**
- Push a `main` que modifique `api/`, `dashboard/`, o `models/`

**Jobs:**
- **notify-deployment**: Notifica inicio de deployment
- **verify-api**: Verifica que la API est√© funcionando
- **verify-dashboard**: Verifica que el Dashboard est√© funcionando
- **deployment-summary**: Genera resumen del deployment

### Ver Estado de CI/CD

- **GitHub Actions**: https://github.com/alvaretto/telco-customer-churn-prediction/actions
- **Badges en README**: Muestran estado actual de CI/CD

---

## üìä Monitoreo de Producci√≥n

### Script de Monitoreo

**Ubicaci√≥n:** `scripts/monitor_production.py`

**Funcionalidad:**
- Verifica health de la API
- Verifica informaci√≥n del modelo
- Prueba predicciones
- Verifica accesibilidad del dashboard

**Uso:**
```bash
python scripts/monitor_production.py
```

**Salida esperada:**
```
üéâ ¬°Todos los servicios est√°n funcionando correctamente!
üéØ Total: 4/4 checks pasaron
```

### Ejecuci√≥n Autom√°tica

El script de monitoreo se ejecuta autom√°ticamente:
- En cada push a `main` (GitHub Actions)
- Puede configurarse como cron job para monitoreo continuo

---

## üìà M√©tricas de Cobertura

### Cobertura Actual

| Componente | Cobertura | Tests |
|------------|-----------|-------|
| API | ~85% | 7 tests |
| Modelo | ~90% | 10 tests |
| **Total** | **~87%** | **17 tests** |

### Objetivo

- Mantener cobertura > 80%
- Agregar tests para nuevas funcionalidades
- Revisar cobertura en cada PR

---

## üîß Troubleshooting

### Error: "No module named 'pytest'"

```bash
pip install pytest pytest-cov
```

### Error: "No module named 'flask'"

```bash
pip install -r api/requirements.txt
```

### Error: "Model file not found"

Aseg√∫rate de que Git LFS est√© configurado:
```bash
git lfs install
git lfs pull
```

### Tests fallan en CI/CD

1. Verifica que las dependencias est√©n en `requirements.txt`
2. Revisa los logs en GitHub Actions
3. Aseg√∫rate de que Git LFS est√© configurado en el repositorio

---

## üìö Recursos Adicionales

- **Pytest Documentation**: https://docs.pytest.org/
- **GitHub Actions**: https://docs.github.com/en/actions
- **Coverage.py**: https://coverage.readthedocs.io/

---

**√öltima actualizaci√≥n:** 2025-11-21  
**Mantenido por:** √Ålvaro √Ångel Molina (@alvaretto)

