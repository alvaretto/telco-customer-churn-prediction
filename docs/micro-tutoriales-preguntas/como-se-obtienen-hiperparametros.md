---
title: "Â¿CÃ³mo se Obtienen los HiperparÃ¡metros?"
author: "Bootcamp VirtIA - ExplicaciÃ³n Detallada"
date: "`r Sys.Date()`"
output:
  html_document: default
  pdf_document:
    latex_engine: xelatex
    keep_tex: false
    toc: true
    toc_depth: 3
---

# ğŸ¯ Â¿CÃ³mo se Obtienen los HiperparÃ¡metros?

## ğŸ“š Conceptos Fundamentales

### Â¿QuÃ© son los HiperparÃ¡metros?

Los **hiperparÃ¡metros** son parÃ¡metros de configuraciÃ³n del modelo que **NO se aprenden** durante el entrenamiento, sino que **se definen ANTES** de entrenar el modelo.

**Diferencia clave:**

- **ParÃ¡metros**: Se aprenden automÃ¡ticamente (ej: pesos de una red neuronal, coeficientes de regresiÃ³n)
- **HiperparÃ¡metros**: Se configuran manualmente (ej: nÃºmero de Ã¡rboles, profundidad mÃ¡xima)

### Ejemplos en Random Forest

Para un Random Forest, los hiperparÃ¡metros incluyen:

- `n_estimators`: NÃºmero de Ã¡rboles en el bosque (100, 200, 300...)
- `max_depth`: Profundidad mÃ¡xima de cada Ã¡rbol (10, 20, None...)
- `min_samples_split`: MÃ­nimo de muestras para dividir un nodo (2, 5, 10...)
- `min_samples_leaf`: MÃ­nimo de muestras en una hoja (1, 2, 4...)
- `max_features`: NÃºmero de features a considerar ('sqrt', 'log2')
- `bootstrap`: Si usar muestreo con reemplazo (True, False)

---

## ğŸ” Proceso de ObtenciÃ³n de HiperparÃ¡metros

### Paso 1: Definir el Espacio de BÃºsqueda

Primero, defines un **diccionario** con los hiperparÃ¡metros que quieres probar y sus posibles valores:

```python
param_distributions = {
    'n_estimators': [100, 200, 300],        # 3 opciones
    'max_depth': [10, 20, None],            # 3 opciones
    'min_samples_split': [2, 5],            # 2 opciones
    'min_samples_leaf': [1, 2],             # 2 opciones
    'max_features': ['sqrt', 'log2'],       # 2 opciones
    'bootstrap': [True, False]              # 2 opciones
}
```

**Total de combinaciones posibles**: 3 Ã— 3 Ã— 2 Ã— 2 Ã— 2 Ã— 2 = **144 combinaciones**

### Paso 2: Crear el Modelo Base

Creas una instancia del modelo sin especificar los hiperparÃ¡metros (usarÃ¡ valores por defecto):

```python
rf_base = RandomForestClassifier(random_state=42)
```

### Paso 3: Configurar RandomizedSearchCV

`RandomizedSearchCV` es una herramienta que:

1. **Prueba combinaciones aleatorias** de hiperparÃ¡metros
2. **EvalÃºa cada combinaciÃ³n** usando validaciÃ³n cruzada
3. **Selecciona la mejor combinaciÃ³n** segÃºn la mÃ©trica elegida

```python
random_search = RandomizedSearchCV(
    estimator=rf_base,                      # Modelo a optimizar
    param_distributions=param_distributions, # Espacio de bÃºsqueda
    n_iter=20,                              # Probar 20 combinaciones aleatorias
    cv=3,                                   # ValidaciÃ³n cruzada con 3 folds
    scoring='roc_auc',                      # MÃ©trica a optimizar
    random_state=42,                        # Reproducibilidad
    n_jobs=-1,                              # Usar todos los CPUs
    verbose=1                               # Mostrar progreso
)
```

**Â¿Por quÃ© 20 iteraciones y no las 144 posibles?**

- **Eficiencia**: Probar 20 combinaciones toma ~3 minutos vs ~20 minutos para todas
- **Efectividad**: RandomizedSearchCV encuentra buenas combinaciones rÃ¡pidamente
- **Trade-off**: PÃ©rdida mÃ­nima de precisiÃ³n (~0.5-1%) con 85% menos tiempo

### Paso 4: Entrenar y Buscar

El mÃ©todo `.fit()` realiza la bÃºsqueda:

```python
random_search.fit(X_train_balanced, y_train_balanced)
```

**Â¿QuÃ© hace internamente?**

1. **Selecciona 20 combinaciones aleatorias** del espacio de bÃºsqueda
2. **Para cada combinaciÃ³n**:
   - Divide los datos en 3 folds (cv=3)
   - Entrena el modelo en 2 folds y valida en 1
   - Repite 3 veces (cada fold se usa una vez para validaciÃ³n)
   - Calcula el promedio de ROC-AUC de los 3 folds
3. **Guarda la combinaciÃ³n con mejor ROC-AUC promedio**

### Paso 5: Obtener los Mejores HiperparÃ¡metros

Una vez completada la bÃºsqueda, accedes a los resultados:

```python
# Mejores hiperparÃ¡metros encontrados
print(random_search.best_params_)
# Ejemplo de salida:
# {
#     'n_estimators': 200,
#     'max_depth': 20,
#     'min_samples_split': 2,
#     'min_samples_leaf': 1,
#     'max_features': 'sqrt',
#     'bootstrap': True
# }

# Mejor score de validaciÃ³n cruzada
print(random_search.best_score_)  # Ej: 0.9365

# Modelo ya entrenado con los mejores hiperparÃ¡metros
best_model = random_search.best_estimator_
```

---

## ğŸ² Ejemplo PrÃ¡ctico Paso a Paso

### SimulaciÃ³n de lo que hace RandomizedSearchCV

Imagina que RandomizedSearchCV prueba estas 5 combinaciones (de las 20):

| IteraciÃ³n | n_estimators | max_depth | min_samples_split | ROC-AUC (CV) |
|-----------|--------------|-----------|-------------------|--------------|
| 1         | 100          | 10        | 2                 | 0.9201       |
| 2         | 200          | 20        | 5                 | **0.9365** âœ… |
| 3         | 300          | None      | 2                 | 0.9287       |
| 4         | 100          | 20        | 5                 | 0.9156       |
| 5         | 200          | 10        | 2                 | 0.9298       |

## ğŸ“Š VisualizaciÃ³n del Proceso

### Diagrama de Flujo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. DEFINIR ESPACIO DE BÃšSQUEDA                              â”‚
â”‚    param_distributions = {                                  â”‚
â”‚        'n_estimators': [100, 200, 300],                     â”‚
â”‚        'max_depth': [10, 20, None],                         â”‚
â”‚        ...                                                  â”‚
â”‚    }                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. CREAR RandomizedSearchCV                                 â”‚
â”‚    random_search = RandomizedSearchCV(...)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. ENTRENAR (random_search.fit())                           â”‚
â”‚                                                             â”‚
â”‚    Para cada una de las 20 iteraciones:                    â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚    â”‚ a) Seleccionar combinaciÃ³n aleatoria        â”‚         â”‚
â”‚    â”‚    Ej: n_estimators=200, max_depth=20       â”‚         â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                   â”‚                                         â”‚
â”‚                   â–¼                                         â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚    â”‚ b) ValidaciÃ³n Cruzada (3 folds)             â”‚         â”‚
â”‚    â”‚    Fold 1: Train en 2/3, Test en 1/3        â”‚         â”‚
â”‚    â”‚    Fold 2: Train en 2/3, Test en 1/3        â”‚         â”‚
â”‚    â”‚    Fold 3: Train en 2/3, Test en 1/3        â”‚         â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                   â”‚                                         â”‚
â”‚                   â–¼                                         â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚    â”‚ c) Calcular ROC-AUC promedio                â”‚         â”‚
â”‚    â”‚    Promedio de los 3 folds                  â”‚         â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. SELECCIONAR MEJOR COMBINACIÃ“N                            â”‚
â”‚    best_params_ = combinaciÃ³n con mayor ROC-AUC             â”‚
â”‚    best_score_ = mejor ROC-AUC promedio                     â”‚
â”‚    best_estimator_ = modelo entrenado con best_params_      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’¡ Preguntas Frecuentes

### â“ Â¿Por quÃ© no usar los hiperparÃ¡metros por defecto?

Los valores por defecto de scikit-learn son genÃ©ricos y rara vez son Ã³ptimos para tu dataset especÃ­fico. La optimizaciÃ³n puede mejorar el rendimiento en 5-15%.

### â“ Â¿CÃ³mo sÃ© quÃ© valores incluir en el espacio de bÃºsqueda?

1. **DocumentaciÃ³n**: Lee la documentaciÃ³n del modelo
2. **Experiencia**: Valores comunes en la literatura
3. **ExperimentaciÃ³n**: Prueba rangos amplios primero, luego refina
4. **Recursos**: Tutoriales y papers del Ã¡rea

### â“ Â¿QuÃ© pasa si aumento n_iter de 20 a 100?

- âœ… **Ventaja**: Mayor probabilidad de encontrar mejores hiperparÃ¡metros
- âŒ **Desventaja**: Tiempo de ejecuciÃ³n 5x mayor
- ğŸ’¡ **RecomendaciÃ³n**: Empieza con 20, si el tiempo lo permite, aumenta a 50

### â“ Â¿Por quÃ© usar random_state?

Para **reproducibilidad**: Si ejecutas el cÃ³digo dos veces con la misma semilla, obtendrÃ¡s exactamente los mismos resultados.

```python
# Sin random_state: resultados diferentes cada vez
random_search = RandomizedSearchCV(...)  # âŒ

# Con random_state: resultados idÃ©nticos
random_search = RandomizedSearchCV(..., random_state=42)  # âœ…
```

### â“ Â¿QuÃ© significa cv=3?

**ValidaciÃ³n cruzada con 3 folds**:

1. Divide los datos de entrenamiento en 3 partes iguales
2. Entrena 3 veces, cada vez usando 2 partes para entrenar y 1 para validar
3. Promedia los resultados de las 3 validaciones

**Ventaja**: EvaluaciÃ³n mÃ¡s robusta que un solo train/test split

---

## ğŸ¯ CÃ³digo Completo del Notebook

AquÃ­ estÃ¡ el cÃ³digo exacto usado en el notebook `Telco_Customer_Churn.ipynb`:

```python
from sklearn.model_selection import RandomizedSearchCV

# Paso 1: Definir espacio de bÃºsqueda
param_distributions = {
    'n_estimators': [100, 200, 300],
    'max_depth': [10, 20, None],
    'min_samples_split': [2, 5],
    'min_samples_leaf': [1, 2],
    'max_features': ['sqrt', 'log2'],
    'bootstrap': [True, False]
}

# Paso 2: Crear modelo base
rf_base = RandomForestClassifier(random_state=42)

# Paso 3: Configurar RandomizedSearchCV
random_search = RandomizedSearchCV(
    estimator=rf_base,
    param_distributions=param_distributions,
    n_iter=20,        # Probar 20 combinaciones
    cv=3,             # ValidaciÃ³n cruzada con 3 folds
    scoring='roc_auc',
    random_state=42,
    n_jobs=-1,        # Usar todos los CPUs disponibles
    verbose=1
)

# Paso 4: Entrenar y buscar
random_search.fit(X_train_balanced, y_train_balanced)

# Paso 5: Obtener resultados
print("Mejores hiperparÃ¡metros encontrados:")
print(random_search.best_params_)

print(f"\nMejor score de validaciÃ³n cruzada (ROC-AUC): {random_search.best_score_:.4f}")

# Paso 6: Usar el mejor modelo
best_rf = random_search.best_estimator_
y_pred = best_rf.predict(X_test_processed)
y_pred_proba = best_rf.predict_proba(X_test_processed)[:, 1]
```

---

## ğŸ“ˆ Resultados TÃ­picos

Cuando ejecutas este cÃ³digo, obtienes algo como:

```
Iniciando bÃºsqueda de hiperparÃ¡metros (OPTIMIZADA)...
ğŸ² Usando semilla: 42
âš¡ ConfiguraciÃ³n: n_iter=20, cv=3 (OpciÃ³n Moderada)
â±ï¸  Tiempo estimado: ~3 minutos

Fitting 3 folds for each of 20 candidates, totalling 60 fits
[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  2.8min finished

================================================================================

Mejores hiperparÃ¡metros encontrados:
{
    'n_estimators': 200,
    'min_samples_split': 2,
    'min_samples_leaf': 1,
    'max_features': 'sqrt',
    'max_depth': 20,
    'bootstrap': True
}

Mejor score de validaciÃ³n cruzada (ROC-AUC): 0.9365

Rendimiento en conjunto de prueba:
  Accuracy: 0.8274
  Precision: 0.6667
  Recall: 0.5700
  F1-Score: 0.6147
  ROC-AUC: 0.8274
```

---

## ğŸš€ Resumen Ejecutivo

### Â¿CÃ³mo se obtienen los hiperparÃ¡metros? - Respuesta Corta

1. **Defines** un espacio de bÃºsqueda con posibles valores
2. **RandomizedSearchCV prueba** combinaciones aleatorias
3. **Cada combinaciÃ³n se evalÃºa** con validaciÃ³n cruzada
4. **Se selecciona** la combinaciÃ³n con mejor mÃ©trica (ROC-AUC)
5. **Accedes** a los mejores valores con `.best_params_`

### AnalogÃ­a Simple

Es como **buscar la mejor receta de pizza**:

- **Ingredientes variables** = hiperparÃ¡metros (cantidad de queso, tiempo de horneado, temperatura)
- **Espacio de bÃºsqueda** = todas las combinaciones posibles de ingredientes
- **RandomizedSearchCV** = probar 20 recetas aleatorias en lugar de las 144 posibles
- **ValidaciÃ³n cruzada** = hacer que 3 personas diferentes prueben cada pizza
- **Mejor receta** = la que obtuvo mejor calificaciÃ³n promedio

Â¡Y listo! Ahora tienes los mejores hiperparÃ¡metros para tu modelo. ğŸ‰


